% ============================================
% GUÍA DE MEJORAS PARA EL ANÁLISIS EXPLORATORIO DE DATOS (EDA)
% Proyecto: AlphaTech-Analyzer
% Universidad de La Habana - MATCOM
% ============================================

\documentclass[12pt,a4paper]{article}

% ============================================
% PAQUETES
% ============================================
\usepackage[utf8]{inputenc}
\usepackage[spanish,es-noshorthands]{babel}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{float}
\usepackage{caption}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,calc,fit,backgrounds,mindmap,patterns,decorations.pathreplacing}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usepgfplotslibrary{statistics,fillbetween}
\usepackage{enumitem}
\usepackage{tcolorbox}
\tcbuselibrary{theorems,skins,breakable}
\usepackage{fancyhdr}
\usepackage{longtable}
\usepackage{multicol}
\usepackage{wrapfig}

\geometry{margin=2.5cm}
\setlength{\headheight}{14.5pt}

% Configuración de encabezados
\pagestyle{fancy}
\fancyhf{}
\rhead{Mejoras EDA}
\lhead{AlphaTech-Analyzer}
\rfoot{Página \thepage}

% Configuración de listings para Python
\lstset{
    language=Python,
    basicstyle=\ttfamily\footnotesize,
    keywordstyle=\color{blue}\bfseries,
    stringstyle=\color{red},
    commentstyle=\color{green!60!black}\itshape,
    frame=single,
    breaklines=true,
    showstringspaces=false,
    numbers=left,
    numberstyle=\tiny\color{gray},
    backgroundcolor=\color{gray!5},
    xleftmargin=2em,
    framexleftmargin=1.5em,
    captionpos=b
}

% Cajas para diferentes tipos de contenido
\newtcolorbox{mejora}[1][]{
    colback=green!5!white,
    colframe=green!60!black,
    fonttitle=\bfseries,
    title=#1
}

\newtcolorbox{codigo}[1][]{
    colback=gray!5!white,
    colframe=gray!50!black,
    fonttitle=\bfseries,
    title=#1
}

\newtcolorbox{teoria}[1][]{
    colback=blue!5!white,
    colframe=blue!60!black,
    fonttitle=\bfseries,
    title=#1
}

\newtcolorbox{importante}[1][]{
    colback=yellow!10!white,
    colframe=orange!70!black,
    fonttitle=\bfseries,
    title=#1
}

\newtcolorbox{referencia}[1][]{
    colback=purple!5!white,
    colframe=purple!60!black,
    fonttitle=\bfseries,
    title=#1
}

\newtcolorbox{definicion}[1][]{
    colback=cyan!5!white,
    colframe=cyan!60!black,
    fonttitle=\bfseries,
    title=#1,
    breakable
}

\newtcolorbox{ejemplo}[1][]{
    colback=gray!5!white,
    colframe=gray!60!black,
    fonttitle=\bfseries,
    title=#1,
    breakable
}

\newtcolorbox{libro}[1][]{
    colback=brown!5!white,
    colframe=brown!60!black,
    fonttitle=\bfseries,
    title=#1
}

% ============================================
% DOCUMENTO
% ============================================
\title{
    \vspace{-1cm}
    {\Large Universidad de La Habana - MATCOM}\\[0.5cm]
    \rule{\linewidth}{0.5mm}\\[0.4cm]
    {\LARGE \textbf{Guía de Mejoras para el\\Análisis Exploratorio de Datos (EDA)}}\\[0.3cm]
    {\large Proyecto AlphaTech-Analyzer}\\[0.2cm]
    \rule{\linewidth}{0.5mm}\\[1cm]
    {\large Análisis de Acciones Tecnológicas del NASDAQ-100}
}
\author{}
\date{\today}

\begin{document}

\maketitle
\thispagestyle{empty}
\newpage

\tableofcontents
\newpage

% ============================================
% INTRODUCCIÓN
% ============================================
\section{Introducción}

\subsection{¿Qué es el Análisis Exploratorio de Datos (EDA)?}

\begin{definicion}[Definición de EDA]
El \textbf{Análisis Exploratorio de Datos} (EDA, por sus siglas en inglés) es el proceso de examinar y resumir las características principales de un conjunto de datos, generalmente usando métodos visuales y estadísticos descriptivos.

\textbf{Objetivo principal:} Entender los datos antes de aplicar modelos estadísticos o de machine learning.

El término fue popularizado por el estadístico John Tukey en su libro \textit{``Exploratory Data Analysis''} (1977).
\end{definicion}

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=0.8cm,
    box/.style={rectangle, draw, fill=blue!20, text width=3cm, text centered, rounded corners, minimum height=1cm, font=\small},
    arrow/.style={thick, ->, >=stealth}
]
% Flujo del análisis de datos
\node (raw) [box, fill=red!20] {Datos Crudos};
\node (eda) [box, fill=yellow!30, right=of raw, text width=4cm] {EDA\\(Explorar, Visualizar, Entender)};
\node (model) [box, fill=green!20, right=of eda] {Modelado\\Estadístico};
\node (results) [box, fill=purple!20, right=of model] {Resultados\\Conclusiones};

\draw [arrow] (raw) -- (eda);
\draw [arrow] (eda) -- (model);
\draw [arrow] (model) -- (results);

% Feedback loop
\draw [arrow, dashed, bend right=40] (model.south) to node[below, font=\tiny] {Revisar datos} (eda.south);
\end{tikzpicture}
\caption{El EDA es el paso crucial entre los datos crudos y el modelado}
\end{figure}

\subsection{¿Por Qué es Importante el EDA en Finanzas?}

En el análisis financiero, el EDA es especialmente crítico porque:

\begin{enumerate}
    \item \textbf{Los datos financieros tienen comportamientos especiales}: No siguen distribuciones normales, tienen eventos extremos (crashes), y cambian con el tiempo.
    
    \item \textbf{Errores en los datos son costosos}: Un dato incorrecto puede llevar a decisiones de inversión erróneas.
    
    \item \textbf{Hay patrones ocultos}: Correlaciones entre activos, estacionalidad, ciclos económicos.
\end{enumerate}

\begin{libro}[Referencia Fundamental]
\textbf{Tukey, J.W. (1977). \textit{Exploratory Data Analysis}. Addison-Wesley.}

Este libro estableció los principios del EDA moderno. Tukey argumentaba que antes de confirmar hipótesis, debemos explorar los datos con mente abierta.

\textit{``The greatest value of a picture is when it forces us to notice what we never expected to see.''} --- John Tukey
\end{libro}

\subsection{Estado Actual de Tu EDA}

Tu notebook \texttt{eda.ipynb} actualmente incluye:

\begin{itemize}
    \item Carga de datos del panel mensual
    \item Estadísticos descriptivos básicos (\texttt{.describe()})
    \item Histograma de retornos globales
    \item Boxplots por empresa
    \item Gráfico de barras de volatilidad
    \item Scatter plot riesgo-retorno
    \item Serie temporal de precios (una empresa)
    \item Matriz de correlación simple
    \item QQ-plot de normalidad
\end{itemize}

\subsection{Qué Falta y Por Qué es Importante}

Según las mejores prácticas en análisis financiero y la documentación de proyectos similares, un EDA completo para datos de series temporales financieras debería incluir:

\begin{importante}[Análisis Faltantes Críticos]
\begin{enumerate}
    \item \textbf{Análisis de valores faltantes y outliers}
    \item \textbf{Matriz de correlación entre empresas (heatmap)}
    \item \textbf{Series temporales múltiples comparativas}
    \item \textbf{Análisis de estacionariedad}
    \item \textbf{Distribuciones por período (antes/después COVID)}
    \item \textbf{Rolling statistics (media/volatilidad móvil)}
    \item \textbf{Análisis de curtosis y asimetría}
    \item \textbf{Drawdown analysis (caídas máximas)}
    \item \textbf{Rendimientos acumulados}
    \item \textbf{Pair plots multivariantes}
\end{enumerate}
\end{importante}

% ============================================
% MEJORA 1: VALORES FALTANTES Y OUTLIERS
% ============================================
\section{Mejora 1: Análisis de Valores Faltantes y Outliers}

\subsection{¿Qué son los Valores Faltantes?}

\begin{definicion}[Valor Faltante (Missing Value)]
Un \textbf{valor faltante} es una observación que debería existir pero no está presente en nuestros datos. En Python/pandas se representa como \texttt{NaN} (Not a Number) o \texttt{None}.

\textbf{Ejemplo:} Si tenemos datos mensuales de Apple desde 2018 hasta 2024, deberíamos tener 84 observaciones. Si solo tenemos 80, hay 4 valores faltantes.
\end{definicion}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.7]
% Tabla con valores faltantes
\draw[thick] (0,0) grid (6,4);

% Headers
\node at (0.5, 4.3) {\tiny Fecha};
\node at (1.5, 4.3) {\tiny AAPL};
\node at (2.5, 4.3) {\tiny MSFT};
\node at (3.5, 4.3) {\tiny GOOGL};
\node at (4.5, 4.3) {\tiny AMZN};
\node at (5.5, 4.3) {\tiny NVDA};

% Row 1
\node at (0.5, 3.5) {\tiny Ene-18};
\node at (1.5, 3.5) {\tiny 42.5};
\node at (2.5, 3.5) {\tiny 95.0};
\node at (3.5, 3.5) {\tiny 110};
\node at (4.5, 3.5) {\tiny 125};
\node at (5.5, 3.5) {\tiny 58};

% Row 2
\node at (0.5, 2.5) {\tiny Feb-18};
\node at (1.5, 2.5) {\tiny 44.2};
\fill[red!30] (2,2) rectangle (3,3); % Missing
\node at (2.5, 2.5) {\tiny NaN};
\node at (3.5, 2.5) {\tiny 108};
\node at (4.5, 2.5) {\tiny 128};
\node at (5.5, 2.5) {\tiny 60};

% Row 3
\node at (0.5, 1.5) {\tiny Mar-18};
\node at (1.5, 1.5) {\tiny 41.8};
\node at (2.5, 1.5) {\tiny 92.3};
\fill[red!30] (3,1) rectangle (4,2); % Missing
\node at (3.5, 1.5) {\tiny NaN};
\fill[red!30] (4,1) rectangle (5,2); % Missing
\node at (4.5, 1.5) {\tiny NaN};
\node at (5.5, 1.5) {\tiny 55};

% Row 4
\node at (0.5, 0.5) {\tiny Abr-18};
\node at (1.5, 0.5) {\tiny 43.1};
\node at (2.5, 0.5) {\tiny 94.7};
\node at (3.5, 0.5) {\tiny 105};
\node at (4.5, 0.5) {\tiny 130};
\node at (5.5, 0.5) {\tiny 62};

% Legend
\fill[red!30] (7, 3) rectangle (7.5, 3.5);
\node[right] at (7.6, 3.25) {\small Valor Faltante (NaN)};
\end{tikzpicture}
\caption{Ejemplo visual de valores faltantes en un panel de datos}
\end{figure}

\subsection{Tipos de Datos Faltantes: La Clasificación de Rubin}

\begin{teoria}[Clasificación de Little y Rubin (2002)]
Donald Rubin y Roderick Little clasificaron los datos faltantes en tres categorías según el \textbf{mecanismo} que los genera:

\begin{enumerate}
    \item \textbf{MCAR (Missing Completely At Random)}:
    \begin{itemize}
        \item La probabilidad de que un dato falte NO depende de ninguna variable
        \item Es el caso más ``benigno''
        \item \textit{Ejemplo:} Un error aleatorio en el servidor de datos
    \end{itemize}
    
    \item \textbf{MAR (Missing At Random)}:
    \begin{itemize}
        \item La probabilidad de que un dato falte depende de otras variables \textbf{observadas}
        \item Se puede ``explicar'' con la información disponible
        \item \textit{Ejemplo:} Empresas pequeñas tienen más datos faltantes (y sabemos cuáles son pequeñas)
    \end{itemize}
    
    \item \textbf{MNAR (Missing Not At Random)}:
    \begin{itemize}
        \item La probabilidad de que un dato falte depende del \textbf{valor que falta}
        \item El caso más problemático
        \item \textit{Ejemplo:} Empresas no reportan pérdidas grandes (el dato falta precisamente por ser negativo)
    \end{itemize}
\end{enumerate}
\end{teoria}

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=1.5cm,
    box/.style={rectangle, draw, text width=4cm, text centered, rounded corners, minimum height=2cm, font=\small}
]
\node (mcar) [box, fill=green!20] {
    \textbf{MCAR}\\
    Falta por azar puro\\
    \textit{Fácil de manejar}
};
\node (mar) [box, fill=yellow!30, right=of mcar] {
    \textbf{MAR}\\
    Falta por razones conocidas\\
    \textit{Manejable con cuidado}
};
\node (mnar) [box, fill=red!20, right=of mar] {
    \textbf{MNAR}\\
    Falta por el propio valor\\
    \textit{Problemático}
};

% Arrows with labels
\draw[->, thick] (mcar.south) -- ++(0,-0.8) node[below, font=\tiny] {Ignorar o imputar};
\draw[->, thick] (mar.south) -- ++(0,-0.8) node[below, font=\tiny] {Imputar con modelos};
\draw[->, thick] (mnar.south) -- ++(0,-0.8) node[below, font=\tiny] {Análisis de sensibilidad};
\end{tikzpicture}
\caption{Los tres tipos de datos faltantes según Rubin}
\end{figure}

\begin{libro}[Referencia Clave]
\textbf{Little, R.J.A. \& Rubin, D.B. (2002). \textit{Statistical Analysis with Missing Data}. 2nd Edition. Wiley.}

Este es EL libro de referencia sobre datos faltantes. Introduce la clasificación MCAR/MAR/MNAR y métodos de imputación como Expectation-Maximization (EM) e imputación múltiple.
\end{libro}

\subsection{¿Qué son los Outliers (Valores Atípicos)?}

\begin{definicion}[Outlier o Valor Atípico]
Un \textbf{outlier} es una observación que se desvía significativamente del patrón general de los datos. Puede ser:
\begin{itemize}
    \item \textbf{Legítimo}: Un evento real extremo (ej: crash del mercado en marzo 2020)
    \item \textbf{Error}: Un dato mal registrado (ej: precio de \$1 en vez de \$100)
\end{itemize}

\textbf{Importante}: En finanzas, los outliers legítimos son muy importantes porque representan eventos de riesgo real.
\end{definicion}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=12cm, height=6cm,
    xlabel={Observación},
    ylabel={Retorno (\%)},
    title={Retornos con Outliers Marcados},
    grid=major,
    ymin=-40, ymax=30
]
% Datos normales
\addplot[only marks, mark=*, blue, mark size=1.5pt] coordinates {
    (1,2) (2,3) (3,-1) (4,4) (5,2) (6,-2) (7,3) (8,1) (9,5) (10,-1)
    (11,2) (12,4) (13,3) (14,-3) (15,1) (16,2) (17,-2) (18,3) (19,4) (20,1)
    (21,-1) (22,2) (23,3) (24,-2) (25,5) (26,1) (27,3) (28,2) (29,-1) (30,4)
};
% Outliers
\addplot[only marks, mark=*, red, mark size=3pt] coordinates {
    (15,-35) (25,25)
};
% Anotaciones
\node[red, font=\small] at (axis cs:15,-30) {COVID Crash};
\node[red, font=\small] at (axis cs:25,22) {Recuperación};

% Líneas de referencia
\draw[dashed, green!60!black] (axis cs:0,8) -- (axis cs:32,8) node[right, font=\tiny] {+2$\sigma$};
\draw[dashed, green!60!black] (axis cs:0,-8) -- (axis cs:32,-8) node[right, font=\tiny] {-2$\sigma$};
\end{axis}
\end{tikzpicture}
\caption{Los puntos rojos son outliers: observaciones muy alejadas del centro}
\end{figure}

\subsection{Métodos de Detección de Outliers}

\subsubsection{Método 1: Rango Intercuartílico (IQR)}

\begin{teoria}[Método IQR - John Tukey (1977)]
El \textbf{Rango Intercuartílico (IQR)} es la diferencia entre el tercer cuartil (Q3, percentil 75) y el primer cuartil (Q1, percentil 25):

\begin{equation}
    IQR = Q_3 - Q_1
\end{equation}

Un valor $x$ se considera \textbf{outlier} si:
\begin{equation}
    x < Q_1 - 1.5 \times IQR \quad \text{o} \quad x > Q_3 + 1.5 \times IQR
\end{equation}

\textbf{¿Por qué 1.5?} Tukey eligió este valor porque, para una distribución normal, aproximadamente 0.7\% de los datos caerían fuera de estos límites por azar.
\end{teoria}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.9]
% Boxplot visual explanation
\draw[thick] (0,0) -- (14,0);

% Box
\fill[blue!20] (4,0.5) rectangle (8,-0.5);
\draw[thick] (4,0.5) -- (4,-0.5);
\draw[thick] (8,0.5) -- (8,-0.5);
\draw[thick] (4,0.5) -- (8,0.5);
\draw[thick] (4,-0.5) -- (8,-0.5);

% Median
\draw[thick, red] (6,0.5) -- (6,-0.5);

% Whiskers
\draw[thick] (4,0) -- (1.5,0);
\draw[thick] (8,0) -- (10.5,0);
\draw[thick] (1.5,0.3) -- (1.5,-0.3);
\draw[thick] (10.5,0.3) -- (10.5,-0.3);

% Outliers
\fill[red] (0.5,0) circle (3pt);
\fill[red] (12,0) circle (3pt);
\fill[red] (13,0) circle (3pt);

% Labels
\node[below] at (4,-0.7) {$Q_1$};
\node[below] at (6,-0.7) {Mediana};
\node[below] at (8,-0.7) {$Q_3$};
\node[below] at (1.5,-0.7) {\small $Q_1 - 1.5 \cdot IQR$};
\node[below] at (10.5,-0.7) {\small $Q_3 + 1.5 \cdot IQR$};

% IQR bracket
\draw[decorate, decoration={brace, amplitude=5pt, raise=3pt}] (4,0.5) -- (8,0.5) 
    node[midway, above=8pt] {IQR};

% Outlier labels
\node[above, red] at (0.5,0.2) {\small Outlier};
\node[above, red] at (12.5,0.2) {\small Outliers};
\end{tikzpicture}
\caption{Anatomía de un boxplot y la regla del IQR para detectar outliers}
\end{figure}

\subsubsection{Método 2: Z-Score (Puntuación Estándar)}

\begin{teoria}[Z-Score]
El \textbf{Z-score} mide cuántas desviaciones estándar está un valor de la media:

\begin{equation}
    z = \frac{x - \mu}{\sigma}
\end{equation}

donde:
\begin{itemize}
    \item $x$ = el valor que estamos evaluando
    \item $\mu$ = la media de todos los datos
    \item $\sigma$ = la desviación estándar de todos los datos
\end{itemize}

\textbf{Regla común:} Un valor es outlier si $|z| > 3$ (está a más de 3 desviaciones estándar de la media).

\textbf{Limitación:} Asume que los datos son normales. Los propios outliers afectan el cálculo de $\mu$ y $\sigma$.
\end{teoria}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=14cm, height=6cm,
    domain=-4:4,
    samples=100,
    xlabel={Z-Score},
    ylabel={Densidad},
    title={Distribución Normal y Regla de 3 Sigmas},
    grid=major,
    ymin=0, ymax=0.45,
    xtick={-3,-2,-1,0,1,2,3},
    extra x ticks={-3,3},
    extra x tick style={grid=major, grid style={red, thick}},
]
% Normal distribution
\addplot[thick, blue, name path=normal] {exp(-x^2/2)/sqrt(2*pi)};

% Fill between -3 and 3
\addplot[fill=blue!20, draw=none, domain=-3:3] {exp(-x^2/2)/sqrt(2*pi)} \closedcycle;

% Fill outlier regions
\addplot[fill=red!30, draw=none, domain=-4:-3] {exp(-x^2/2)/sqrt(2*pi)} \closedcycle;
\addplot[fill=red!30, draw=none, domain=3:4] {exp(-x^2/2)/sqrt(2*pi)} \closedcycle;

\end{axis}

% Labels
\node at (7, 2) {\small 99.7\% de los datos};
\node[red] at (1.5, 1) {\small 0.15\%};
\node[red] at (12.5, 1) {\small 0.15\%};
\end{tikzpicture}
\caption{El 99.7\% de los datos normales está entre $\pm 3\sigma$. Los valores fuera son outliers.}
\end{figure}

\begin{libro}[Referencia sobre Outliers]
\textbf{Barnett, V. \& Lewis, T. (1994). \textit{Outliers in Statistical Data}. 3rd Edition. Wiley.}

Cubre todos los métodos de detección de outliers: paramétricos, no paramétricos, univariantes y multivariantes. Incluye tests formales como el test de Grubbs y Dixon.
\end{libro}

\subsection{Fundamento Teórico}

\begin{teoria}[Importancia del Análisis de Datos Faltantes]
Los valores faltantes en series financieras pueden deberse a:
\begin{itemize}
    \item Días sin cotización (feriados, suspensiones)
    \item Errores en la fuente de datos
    \item Empresas que comenzaron a cotizar después del inicio del período
\end{itemize}

Según \textit{Little \& Rubin (2002), ``Statistical Analysis with Missing Data''}, es crucial identificar si los datos faltan de forma:
\begin{itemize}
    \item \textbf{MCAR} (Missing Completely At Random): Aleatorio puro
    \item \textbf{MAR} (Missing At Random): Depende de variables observadas
    \item \textbf{MNAR} (Missing Not At Random): Depende del valor faltante mismo
\end{itemize}
\end{teoria}

\subsection{Implementación Propuesta}

\begin{lstlisting}[caption={Análisis de valores faltantes}, label={lst:missing}]
# ============================================
# CELDA: Analisis de Valores Faltantes
# ============================================
import missingno as msno  # pip install missingno

# 1. Contar valores faltantes por columna
# .isnull() retorna True/False para cada celda
# .sum() cuenta los True (valores nulos)
missing_counts = panel_df.isnull().sum()
print("Valores faltantes por columna:")
print(missing_counts)

# 2. Porcentaje de datos faltantes
# Dividimos entre el total de filas para obtener proporcion
missing_pct = (panel_df.isnull().sum() / len(panel_df)) * 100
print("\nPorcentaje de datos faltantes:")
print(missing_pct.round(2))

# 3. Visualizacion matricial de valores faltantes
# msno.matrix muestra patrones de datos faltantes
# Las lineas blancas indican valores nulos
plt.figure(figsize=(12, 6))
msno.matrix(panel_df, figsize=(12, 6), sparkline=False)
plt.title("Patron de Valores Faltantes en el Dataset")
plt.tight_layout()
plt.savefig("../data/processed/missing_values_pattern.png", dpi=150)
plt.show()

# 4. Empresas con datos incompletos
# Agrupamos por empresa y contamos filas
obs_por_empresa = panel_df.groupby("Company").size()
empresas_incompletas = obs_por_empresa[obs_por_empresa < obs_por_empresa.max()]
print("\nEmpresas con menos observaciones que el maximo:")
print(empresas_incompletas)
\end{lstlisting}

\subsubsection{Explicación Línea por Línea}

\begin{enumerate}
    \item \textbf{Línea 6}: \texttt{import missingno as msno} - Librería especializada para visualizar patrones de datos faltantes.
    
    \item \textbf{Línea 10}: \texttt{panel\_df.isnull().sum()} - El método \texttt{.isnull()} crea un DataFrame booleano donde \texttt{True} indica valor nulo. Luego \texttt{.sum()} cuenta los \texttt{True} por columna.
    
    \item \textbf{Línea 16}: Calculamos el porcentaje dividiendo entre \texttt{len(panel\_df)} (número total de filas).
    
    \item \textbf{Línea 22}: \texttt{msno.matrix()} genera una visualización donde cada fila es una observación y cada columna es una variable. Los espacios blancos son valores faltantes.
    
    \item \textbf{Línea 30}: \texttt{groupby("Company").size()} cuenta cuántas filas tiene cada empresa.
\end{enumerate}

\subsection{Análisis de Outliers}

\begin{lstlisting}[caption={Deteccion de outliers con IQR y Z-score}, label={lst:outliers}]
# ============================================
# CELDA: Deteccion de Outliers
# ============================================

# Metodo 1: Rango Intercuartilico (IQR)
# IQR = Q3 - Q1, outliers son valores fuera de [Q1-1.5*IQR, Q3+1.5*IQR]
def detectar_outliers_iqr(serie, factor=1.5):
    """
    Detecta outliers usando el metodo IQR.
    
    Parametros:
    -----------
    serie : pd.Series
        Serie de datos numericos
    factor : float
        Multiplicador del IQR (1.5 es estandar, 3.0 para extremos)
    
    Retorna:
    --------
    pd.Series : booleano indicando si cada valor es outlier
    """
    Q1 = serie.quantile(0.25)  # Primer cuartil (percentil 25)
    Q3 = serie.quantile(0.75)  # Tercer cuartil (percentil 75)
    IQR = Q3 - Q1              # Rango intercuartilico
    
    # Limites inferior y superior
    limite_inf = Q1 - factor * IQR
    limite_sup = Q3 + factor * IQR
    
    # Retorna True si el valor esta fuera de los limites
    return (serie < limite_inf) | (serie > limite_sup)

# Aplicar a los retornos
outliers_return = detectar_outliers_iqr(panel_df["Return"].dropna())
n_outliers = outliers_return.sum()
pct_outliers = (n_outliers / len(outliers_return)) * 100

print(f"Outliers en retornos (metodo IQR):")
print(f"  Total: {n_outliers}")
print(f"  Porcentaje: {pct_outliers:.2f}%")

# Metodo 2: Z-score
# Un valor es outlier si |z| > 3 (esta a mas de 3 desv. estandar de la media)
from scipy import stats

z_scores = np.abs(stats.zscore(panel_df["Return"].dropna()))
outliers_zscore = z_scores > 3
print(f"\nOutliers en retornos (Z-score > 3):")
print(f"  Total: {outliers_zscore.sum()}")

# Visualizacion de outliers
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Boxplot con outliers marcados
axes[0].boxplot(panel_df["Return"].dropna(), vert=True)
axes[0].set_title("Boxplot de Retornos\n(puntos fuera son outliers)")
axes[0].set_ylabel("Retorno logaritmico")

# Histograma con lineas de corte IQR
returns = panel_df["Return"].dropna()
Q1, Q3 = returns.quantile([0.25, 0.75])
IQR = Q3 - Q1

axes[1].hist(returns, bins=50, edgecolor='black', alpha=0.7)
axes[1].axvline(Q1 - 1.5*IQR, color='red', linestyle='--', 
                label=f'Limite inf: {Q1-1.5*IQR:.3f}')
axes[1].axvline(Q3 + 1.5*IQR, color='red', linestyle='--', 
                label=f'Limite sup: {Q3+1.5*IQR:.3f}')
axes[1].legend()
axes[1].set_title("Distribucion con limites IQR")
axes[1].set_xlabel("Retorno logaritmico")

plt.tight_layout()
plt.savefig("../data/processed/outliers_analysis.png", dpi=150)
plt.show()
\end{lstlisting}

\begin{teoria}[Métodos de Detección de Outliers]
\textbf{1. Método IQR (Tukey, 1977):}
\begin{equation}
    \text{Outlier si } x < Q_1 - 1.5 \times IQR \text{ o } x > Q_3 + 1.5 \times IQR
\end{equation}

\textbf{2. Z-Score:}
\begin{equation}
    z = \frac{x - \mu}{\sigma}, \quad \text{Outlier si } |z| > 3
\end{equation}

El método IQR es más robusto porque no asume normalidad y no se ve afectado por los propios outliers al calcular los límites.
\end{teoria}

% ============================================
% MEJORA 2: MATRIZ DE CORRELACIÓN ENTRE EMPRESAS
% ============================================
\section{Mejora 2: Matriz de Correlación entre Empresas}

\subsection{¿Qué es la Correlación?}

\begin{definicion}[Correlación de Pearson]
La \textbf{correlación de Pearson} ($\rho$ o $r$) mide la fuerza y dirección de la relación \textbf{lineal} entre dos variables. Su valor va de -1 a +1.

\begin{equation}
    \rho_{X,Y} = \frac{\text{Cov}(X, Y)}{\sigma_X \cdot \sigma_Y} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum(x_i - \bar{x})^2} \cdot \sqrt{\sum(y_i - \bar{y})^2}}
\end{equation}

\textbf{Interpretación:}
\begin{itemize}
    \item $\rho = +1$: Correlación positiva perfecta (cuando X sube, Y sube proporcionalmente)
    \item $\rho = 0$: No hay relación lineal
    \item $\rho = -1$: Correlación negativa perfecta (cuando X sube, Y baja proporcionalmente)
\end{itemize}
\end{definicion}

\begin{figure}[H]
\centering
\begin{tikzpicture}
% Correlation examples
\begin{scope}[xshift=0cm]
    \begin{axis}[
        width=4.5cm, height=4cm,
        title={\small $\rho = +0.95$},
        xlabel={\tiny X}, ylabel={\tiny Y},
        xmin=0, xmax=10, ymin=0, ymax=10,
        ticks=none
    ]
    \addplot[only marks, mark=*, blue, mark size=1pt] coordinates {
        (1,1.2) (2,2.3) (3,2.8) (4,4.1) (5,5.2) (6,5.9) (7,7.1) (8,7.8) (9,8.5) (10,9.8)
    };
    \addplot[red, thick, domain=0:10] {0.95*x + 0.3};
    \end{axis}
\end{scope}

\begin{scope}[xshift=5cm]
    \begin{axis}[
        width=4.5cm, height=4cm,
        title={\small $\rho \approx 0$},
        xlabel={\tiny X}, ylabel={\tiny Y},
        xmin=0, xmax=10, ymin=0, ymax=10,
        ticks=none
    ]
    \addplot[only marks, mark=*, blue, mark size=1pt] coordinates {
        (1,5) (2,3) (3,8) (4,2) (5,7) (6,4) (7,6) (8,1) (9,9) (10,5)
    };
    \end{axis}
\end{scope}

\begin{scope}[xshift=10cm]
    \begin{axis}[
        width=4.5cm, height=4cm,
        title={\small $\rho = -0.92$},
        xlabel={\tiny X}, ylabel={\tiny Y},
        xmin=0, xmax=10, ymin=0, ymax=10,
        ticks=none
    ]
    \addplot[only marks, mark=*, blue, mark size=1pt] coordinates {
        (1,9.5) (2,8.2) (3,7.5) (4,6.3) (5,5.1) (6,4.2) (7,3.5) (8,2.1) (9,1.8) (10,0.5)
    };
    \addplot[red, thick, domain=0:10] {-0.95*x + 10.5};
    \end{axis}
\end{scope}
\end{tikzpicture}
\caption{Ejemplos de correlación positiva, nula y negativa}
\end{figure}

\subsection{¿Por Qué es Importante en Finanzas?}

\begin{teoria}[Correlación y Diversificación - Markowitz (1952)]
Harry Markowitz, en su \textit{Teoría Moderna de Portafolios}, demostró que:

\begin{enumerate}
    \item \textbf{Combinar activos reduce el riesgo} (si no están perfectamente correlacionados)
    \item El \textbf{riesgo del portafolio} depende de las correlaciones entre activos
    \item Activos con \textbf{baja correlación} entre sí son ideales para diversificar
\end{enumerate}

Para dos activos con pesos $w_1$ y $w_2$, la varianza del portafolio es:
\begin{equation}
    \sigma_p^2 = w_1^2\sigma_1^2 + w_2^2\sigma_2^2 + 2w_1w_2\sigma_1\sigma_2\rho_{12}
\end{equation}

\textbf{Observación clave:} Si $\rho_{12} < 1$, el riesgo del portafolio es MENOR que el promedio ponderado de los riesgos individuales.
\end{teoria}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.9]
% Efficient frontier illustration
\begin{axis}[
    width=12cm, height=8cm,
    xlabel={Riesgo (Volatilidad $\sigma$)},
    ylabel={Retorno Esperado ($\mu$)},
    title={Frontera Eficiente de Markowitz},
    grid=major,
    xmin=0, xmax=0.35, ymin=0, ymax=0.20
]
% Individual assets
\addplot[only marks, mark=*, mark size=4pt, blue] coordinates {
    (0.15, 0.08)
    (0.25, 0.12)
    (0.30, 0.15)
    (0.20, 0.10)
    (0.28, 0.14)
};
\node[right] at (axis cs:0.15, 0.08) {\small AAPL};
\node[right] at (axis cs:0.25, 0.12) {\small MSFT};
\node[right] at (axis cs:0.30, 0.15) {\small NVDA};
\node[right] at (axis cs:0.20, 0.10) {\small GOOGL};
\node[right] at (axis cs:0.28, 0.14) {\small TSLA};

% Efficient frontier (curve)
\addplot[thick, red, smooth, domain=0.10:0.32] {0.05 + 0.4*x - 0.3*x^2};

% Minimum variance portfolio
\addplot[only marks, mark=star, mark size=5pt, green!60!black] coordinates {(0.10, 0.085)};
\node[left, green!60!black] at (axis cs:0.10, 0.085) {\small Mínima varianza};

\end{axis}
\end{tikzpicture}
\caption{Combinando activos (puntos azules) se puede alcanzar la frontera eficiente (curva roja)}
\end{figure}

\begin{libro}[Referencia Fundamental]
\textbf{Markowitz, H. (1952). ``Portfolio Selection''. \textit{The Journal of Finance}, 7(1), 77-91.}

Este artículo de 14 páginas revolucionó las finanzas y le valió el Premio Nobel de Economía en 1990. Introduce el concepto de que los inversores no solo deben considerar el retorno esperado, sino también el riesgo (varianza) y las correlaciones entre activos.
\end{libro}

\subsection{¿Qué es un Heatmap de Correlación?}

\begin{definicion}[Heatmap (Mapa de Calor)]
Un \textbf{heatmap} es una visualización donde los valores numéricos se representan como colores. En un heatmap de correlación:
\begin{itemize}
    \item Cada celda representa la correlación entre dos variables
    \item Colores cálidos (rojo) = correlación positiva alta
    \item Colores fríos (azul) = correlación negativa
    \item Colores neutros (blanco/amarillo) = correlación cercana a cero
\end{itemize}
\end{definicion}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.65]
% Heatmap cells - using fixed colors to simulate correlations
\def\companies{{"AAPL", "MSFT", "GOOGL", "AMZN", "NVDA"}}

% Define colors for correlation values
% Row 1: AAPL
\fill[green!80!black] (0,4) rectangle (1,5); % AAPL-AAPL = 1.0
\fill[green!60] (1,4) rectangle (2,5);       % AAPL-MSFT = 0.8
\fill[green!50] (2,4) rectangle (3,5);       % AAPL-GOOGL = 0.7
\fill[green!40] (3,4) rectangle (4,5);       % AAPL-AMZN = 0.6
\fill[green!55] (4,4) rectangle (5,5);       % AAPL-NVDA = 0.75

% Row 2: MSFT
\fill[green!60] (0,3) rectangle (1,4);
\fill[green!80!black] (1,3) rectangle (2,4);
\fill[green!55] (2,3) rectangle (3,4);
\fill[green!50] (3,3) rectangle (4,4);
\fill[green!45] (4,3) rectangle (5,4);

% Row 3: GOOGL
\fill[green!50] (0,2) rectangle (1,3);
\fill[green!55] (1,2) rectangle (2,3);
\fill[green!80!black] (2,2) rectangle (3,3);
\fill[green!60] (3,2) rectangle (4,3);
\fill[green!40] (4,2) rectangle (5,3);

% Row 4: AMZN
\fill[green!40] (0,1) rectangle (1,2);
\fill[green!50] (1,1) rectangle (2,2);
\fill[green!60] (2,1) rectangle (3,2);
\fill[green!80!black] (3,1) rectangle (4,2);
\fill[green!35] (4,1) rectangle (5,2);

% Row 5: NVDA
\fill[green!55] (0,0) rectangle (1,1);
\fill[green!45] (1,0) rectangle (2,1);
\fill[green!40] (2,0) rectangle (3,1);
\fill[green!35] (3,0) rectangle (4,1);
\fill[green!80!black] (4,0) rectangle (5,1);

% Grid
\draw[thick] (0,0) grid (5,5);

% Column labels
\node[rotate=45, anchor=west] at (0.5,5.2) {\small AAPL};
\node[rotate=45, anchor=west] at (1.5,5.2) {\small MSFT};
\node[rotate=45, anchor=west] at (2.5,5.2) {\small GOOGL};
\node[rotate=45, anchor=west] at (3.5,5.2) {\small AMZN};
\node[rotate=45, anchor=west] at (4.5,5.2) {\small NVDA};

% Row labels
\node[left] at (0,4.5) {\small AAPL};
\node[left] at (0,3.5) {\small MSFT};
\node[left] at (0,2.5) {\small GOOGL};
\node[left] at (0,1.5) {\small AMZN};
\node[left] at (0,0.5) {\small NVDA};

% Values in cells (diagonal = 1.0)
\node at (0.5,4.5) {\tiny 1.00};
\node at (1.5,4.5) {\tiny 0.82};
\node at (2.5,4.5) {\tiny 0.71};
\node at (3.5,4.5) {\tiny 0.65};
\node at (4.5,4.5) {\tiny 0.78};

\node at (0.5,3.5) {\tiny 0.82};
\node at (1.5,3.5) {\tiny 1.00};
\node at (2.5,3.5) {\tiny 0.75};
\node at (3.5,3.5) {\tiny 0.70};
\node at (4.5,3.5) {\tiny 0.68};

\node at (0.5,2.5) {\tiny 0.71};
\node at (1.5,2.5) {\tiny 0.75};
\node at (2.5,2.5) {\tiny 1.00};
\node at (3.5,2.5) {\tiny 0.80};
\node at (4.5,2.5) {\tiny 0.62};

\node at (0.5,1.5) {\tiny 0.65};
\node at (1.5,1.5) {\tiny 0.70};
\node at (2.5,1.5) {\tiny 0.80};
\node at (3.5,1.5) {\tiny 1.00};
\node at (4.5,1.5) {\tiny 0.55};

\node at (0.5,0.5) {\tiny 0.78};
\node at (1.5,0.5) {\tiny 0.68};
\node at (2.5,0.5) {\tiny 0.62};
\node at (3.5,0.5) {\tiny 0.55};
\node at (4.5,0.5) {\tiny 1.00};

% Color scale
\begin{scope}[xshift=7cm, yshift=1cm]
    \foreach \y/\val/\col in {0/0.5/green!30, 0.5/0.6/green!40, 1/0.7/green!50, 1.5/0.8/green!60, 2/0.9/green!70, 2.5/1.0/green!80!black} {
        \fill[\col] (0,\y) rectangle (0.5,\y+0.5);
        \node[right] at (0.6, \y+0.25) {\tiny \val};
    }
    \draw (0,0) rectangle (0.5,3);
    \node[above] at (0.25,3.1) {\tiny Correlación};
\end{scope}
\end{tikzpicture}
\caption{Ejemplo de heatmap de correlación entre 5 empresas}
\end{figure}

\subsection{Fundamento Teórico}

\begin{teoria}[Correlación en Finanzas]
La correlación de Pearson entre dos activos $i$ y $j$ mide la relación lineal entre sus rendimientos:
\begin{equation}
    \rho_{ij} = \frac{\text{Cov}(R_i, R_j)}{\sigma_i \sigma_j} = \frac{\sum_{t=1}^{n}(R_{i,t} - \bar{R}_i)(R_{j,t} - \bar{R}_j)}{\sqrt{\sum(R_{i,t} - \bar{R}_i)^2} \sqrt{\sum(R_{j,t} - \bar{R}_j)^2}}
\end{equation}

\textbf{Interpretación:}
\begin{itemize}
    \item $\rho = 1$: Correlación positiva perfecta
    \item $\rho = 0$: Sin correlación lineal
    \item $\rho = -1$: Correlación negativa perfecta
\end{itemize}

En el contexto de portafolios, la correlación es crucial para la diversificación. Según Markowitz (1952), combinar activos con baja correlación reduce el riesgo total del portafolio.
\end{teoria}

\subsection{Implementación}

\begin{lstlisting}[caption={Matriz de correlacion entre empresas}, label={lst:corr_matrix}]
# ============================================
# CELDA: Matriz de Correlacion entre Empresas
# ============================================

# 1. Pivotear el panel para tener empresas como columnas
# pivot_table reorganiza los datos: filas=fechas, columnas=empresas, valores=retornos
returns_wide = panel_df.pivot_table(
    index="Date",           # Las fechas seran el indice (filas)
    columns="Company",      # Las empresas seran las columnas
    values="Return"         # Los valores seran los retornos
)

print("Dimensiones del DataFrame pivoteado:")
print(f"  Filas (meses): {returns_wide.shape[0]}")
print(f"  Columnas (empresas): {returns_wide.shape[1]}")
print(returns_wide.head())

# 2. Calcular matriz de correlacion
# .corr() calcula correlacion de Pearson entre todas las columnas
corr_matrix = returns_wide.corr()

# 3. Visualizar como heatmap
plt.figure(figsize=(16, 14))

# sns.heatmap crea un mapa de calor
# annot=True muestra los valores numericos en cada celda
# fmt=".2f" formatea a 2 decimales
# cmap="RdYlGn" usa escala de colores rojo-amarillo-verde
# center=0 centra la escala de colores en 0
sns.heatmap(
    corr_matrix,
    annot=True,              # Mostrar valores numericos
    fmt=".2f",               # Formato de 2 decimales
    cmap="RdYlGn",           # Paleta de colores
    center=0,                # Centrar colores en 0
    square=True,             # Celdas cuadradas
    linewidths=0.5,          # Grosor de lineas entre celdas
    cbar_kws={"shrink": 0.8} # Reducir tamano de barra de colores
)

plt.title("Matriz de Correlacion de Retornos entre Empresas\n(Periodo 2018-2024)", 
          fontsize=14, fontweight='bold')
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig("../data/processed/correlation_heatmap.png", dpi=150, bbox_inches='tight')
plt.show()

# 4. Identificar pares mas y menos correlacionados
# Convertir matriz a formato largo (cada par una fila)
corr_pairs = corr_matrix.unstack()  # Convierte matriz a Series con MultiIndex
corr_pairs = corr_pairs[corr_pairs.index.get_level_values(0) < 
                        corr_pairs.index.get_level_values(1)]  # Evitar duplicados

print("\n=== TOP 10 PARES MAS CORRELACIONADOS ===")
print(corr_pairs.sort_values(ascending=False).head(10))

print("\n=== TOP 10 PARES MENOS CORRELACIONADOS ===")
print(corr_pairs.sort_values(ascending=True).head(10))
\end{lstlisting}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.8]
    % Ejemplo simplificado de heatmap
    \foreach \x in {0,1,2,3,4} {
        \foreach \y in {0,1,2,3,4} {
            \pgfmathsetmacro{\val}{0.3 + 0.5*rand}
            \pgfmathsetmacro{\r}{min(1, max(0, 0.5 + \val))}
            \pgfmathsetmacro{\g}{min(1, max(0, 1 - abs(\val - 0.5)))}
            \fill[fill=green!\g!red!\r] (\x, \y) rectangle (\x+1, \y+1);
        }
    }
    % Diagonal (correlacion = 1)
    \foreach \x in {0,1,2,3,4} {
        \fill[fill=green!80!black] (\x, 4-\x) rectangle (\x+1, 5-\x);
    }
    % Labels
    \node at (0.5, -0.3) {\tiny AAPL};
    \node at (1.5, -0.3) {\tiny MSFT};
    \node at (2.5, -0.3) {\tiny GOOGL};
    \node at (3.5, -0.3) {\tiny AMZN};
    \node at (4.5, -0.3) {\tiny NVDA};
    
    \node at (-0.3, 4.5) {\tiny AAPL};
    \node at (-0.3, 3.5) {\tiny MSFT};
    \node at (-0.3, 2.5) {\tiny GOOGL};
    \node at (-0.3, 1.5) {\tiny AMZN};
    \node at (-0.3, 0.5) {\tiny NVDA};
\end{tikzpicture}
\caption{Ejemplo de heatmap de correlación (esquemático)}
\end{figure}

% ============================================
% MEJORA 3: SERIES TEMPORALES COMPARATIVAS
% ============================================
\section{Mejora 3: Series Temporales Comparativas}

\subsection{¿Qué es una Serie Temporal?}

\begin{definicion}[Serie Temporal]
Una \textbf{serie temporal} es una secuencia de observaciones ordenadas en el tiempo. Cada observación $y_t$ está asociada a un momento específico $t$.

\textbf{Ejemplos:}
\begin{itemize}
    \item Precio de cierre diario de Apple: $P_1, P_2, P_3, \ldots, P_T$
    \item Temperatura mensual en La Habana
    \item Ventas trimestrales de una empresa
\end{itemize}

\textbf{Notación:} $\{y_t\}_{t=1}^{T}$ donde $T$ es el número total de observaciones.
\end{definicion}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=14cm, height=6cm,
    xlabel={Tiempo (meses)},
    ylabel={Precio (\$)},
    title={Ejemplo de Serie Temporal: Precio de una Acción},
    grid=major,
    xmin=0, xmax=25,
    ymin=0, ymax=200,
    legend pos=north west
]
\addplot[thick, blue, mark=*, mark size=1.5pt] coordinates {
    (1,100) (2,105) (3,102) (4,110) (5,108) (6,115) (7,120) (8,118)
    (9,125) (10,122) (11,130) (12,135) (13,140) (14,138) (15,145)
    (16,150) (17,148) (18,155) (19,160) (20,158) (21,165) (22,170) (23,175) (24,180)
};
\addlegendentry{Precio observado}

% Trend line
\addplot[thick, red, dashed, domain=0:25] {95 + 3.5*x};
\addlegendentry{Tendencia}
\end{axis}
\end{tikzpicture}
\caption{Una serie temporal muestra cómo evoluciona una variable en el tiempo}
\end{figure}

\subsection{Componentes de una Serie Temporal}

\begin{teoria}[Descomposición de Series Temporales]
Toda serie temporal puede descomponerse en componentes:

\begin{equation}
    y_t = T_t + S_t + C_t + \epsilon_t
\end{equation}

donde:
\begin{itemize}
    \item $T_t$ = \textbf{Tendencia}: Movimiento de largo plazo (crecimiento o decrecimiento)
    \item $S_t$ = \textbf{Estacionalidad}: Patrones que se repiten en períodos fijos (ej: ventas altas en diciembre)
    \item $C_t$ = \textbf{Ciclo}: Fluctuaciones de mediano plazo (ciclos económicos)
    \item $\epsilon_t$ = \textbf{Ruido/Error}: Variación aleatoria no explicada
\end{itemize}
\end{teoria}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.8]
% Tendencia
\begin{scope}[yshift=6cm]
    \draw[->] (0,0) -- (10,0) node[right] {\tiny t};
    \draw[->] (0,0) -- (0,2) node[above] {\tiny $T_t$};
    \draw[thick, blue] (0,0.5) -- (9,1.8);
    \node[left] at (0,1) {\small Tendencia};
\end{scope}

% Estacionalidad
\begin{scope}[yshift=3.5cm]
    \draw[->] (0,0) -- (10,0) node[right] {\tiny t};
    \draw[->] (0,0) -- (0,2) node[above] {\tiny $S_t$};
    \draw[thick, green!60!black, domain=0:9, samples=50] plot (\x, {0.8 + 0.5*sin(\x*120)});
    \node[left] at (0,1) {\small Estacionalidad};
\end{scope}

% Ruido
\begin{scope}[yshift=1cm]
    \draw[->] (0,0) -- (10,0) node[right] {\tiny t};
    \draw[->] (0,0) -- (0,2) node[above] {\tiny $\epsilon_t$};
    \draw[thick, red] (0,1) -- (0.5,1.3) -- (1,0.7) -- (1.5,1.2) -- (2,0.8) -- 
                       (2.5,1.1) -- (3,0.9) -- (3.5,1.4) -- (4,0.6) -- (4.5,1.1) --
                       (5,0.9) -- (5.5,1.3) -- (6,0.7) -- (6.5,1.0) -- (7,1.2) --
                       (7.5,0.8) -- (8,1.1) -- (8.5,0.9) -- (9,1.0);
    \node[left] at (0,1) {\small Ruido};
\end{scope}

% Plus signs
\node at (10.5, 7) {\Large +};
\node at (10.5, 4.5) {\Large +};
\node at (10.5, 2) {\Large =};

% Result
\begin{scope}[xshift=11.5cm, yshift=3.5cm]
    \draw[->] (0,0) -- (10,0) node[right] {\tiny t};
    \draw[->] (0,0) -- (0,3) node[above] {\tiny $y_t$};
    \draw[thick, purple, domain=0:9, samples=50] 
        plot (\x, {0.5 + 0.15*\x + 0.5*sin(\x*120) + 0.2*rand});
    \node[left] at (0,1.5) {\small Serie};
    \node[left] at (0,1) {\small Observada};
\end{scope}
\end{tikzpicture}
\caption{Descomposición de una serie temporal en sus componentes}
\end{figure}

\subsection{¿Por Qué Normalizar los Precios?}

\begin{definicion}[Normalización Base 100]
Para comparar empresas con precios muy diferentes, \textbf{normalizamos} a una base común (usualmente 100):

\begin{equation}
    P_t^{norm} = \frac{P_t}{P_1} \times 100
\end{equation}

donde $P_1$ es el precio en el primer período.

\textbf{Interpretación:} Si $P_t^{norm} = 250$, significa que la acción ha crecido 150\% desde el inicio.
\end{definicion}

\begin{ejemplo}[¿Por qué es necesario normalizar?]
Supongamos que queremos comparar:
\begin{itemize}
    \item Apple: Precio inicial \$42, precio final \$180
    \item Nvidia: Precio inicial \$58, precio final \$500
\end{itemize}

Sin normalizar, Nvidia ``parece'' haber subido más (\$442 vs \$138).

Con normalización:
\begin{itemize}
    \item Apple: $\frac{180}{42} \times 100 = 429$ (creció 329\%)
    \item Nvidia: $\frac{500}{58} \times 100 = 862$ (creció 762\%)
\end{itemize}

Ahora podemos comparar \textbf{rendimientos porcentuales} correctamente.
\end{ejemplo}

\begin{figure}[H]
\centering
\begin{tikzpicture}
% Sin normalizar
\begin{scope}[xshift=0cm]
\begin{axis}[
    width=7cm, height=5cm,
    title={\small Sin Normalizar},
    xlabel={\tiny Tiempo},
    ylabel={\tiny Precio (\$)},
    legend pos=north west,
    ymin=0, ymax=550
]
\addplot[thick, blue] coordinates {(0,42) (1,50) (2,65) (3,80) (4,100) (5,140) (6,180)};
\addplot[thick, red] coordinates {(0,58) (1,80) (2,120) (3,200) (4,300) (5,400) (6,500)};
\legend{\tiny AAPL, \tiny NVDA}
\end{axis}
\end{scope}

% Con normalizar
\begin{scope}[xshift=8cm]
\begin{axis}[
    width=7cm, height=5cm,
    title={\small Normalizado (Base 100)},
    xlabel={\tiny Tiempo},
    ylabel={\tiny Índice},
    legend pos=north west,
    ymin=0, ymax=1000
]
\addplot[thick, blue] coordinates {(0,100) (1,119) (2,155) (3,190) (4,238) (5,333) (6,429)};
\addplot[thick, red] coordinates {(0,100) (1,138) (2,207) (3,345) (4,517) (5,690) (6,862)};
\legend{\tiny AAPL, \tiny NVDA}
\end{axis}
\end{scope}
\end{tikzpicture}
\caption{La normalización permite comparar rendimientos de acciones con precios diferentes}
\end{figure}

\begin{libro}[Referencias sobre Series Temporales]
\textbf{Box, G.E.P., Jenkins, G.M. \& Reinsel, G.C. (2015). \textit{Time Series Analysis: Forecasting and Control}. 5th Edition. Wiley.}

El libro clásico de Box-Jenkins. Introduce modelos ARIMA y metodologías para análisis y pronóstico de series temporales.

\textbf{Hyndman, R.J. \& Athanasopoulos, G. (2021). \textit{Forecasting: Principles and Practice}. 3rd Edition.}

Libro moderno y gratuito en: \url{https://otexts.com/fpp3/}
\end{libro}

\subsection{Fundamento Teórico}

\begin{teoria}[Análisis de Series Temporales Financieras]
Las series temporales financieras tienen características únicas:
\begin{itemize}
    \item \textbf{No estacionariedad}: Los precios tienden a crecer (tendencia)
    \item \textbf{Volatility clustering}: Períodos de alta volatilidad seguidos de más volatilidad
    \item \textbf{Colas pesadas}: Más eventos extremos que una distribución normal
    \item \textbf{Asimetría}: Las caídas suelen ser más bruscas que las subidas
\end{itemize}

Según \textit{Tsay (2010), ``Analysis of Financial Time Series''}, es esencial visualizar múltiples series normalizadas para comparar su comportamiento relativo.
\end{teoria}

\subsection{Implementación}

\begin{lstlisting}[caption={Series temporales normalizadas}, label={lst:series_norm}]
# ============================================
# CELDA: Series Temporales Comparativas
# ============================================

# Seleccionar empresas representativas (FAANG + otras)
empresas_top = ["Apple", "Microsoft", "Alphabet", "Amazon", 
                "Meta Platforms", "Nvidia", "Tesla"]

# Filtrar el panel para estas empresas
df_top = panel_df[panel_df["Company"].isin(empresas_top)].copy()

# Pivotear para tener precios por empresa
precios = df_top.pivot_table(
    index="Date",
    columns="Company", 
    values="AdjClose"
)

# Normalizar precios a base 100 (primer dia = 100)
# Esto permite comparar rendimientos relativos
# Formula: precio_normalizado = (precio / precio_inicial) * 100
precios_norm = (precios / precios.iloc[0]) * 100

# Graficar
plt.figure(figsize=(14, 8))

for empresa in precios_norm.columns:
    plt.plot(precios_norm.index, precios_norm[empresa], 
             label=empresa, linewidth=1.5)

# Linea horizontal en 100 (valor inicial)
plt.axhline(y=100, color='gray', linestyle='--', alpha=0.5)

# Marcar eventos importantes
# COVID-19 crash: Marzo 2020
plt.axvline(pd.Timestamp('2020-03-01'), color='red', 
            linestyle=':', alpha=0.7, label='COVID Crash')
# Tech selloff: Inicio 2022
plt.axvline(pd.Timestamp('2022-01-01'), color='orange', 
            linestyle=':', alpha=0.7, label='Tech Selloff 2022')

plt.title("Evolucion de Precios Normalizados (Base 100)\nEmpresas Tecnologicas Lideres 2018-2024",
          fontsize=14, fontweight='bold')
plt.xlabel("Fecha")
plt.ylabel("Precio Normalizado (Inicio = 100)")
plt.legend(loc='upper left', fontsize=9)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig("../data/processed/series_normalizadas.png", dpi=150)
plt.show()

# Calcular rendimiento total del periodo
rendimiento_total = ((precios.iloc[-1] / precios.iloc[0]) - 1) * 100
print("\n=== RENDIMIENTO TOTAL DEL PERIODO (%) ===")
print(rendimiento_total.sort_values(ascending=False).round(1))
\end{lstlisting}

% ============================================
% MEJORA 4: ROLLING STATISTICS
% ============================================
\section{Mejora 4: Estadísticos Móviles (Rolling Statistics)}

\subsection{¿Qué son los Estadísticos Móviles?}

\begin{definicion}[Estadístico Móvil (Rolling Statistic)]
Un \textbf{estadístico móvil} calcula una métrica (media, desviación estándar, etc.) sobre una \textbf{ventana deslizante} de $k$ observaciones consecutivas.

\textbf{Idea:} En vez de calcular UN solo valor para todos los datos, calculamos MUCHOS valores, uno para cada posición de la ventana.
\end{definicion}

\begin{figure}[H]
\centering
\begin{tikzpicture}[scale=0.9]
% Data points
\foreach \x/\y in {1/3, 2/5, 3/4, 4/6, 5/7, 6/5, 7/8, 8/6, 9/9, 10/7, 11/10, 12/8} {
    \fill[blue] (\x, \y/2) circle (3pt);
    \node[below, font=\tiny] at (\x, \y/2 - 0.3) {\y};
}

% Window 1
\draw[thick, red, rounded corners] (0.5, 0.5) rectangle (3.5, 4.5);
\node[red, above] at (2, 4.6) {\small Ventana 1};
\node[red, below] at (2, 0.3) {\tiny Media = (3+5+4)/3 = 4.0};

% Window 2
\draw[thick, orange, rounded corners, dashed] (1.5, 0.5) rectangle (4.5, 4.5);

% Window 3
\draw[thick, green!60!black, rounded corners, dotted] (2.5, 0.5) rectangle (5.5, 4.5);

% Arrow showing movement
\draw[->, thick, purple] (2, -0.5) -- (4, -0.5);
\node[purple, below] at (3, -0.7) {\small La ventana se desliza};

% Axis
\draw[->] (0, 0) -- (13, 0) node[right] {Tiempo};
\draw[->] (0, 0) -- (0, 5.5) node[above] {Valor};
\end{tikzpicture}
\caption{Una ventana de tamaño 3 se desliza sobre los datos, calculando la media en cada posición}
\end{figure}

\subsection{Media Móvil (Moving Average)}

\begin{teoria}[Media Móvil Simple (SMA)]
La \textbf{Media Móvil Simple} de $k$ períodos en el momento $t$ es:

\begin{equation}
    SMA_t^{(k)} = \frac{1}{k} \sum_{i=0}^{k-1} y_{t-i} = \frac{y_t + y_{t-1} + \cdots + y_{t-k+1}}{k}
\end{equation}

\textbf{Ejemplo con $k=3$:}
\begin{itemize}
    \item $SMA_3 = \frac{y_1 + y_2 + y_3}{3}$
    \item $SMA_4 = \frac{y_2 + y_3 + y_4}{3}$
    \item $SMA_5 = \frac{y_3 + y_4 + y_5}{3}$
\end{itemize}

\textbf{Propósito:} Suavizar la serie, eliminar ruido y revelar tendencias.
\end{teoria}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=14cm, height=6cm,
    xlabel={Mes},
    ylabel={Retorno (\%)},
    title={Retornos Mensuales vs Media Móvil de 6 Meses},
    grid=major,
    legend pos=north east,
    ymin=-15, ymax=20
]
% Raw returns (noisy)
\addplot[thick, blue!50, mark=none] coordinates {
    (1,5) (2,-3) (3,8) (4,2) (5,-5) (6,10) (7,3) (8,-2) (9,7) (10,4)
    (11,-4) (12,12) (13,6) (14,-1) (15,9) (16,2) (17,-6) (18,11)
    (19,4) (20,-3) (21,8) (22,5) (23,-2) (24,10)
};
\addlegendentry{Retornos mensuales}

% 6-month moving average (smoother)
\addplot[thick, red, mark=none] coordinates {
    (6,2.8) (7,2.5) (8,2.7) (9,2.5) (10,3.5) (11,2.7) (12,3.3)
    (13,3.8) (14,3.5) (15,4.3) (16,4.5) (17,3.7) (18,3.3)
    (19,3.5) (20,2.0) (21,2.3) (22,3.2) (23,3.7) (24,3.7)
};
\addlegendentry{Media móvil 6 meses}

% Highlight smoothing effect
\draw[<->, thick, green!60!black] (axis cs:12, 12) -- (axis cs:12, 3.3);
\node[right, green!60!black, font=\tiny] at (axis cs:12.2, 7.5) {La MA suaviza};
\end{axis}
\end{tikzpicture}
\caption{La media móvil (rojo) suaviza los retornos ruidosos (azul)}
\end{figure}

\subsection{Volatilidad Móvil (Rolling Volatility)}

\begin{teoria}[Volatilidad Móvil]
La \textbf{volatilidad móvil} de $k$ períodos es la desviación estándar calculada sobre una ventana deslizante:

\begin{equation}
    \sigma_t^{(k)} = \sqrt{\frac{1}{k-1} \sum_{i=0}^{k-1} (r_{t-i} - \bar{r}_t^{(k)})^2}
\end{equation}

donde $\bar{r}_t^{(k)}$ es la media móvil de retornos.

\textbf{¿Por qué es importante?}
\begin{itemize}
    \item La volatilidad NO es constante en el tiempo
    \item Hay períodos de alta volatilidad (crisis) y baja volatilidad (calma)
    \item Esto se conoce como \textbf{volatility clustering}
\end{itemize}
\end{teoria}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=14cm, height=6cm,
    xlabel={Fecha},
    ylabel={Volatilidad Móvil 12m},
    title={Volatilidad Clustering: Períodos de Alta y Baja Volatilidad},
    grid=major,
    xmin=0, xmax=80,
    ymin=0, ymax=0.15
]
% Simulated rolling volatility with clusters
\addplot[thick, blue, fill=blue!20, fill opacity=0.5] coordinates {
    (1,0.03) (5,0.035) (10,0.04) (15,0.038) (20,0.042) (25,0.045)
    (26,0.08) (27,0.12) (28,0.11) (29,0.10) (30,0.095) (31,0.085) (32,0.075)
    (35,0.06) (40,0.05) (45,0.045) (50,0.04) (55,0.038)
    (60,0.035) (65,0.032) (70,0.03) (75,0.028) (80,0.03)
} \closedcycle;

% Annotations
\node[above, font=\small] at (axis cs:29, 0.12) {Crisis (COVID)};
\draw[<-, thick] (axis cs:29, 0.115) -- (axis cs:35, 0.13);
\node[above, font=\small] at (axis cs:50, 0.055) {Período Calmo};
\end{axis}
\end{tikzpicture}
\caption{La volatilidad no es constante: se agrupa en períodos de alta y baja volatilidad}
\end{figure}

\begin{libro}[Referencia sobre Volatility Clustering]
\textbf{Engle, R.F. (1982). ``Autoregressive Conditional Heteroskedasticity with Estimates of the Variance of UK Inflation''. \textit{Econometrica}, 50, 987-1007.}

Robert Engle introdujo los modelos ARCH para capturar el volatility clustering. Ganó el Premio Nobel de Economía en 2003.

\textbf{Bollerslev, T. (1986). ``Generalized Autoregressive Conditional Heteroskedasticity''. \textit{Journal of Econometrics}, 31, 307-327.}

Introduce el modelo GARCH, extensión del ARCH que es el estándar actual para modelar volatilidad.
\end{libro}

\subsection{Fundamento Teórico}

\begin{teoria}[Media y Volatilidad Móvil]
Los estadísticos móviles (rolling) calculan una métrica sobre una ventana deslizante de $k$ observaciones:

\textbf{Media móvil de $k$ períodos:}
\begin{equation}
    \bar{r}_t^{(k)} = \frac{1}{k} \sum_{i=0}^{k-1} r_{t-i}
\end{equation}

\textbf{Volatilidad móvil de $k$ períodos:}
\begin{equation}
    \sigma_t^{(k)} = \sqrt{\frac{1}{k-1} \sum_{i=0}^{k-1} (r_{t-i} - \bar{r}_t^{(k)})^2}
\end{equation}

Estos indicadores son fundamentales para:
\begin{itemize}
    \item Detectar cambios en tendencia
    \item Identificar regímenes de volatilidad
    \item Suavizar ruido en los datos
\end{itemize}
\end{teoria}

\subsection{Implementación}

\begin{lstlisting}[caption={Estadisticos moviles}, label={lst:rolling}]
# ============================================
# CELDA: Rolling Mean y Rolling Volatility
# ============================================

# Configurar ventanas de analisis
VENTANA_CORTA = 6   # 6 meses
VENTANA_LARGA = 12  # 12 meses (1 anio)

# Seleccionar una empresa para analisis detallado
empresa = "Nvidia"
df_emp = panel_df[panel_df["Company"] == empresa].copy()
df_emp = df_emp.set_index("Date").sort_index()

# Calcular estadisticos moviles
# .rolling(window) crea una ventana deslizante
# .mean() y .std() calculan sobre esa ventana
df_emp["RollingMean_6m"] = df_emp["Return"].rolling(window=VENTANA_CORTA).mean()
df_emp["RollingMean_12m"] = df_emp["Return"].rolling(window=VENTANA_LARGA).mean()
df_emp["RollingVol_6m"] = df_emp["Return"].rolling(window=VENTANA_CORTA).std()
df_emp["RollingVol_12m"] = df_emp["Return"].rolling(window=VENTANA_LARGA).std()

# Visualizar
fig, axes = plt.subplots(3, 1, figsize=(14, 12), sharex=True)

# Panel 1: Retornos con medias moviles
axes[0].bar(df_emp.index, df_emp["Return"], alpha=0.4, label="Retorno mensual", width=20)
axes[0].plot(df_emp.index, df_emp["RollingMean_6m"], 'b-', 
             linewidth=2, label=f"Media movil {VENTANA_CORTA}m")
axes[0].plot(df_emp.index, df_emp["RollingMean_12m"], 'r-', 
             linewidth=2, label=f"Media movil {VENTANA_LARGA}m")
axes[0].axhline(y=0, color='gray', linestyle='--')
axes[0].set_ylabel("Retorno")
axes[0].set_title(f"Retornos y Medias Moviles - {empresa}")
axes[0].legend(loc='upper right')
axes[0].grid(True, alpha=0.3)

# Panel 2: Volatilidad movil
axes[1].fill_between(df_emp.index, 0, df_emp["RollingVol_6m"], 
                     alpha=0.3, label=f"Vol {VENTANA_CORTA}m")
axes[1].plot(df_emp.index, df_emp["RollingVol_12m"], 'r-', 
             linewidth=2, label=f"Vol {VENTANA_LARGA}m")
axes[1].set_ylabel("Volatilidad")
axes[1].set_title(f"Volatilidad Movil - {empresa}")
axes[1].legend(loc='upper right')
axes[1].grid(True, alpha=0.3)

# Panel 3: Precio
axes[2].plot(df_emp.index, df_emp["AdjClose"], 'g-', linewidth=1.5)
axes[2].set_ylabel("Precio ($)")
axes[2].set_xlabel("Fecha")
axes[2].set_title(f"Evolucion del Precio - {empresa}")
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(f"../data/processed/rolling_stats_{empresa.lower()}.png", dpi=150)
plt.show()
\end{lstlisting}

% ============================================
% MEJORA 5: ANÁLISIS DE DISTRIBUCIÓN
% ============================================
\section{Mejora 5: Análisis Detallado de Distribución}

\subsection{¿Qué es una Distribución de Probabilidad?}

\begin{definicion}[Distribución de Probabilidad]
Una \textbf{distribución de probabilidad} describe cómo se reparten los valores de una variable aleatoria. Nos dice qué valores son más probables y cuáles son menos probables.

Para variables continuas (como los retornos), usamos la \textbf{función de densidad de probabilidad (PDF)}.
\end{definicion}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=12cm, height=6cm,
    domain=-4:4,
    samples=100,
    xlabel={Valor},
    ylabel={Densidad de probabilidad},
    title={Distribución Normal Estándar},
    grid=major,
    ymin=0, ymax=0.45,
    area style
]
\addplot[thick, blue, fill=blue!20] {exp(-x^2/2)/sqrt(2*pi)} \closedcycle;

% Annotations
\draw[<->, thick, red] (axis cs:-1, 0.24) -- (axis cs:1, 0.24);
\node[above, red, font=\small] at (axis cs:0, 0.26) {68\% de los datos};

\draw[<->, thick, orange] (axis cs:-2, 0.05) -- (axis cs:2, 0.05);
\node[below, orange, font=\small] at (axis cs:0, 0.03) {95\% de los datos};
\end{axis}

% Labels for sigma
\node at (4.2, 1.5) {\small $-\sigma$};
\node at (7.8, 1.5) {\small $+\sigma$};
\node at (2.2, 0.5) {\small $-2\sigma$};
\node at (9.8, 0.5) {\small $+2\sigma$};
\end{tikzpicture}
\caption{La distribución normal: la mayoría de los datos está cerca de la media}
\end{figure}

\subsection{Los Cuatro Momentos de una Distribución}

\begin{teoria}[Los Momentos Estadísticos]
Una distribución se caracteriza por sus \textbf{momentos}:

\begin{enumerate}
    \item \textbf{Primer Momento - Media ($\mu$):} El centro de la distribución
    \begin{equation}
        \mu = E[X] = \frac{1}{n}\sum_{i=1}^{n} x_i
    \end{equation}
    
    \item \textbf{Segundo Momento - Varianza ($\sigma^2$):} La dispersión alrededor de la media
    \begin{equation}
        \sigma^2 = E[(X-\mu)^2] = \frac{1}{n-1}\sum_{i=1}^{n} (x_i - \bar{x})^2
    \end{equation}
    
    \item \textbf{Tercer Momento - Asimetría (Skewness):} La ``inclinación'' de la distribución
    \begin{equation}
        \gamma_1 = E\left[\left(\frac{X-\mu}{\sigma}\right)^3\right]
    \end{equation}
    
    \item \textbf{Cuarto Momento - Curtosis:} El ``peso'' de las colas
    \begin{equation}
        \gamma_2 = E\left[\left(\frac{X-\mu}{\sigma}\right)^4\right] - 3
    \end{equation}
\end{enumerate}
\end{teoria}

\subsection{Asimetría (Skewness): ¿Hacia Dónde se Inclina?}

\begin{definicion}[Asimetría / Skewness]
La \textbf{asimetría} mide cuán simétrica es una distribución respecto a su media.

\begin{itemize}
    \item $\gamma_1 = 0$: Distribución \textbf{simétrica} (como la normal)
    \item $\gamma_1 > 0$: \textbf{Sesgo positivo} - cola derecha más larga
    \item $\gamma_1 < 0$: \textbf{Sesgo negativo} - cola izquierda más larga
\end{itemize}
\end{definicion}

\begin{figure}[H]
\centering
\begin{tikzpicture}
% Negative skew
\begin{scope}[xshift=0cm]
\begin{axis}[
    width=5cm, height=4cm,
    title={\small Sesgo Negativo ($\gamma_1 < 0$)},
    ticks=none,
    ymin=0
]
\addplot[thick, blue, fill=blue!20, domain=0:10, samples=50] 
    {x^3 * exp(-x) / 6} \closedcycle;
\draw[<-, thick, red] (axis cs:2, 0.2) -- (axis cs:0.5, 0.3);
\node[red, font=\tiny] at (axis cs:1.5, 0.35) {Cola larga};
\end{axis}
\end{scope}

% Symmetric
\begin{scope}[xshift=5cm]
\begin{axis}[
    width=5cm, height=4cm,
    title={\small Simétrica ($\gamma_1 = 0$)},
    ticks=none,
    domain=-3:3,
    ymin=0
]
\addplot[thick, blue, fill=blue!20, samples=50] 
    {exp(-x^2/2)/sqrt(2*pi)} \closedcycle;
\end{axis}
\end{scope}

% Positive skew
\begin{scope}[xshift=10cm]
\begin{axis}[
    width=5cm, height=4cm,
    title={\small Sesgo Positivo ($\gamma_1 > 0$)},
    ticks=none,
    ymin=0,
    xmin=0, xmax=10
]
\addplot[thick, blue, fill=blue!20, domain=0:10, samples=50] 
    {2*x * exp(-x^2/4) / 4} \closedcycle;
\draw[->, thick, red] (axis cs:4, 0.15) -- (axis cs:7, 0.05);
\node[red, font=\tiny] at (axis cs:5.5, 0.22) {Cola larga};
\end{axis}
\end{scope}
\end{tikzpicture}
\caption{Tres tipos de asimetría en distribuciones}
\end{figure}

\begin{importante}[Asimetría en Finanzas]
Los retornos financieros suelen tener \textbf{sesgo negativo}: las caídas bruscas (crashes) son más comunes que las subidas equivalentes. Esto significa que:
\begin{itemize}
    \item Los eventos negativos extremos son más frecuentes
    \item El riesgo de pérdida es mayor de lo que sugiere la media
    \item La distribución normal SUBESTIMA el riesgo de pérdidas grandes
\end{itemize}
\end{importante}

\subsection{Curtosis: ¿Cuán ``Pesadas'' son las Colas?}

\begin{definicion}[Curtosis y Exceso de Curtosis]
La \textbf{curtosis} mide el peso de las colas de una distribución. Usamos el \textbf{exceso de curtosis} (curtosis - 3) para comparar con la distribución normal:

\begin{itemize}
    \item $\gamma_2 = 0$: \textbf{Mesocúrtica} (colas como la normal)
    \item $\gamma_2 > 0$: \textbf{Leptocúrtica} (colas más pesadas, más eventos extremos)
    \item $\gamma_2 < 0$: \textbf{Platicúrtica} (colas más livianas, menos eventos extremos)
\end{itemize}
\end{definicion}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=14cm, height=7cm,
    domain=-5:5,
    samples=100,
    xlabel={Valor},
    ylabel={Densidad},
    title={Comparación de Curtosis},
    legend pos=north east,
    ymin=0, ymax=0.5
]
% Normal (mesokurtic)
\addplot[thick, blue] {exp(-x^2/2)/sqrt(2*pi)};
\addlegendentry{Normal ($\gamma_2=0$)}

% Leptokurtic (heavy tails) - t-distribution with low df
\addplot[thick, red] {0.375 / (1 + x^2/3)^2};
\addlegendentry{Leptocúrtica ($\gamma_2>0$)}

% Platykurtic (light tails) - uniform-ish
\addplot[thick, green!60!black] {0.35 * exp(-abs(x)/1.5)};
\addlegendentry{Platicúrtica ($\gamma_2<0$)}

% Highlight tails
\draw[<-, thick, red] (axis cs:3.5, 0.02) -- (axis cs:4.5, 0.08);
\node[red, font=\small] at (axis cs:4.5, 0.12) {Colas pesadas};
\end{axis}
\end{tikzpicture}
\caption{La curtosis mide la probabilidad de eventos extremos (peso de las colas)}
\end{figure}

\begin{importante}[Curtosis en Finanzas]
Los retornos financieros típicamente tienen \textbf{exceso de curtosis positivo} (leptocúrtica). Esto significa:
\begin{itemize}
    \item Más eventos extremos de lo que predice la distribución normal
    \item Los ``cisnes negros'' (Black Swans) son más frecuentes
    \item Los modelos que asumen normalidad SUBESTIMAN el riesgo
\end{itemize}

\textbf{Ejemplo:} El crash del ``Lunes Negro'' (1987) de -22\% sería un evento de más de 20 desviaciones estándar bajo normalidad (probabilidad prácticamente cero), pero ocurrió.
\end{importante}

\subsection{Test de Jarque-Bera: ¿Los Datos son Normales?}

\begin{teoria}[Test de Jarque-Bera (1987)]
El test de \textbf{Jarque-Bera} evalúa si los datos provienen de una distribución normal, combinando asimetría y curtosis:

\begin{equation}
    JB = \frac{n}{6}\left(S^2 + \frac{(K-3)^2}{4}\right)
\end{equation}

donde:
\begin{itemize}
    \item $n$ = número de observaciones
    \item $S$ = asimetría muestral
    \item $K$ = curtosis muestral
\end{itemize}

Bajo la hipótesis nula ($H_0$: los datos son normales), $JB \sim \chi^2(2)$.

\textbf{Regla de decisión:}
\begin{itemize}
    \item Si $p$-valor $< 0.05$: Rechazamos normalidad
    \item Si $p$-valor $\geq 0.05$: No rechazamos normalidad
\end{itemize}
\end{teoria}

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=1cm,
    box/.style={rectangle, draw, fill=blue!10, text width=3.5cm, text centered, rounded corners, minimum height=1.5cm, font=\small}
]
\node (data) [box] {Datos de retornos};
\node (calc) [box, right=of data] {Calcular $S$ y $K$};
\node (jb) [box, right=of calc] {Calcular $JB$};
\node (pval) [box, right=of jb] {Obtener $p$-valor};

\node (normal) [box, below left=1.5cm and 0.5cm of pval, fill=green!20] {$p \geq 0.05$\\No rechazar $H_0$\\(Posible normalidad)};
\node (nonormal) [box, below right=1.5cm and 0.5cm of pval, fill=red!20] {$p < 0.05$\\Rechazar $H_0$\\(No es normal)};

\draw[->, thick] (data) -- (calc);
\draw[->, thick] (calc) -- (jb);
\draw[->, thick] (jb) -- (pval);
\draw[->, thick] (pval) -- (normal);
\draw[->, thick] (pval) -- (nonormal);
\end{tikzpicture}
\caption{Flujo del test de Jarque-Bera para evaluar normalidad}
\end{figure}

\begin{libro}[Referencias sobre Distribuciones]
\textbf{Casella, G. \& Berger, R.L. (2002). \textit{Statistical Inference}. 2nd Edition. Duxbury.}

Libro clásico de inferencia estadística. Cubre distribuciones, momentos, y tests de hipótesis con rigor matemático.

\textbf{Cont, R. (2001). ``Empirical Properties of Asset Returns: Stylized Facts and Statistical Issues''. \textit{Quantitative Finance}, 1, 223-236.}

Artículo que documenta los ``hechos estilizados'' de los retornos financieros: colas pesadas, asimetría, volatility clustering, etc.
\end{libro}

\subsection{Fundamento Teórico}

\begin{teoria}[Momentos de una Distribución]
Una distribución se caracteriza por sus momentos:

\textbf{1. Media (1er momento):} $\mu = E[X]$

\textbf{2. Varianza (2do momento):} $\sigma^2 = E[(X-\mu)^2]$

\textbf{3. Asimetría (Skewness, 3er momento):}
\begin{equation}
    \gamma_1 = E\left[\left(\frac{X-\mu}{\sigma}\right)^3\right]
\end{equation}
\begin{itemize}
    \item $\gamma_1 = 0$: Distribución simétrica
    \item $\gamma_1 > 0$: Cola derecha más larga (sesgo positivo)
    \item $\gamma_1 < 0$: Cola izquierda más larga (sesgo negativo)
\end{itemize}

\textbf{4. Curtosis (4to momento):}
\begin{equation}
    \gamma_2 = E\left[\left(\frac{X-\mu}{\sigma}\right)^4\right] - 3
\end{equation}
\begin{itemize}
    \item $\gamma_2 = 0$: Curtosis igual a la normal (mesocúrtica)
    \item $\gamma_2 > 0$: Colas más pesadas que la normal (leptocúrtica)
    \item $\gamma_2 < 0$: Colas más livianas que la normal (platicúrtica)
\end{itemize}

Los rendimientos financieros típicamente tienen curtosis positiva (exceso de curtosis), lo que significa más eventos extremos de lo esperado bajo normalidad.
\end{teoria}

\subsection{Implementación}

\begin{lstlisting}[caption={Analisis de momentos de la distribucion}, label={lst:moments}]
# ============================================
# CELDA: Analisis de Asimetria y Curtosis
# ============================================
from scipy.stats import skew, kurtosis, jarque_bera

# Calcular momentos para cada empresa
moments_list = []

for company in panel_df["Company"].unique():
    returns = panel_df[panel_df["Company"] == company]["Return"].dropna()
    
    # Calcular estadisticos
    # skew(): asimetria (sesgo)
    # kurtosis(): exceso de curtosis (kurtosis - 3)
    # jarque_bera(): test de normalidad
    jb_stat, jb_pval = jarque_bera(returns)
    
    moments_list.append({
        "Company": company,
        "N": len(returns),
        "Mean": returns.mean(),
        "Std": returns.std(),
        "Skewness": skew(returns),      # Asimetria
        "Kurtosis": kurtosis(returns),  # Exceso de curtosis
        "JB_stat": jb_stat,             # Estadistico Jarque-Bera
        "JB_pval": jb_pval,             # p-valor del test
        "Normal": "Si" if jb_pval > 0.05 else "No"  # Decision
    })

moments_df = pd.DataFrame(moments_list)

# Ordenar por curtosis (mayor a menor)
moments_df = moments_df.sort_values("Kurtosis", ascending=False)

print("=== ANALISIS DE MOMENTOS POR EMPRESA ===")
print(moments_df.to_string(index=False))

# Visualizacion
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Grafico de asimetria vs curtosis
scatter = axes[0].scatter(
    moments_df["Skewness"], 
    moments_df["Kurtosis"],
    c=moments_df["Std"],     # Color segun volatilidad
    s=100,
    cmap="viridis",
    alpha=0.7
)
axes[0].axhline(y=0, color='red', linestyle='--', alpha=0.5, label='Curtosis Normal')
axes[0].axvline(x=0, color='red', linestyle='--', alpha=0.5, label='Asimetria=0')
axes[0].set_xlabel("Asimetria (Skewness)")
axes[0].set_ylabel("Exceso de Curtosis")
axes[0].set_title("Asimetria vs Curtosis por Empresa")
plt.colorbar(scatter, ax=axes[0], label="Volatilidad")

# Histograma comparativo: datos vs normal teorica
returns_all = panel_df["Return"].dropna()
x = np.linspace(returns_all.min(), returns_all.max(), 100)
normal_pdf = stats.norm.pdf(x, returns_all.mean(), returns_all.std())

axes[1].hist(returns_all, bins=50, density=True, alpha=0.7, 
             label="Datos reales", edgecolor='black')
axes[1].plot(x, normal_pdf, 'r-', linewidth=2, label="Normal teorica")
axes[1].set_xlabel("Retorno")
axes[1].set_ylabel("Densidad")
axes[1].set_title("Distribucion Real vs Normal Teorica")
axes[1].legend()

plt.tight_layout()
plt.savefig("../data/processed/distribution_analysis.png", dpi=150)
plt.show()
\end{lstlisting}

\begin{teoria}[Test de Jarque-Bera]
El test de Jarque-Bera evalúa si los datos provienen de una distribución normal:
\begin{equation}
    JB = \frac{n}{6}\left(S^2 + \frac{(K-3)^2}{4}\right)
\end{equation}
donde $S$ es la asimetría y $K$ es la curtosis.

Bajo $H_0$ (normalidad), $JB \sim \chi^2(2)$.

\textbf{Decisión:} Si $p < 0.05$, rechazamos normalidad.
\end{teoria}

% ============================================
% MEJORA 6: DRAWDOWN ANALYSIS
% ============================================
\section{Mejora 6: Análisis de Drawdown (Caídas Máximas)}

\subsection{¿Qué es un Drawdown?}

\begin{definicion}[Drawdown]
El \textbf{drawdown} es la caída porcentual desde un máximo histórico hasta el punto más bajo antes de alcanzar un nuevo máximo.

Matemáticamente, el drawdown en el momento $t$ es:
\begin{equation}
    DD_t = \frac{P_t - \max_{s \leq t} P_s}{\max_{s \leq t} P_s}
\end{equation}

donde $\max_{s \leq t} P_s$ es el precio máximo observado hasta el momento $t$.

\textbf{Nota:} El drawdown siempre es $\leq 0$ (o cero si estamos en un máximo).
\end{definicion}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=14cm, height=7cm,
    xlabel={Tiempo},
    ylabel={Precio (\$)},
    title={Visualización de Drawdown},
    grid=major,
    ymin=0, ymax=180,
    legend pos=north west
]
% Price series
\addplot[thick, blue, name path=price] coordinates {
    (0,100) (5,110) (10,130) (15,150) (20,145) (25,120) (30,100) 
    (35,90) (40,110) (45,140) (50,160) (55,170) (60,155) (65,165) (70,175)
};
\addlegendentry{Precio}

% Running maximum
\addplot[thick, red, dashed, name path=max] coordinates {
    (0,100) (5,110) (10,130) (15,150) (20,150) (25,150) (30,150) 
    (35,150) (40,150) (45,150) (50,160) (55,170) (60,170) (65,170) (70,175)
};
\addlegendentry{Máximo acumulado}

% Fill drawdown area
\addplot[fill=red, fill opacity=0.2] fill between[of=max and price, soft clip={domain=15:50}];

% Annotations
\draw[<->, thick, green!60!black] (axis cs:35, 90) -- (axis cs:35, 150);
\node[right, green!60!black, font=\small] at (axis cs:35.5, 120) {DD = -40\%};

\node[above, font=\small] at (axis cs:15, 152) {Máximo};
\node[below, font=\small] at (axis cs:35, 88) {Mínimo (trough)};

\end{axis}
\end{tikzpicture}
\caption{El drawdown mide la caída desde el máximo (área roja sombreada)}
\end{figure}

\subsection{Maximum Drawdown (MDD): La Peor Caída}

\begin{definicion}[Maximum Drawdown]
El \textbf{Maximum Drawdown (MDD)} es el mayor drawdown observado en todo el período:

\begin{equation}
    MDD = \min_{t \in [1,T]} DD_t
\end{equation}

Es el \textbf{peor escenario} que un inversionista habría experimentado si hubiera comprado en el peor momento posible.
\end{definicion}

\begin{ejemplo}[Interpretación del Maximum Drawdown]
Si el MDD de Tesla es -65\%, significa que:
\begin{itemize}
    \item En algún momento, Tesla cayó 65\% desde su máximo
    \item Un inversionista que compró en el pico perdió 65\% de su inversión
    \item Para recuperarse, Tesla necesitó subir $\frac{65}{100-65} = 186\%$
\end{itemize}

\textbf{Fórmula de recuperación:} Si pierdes $x\%$, necesitas ganar $\frac{x}{100-x} \times 100\%$ para recuperarte.
\end{ejemplo}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=12cm, height=5cm,
    xlabel={Pérdida (\%)},
    ylabel={Ganancia Necesaria (\%)},
    title={Ganancia Necesaria para Recuperarse de una Pérdida},
    grid=major,
    xmin=0, xmax=90,
    ymin=0, ymax=1000,
    xtick={0,10,20,30,40,50,60,70,80,90}
]
\addplot[thick, red, domain=1:89, samples=50] {100*x/(100-x)};

% Annotations
\addplot[only marks, mark=*, blue, mark size=3pt] coordinates {
    (10, 11.1) (20, 25) (30, 42.9) (50, 100) (75, 300)
};
\node[above right, font=\tiny] at (axis cs:10, 11) {-10\% $\to$ +11\%};
\node[above right, font=\tiny] at (axis cs:50, 100) {-50\% $\to$ +100\%};
\node[above right, font=\tiny] at (axis cs:75, 300) {-75\% $\to$ +300\%};
\end{axis}
\end{tikzpicture}
\caption{Las pérdidas grandes requieren ganancias desproporcionadamente mayores para recuperarse}
\end{figure}

\subsection{¿Por Qué es Importante el Drawdown?}

\begin{teoria}[Importancia del Análisis de Drawdown]
El drawdown es una métrica de riesgo crucial porque:

\begin{enumerate}
    \item \textbf{Mide el riesgo real percibido}: La volatilidad es abstracta, pero ver tu portafolio caer 50\% es muy concreto.
    
    \item \textbf{Afecta el comportamiento del inversionista}: Muchos venden en pánico durante drawdowns grandes, realizando pérdidas.
    
    \item \textbf{Captura el riesgo de cola}: A diferencia de la volatilidad, el MDD se enfoca en eventos extremos.
    
    \item \textbf{No es simétrico}: La recuperación de pérdidas es asimétrica (perder 50\% requiere ganar 100\%).
\end{enumerate}
\end{teoria}

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=1.5cm,
    box/.style={rectangle, draw, text width=3cm, text centered, rounded corners, minimum height=1.5cm, font=\small}
]
\node (dd) [box, fill=red!20] {Drawdown Grande\\(-40\%)};
\node (panic) [box, fill=orange!20, right=of dd] {Pánico\\Venta en pérdida};
\node (loss) [box, fill=red!40, right=of panic] {Pérdida\\Realizada};
\node (miss) [box, fill=gray!20, right=of loss] {Pierde la\\Recuperación};

\draw[->, thick] (dd) -- (panic);
\draw[->, thick] (panic) -- (loss);
\draw[->, thick] (loss) -- (miss);

\node[below=0.5cm of panic, text width=6cm, text centered, font=\small\itshape] 
    {El drawdown no solo afecta el valor del portafolio, sino también la psicología del inversionista};
\end{tikzpicture}
\caption{El ciclo del drawdown: cómo las caídas grandes llevan a malas decisiones}
\end{figure}

\begin{libro}[Referencias sobre Drawdown y Riesgo]
\textbf{Magdon-Ismail, M. \& Atiya, A. (2004). ``Maximum Drawdown''. \textit{Risk Magazine}.}

Artículo técnico sobre la distribución estadística del Maximum Drawdown.

\textbf{Taleb, N.N. (2007). \textit{The Black Swan: The Impact of the Highly Improbable}. Random House.}

Libro sobre eventos extremos (``cisnes negros'') y por qué los modelos tradicionales subestiman el riesgo de cola.
\end{libro}

\subsection{Fundamento Teórico}

\begin{teoria}[Drawdown y Maximum Drawdown]
El \textbf{drawdown} en el momento $t$ mide la caída desde el máximo histórico hasta ese punto:
\begin{equation}
    DD_t = \frac{P_t - \max_{s \leq t} P_s}{\max_{s \leq t} P_s}
\end{equation}

El \textbf{Maximum Drawdown (MDD)} es la mayor caída observada:
\begin{equation}
    MDD = \min_t DD_t
\end{equation}

Esta métrica es crucial para:
\begin{itemize}
    \item Evaluar el peor escenario histórico
    \item Medir la recuperación necesaria
    \item Comparar riesgo entre activos
\end{itemize}

\textbf{Nota importante:} Si un activo cae 50\%, necesita subir 100\% para recuperarse.
\end{teoria}

\subsection{Implementación}

\begin{lstlisting}[caption={Analisis de Drawdown}, label={lst:drawdown}]
# ============================================
# CELDA: Analisis de Drawdown
# ============================================

def calcular_drawdown(precios):
    """
    Calcula la serie de drawdown para una serie de precios.
    
    Parametros:
    -----------
    precios : pd.Series
        Serie temporal de precios
    
    Retorna:
    --------
    pd.Series : Serie de drawdowns (valores negativos o cero)
    """
    # Maximo acumulado hasta cada punto
    # cummax() retorna el maximo visto hasta ese momento
    max_acumulado = precios.cummax()
    
    # Drawdown: diferencia porcentual respecto al maximo
    drawdown = (precios - max_acumulado) / max_acumulado
    
    return drawdown

# Calcular drawdown para cada empresa
drawdown_stats = []

for company in panel_df["Company"].unique():
    df_emp = panel_df[panel_df["Company"] == company].sort_values("Date")
    precios = df_emp["AdjClose"]
    
    dd = calcular_drawdown(precios)
    
    drawdown_stats.append({
        "Company": company,
        "Max_Drawdown": dd.min(),  # Peor caida (valor mas negativo)
        "Avg_Drawdown": dd.mean(), # Drawdown promedio
        "Time_Underwater": (dd < 0).sum(),  # Meses bajo el maximo
    })

dd_df = pd.DataFrame(drawdown_stats).sort_values("Max_Drawdown")

print("=== MAXIMUM DRAWDOWN POR EMPRESA ===")
print(dd_df.to_string(index=False))

# Visualizar drawdown de empresas seleccionadas
empresas_plot = ["Tesla", "Nvidia", "Apple", "Microsoft"]
fig, axes = plt.subplots(len(empresas_plot), 1, figsize=(14, 12), sharex=True)

for ax, empresa in zip(axes, empresas_plot):
    df_emp = panel_df[panel_df["Company"] == empresa].sort_values("Date")
    df_emp = df_emp.set_index("Date")
    
    dd = calcular_drawdown(df_emp["AdjClose"])
    
    # Rellenar area de drawdown
    ax.fill_between(dd.index, dd.values, 0, 
                    where=(dd < 0), 
                    color='red', alpha=0.4)
    ax.plot(dd.index, dd.values, 'r-', linewidth=0.5)
    ax.axhline(y=0, color='black', linewidth=0.5)
    
    # Marcar el punto de maximo drawdown
    min_idx = dd.idxmin()
    min_val = dd.min()
    ax.scatter([min_idx], [min_val], color='darkred', s=100, zorder=5)
    ax.annotate(f'MDD: {min_val:.1%}', 
                xy=(min_idx, min_val), 
                xytext=(10, 10),
                textcoords='offset points',
                fontsize=10, fontweight='bold')
    
    ax.set_ylabel("Drawdown")
    ax.set_title(f"{empresa} - Maximum Drawdown: {min_val:.1%}")
    ax.set_ylim(min(dd) * 1.1, 0.05)
    ax.grid(True, alpha=0.3)

plt.xlabel("Fecha")
plt.tight_layout()
plt.savefig("../data/processed/drawdown_analysis.png", dpi=150)
plt.show()
\end{lstlisting}

% ============================================
% MEJORA 7: RENDIMIENTOS ACUMULADOS
% ============================================
\section{Mejora 7: Rendimientos Acumulados}

\subsection{¿Qué es el Rendimiento Acumulado?}

\begin{definicion}[Rendimiento Acumulado]
El \textbf{rendimiento acumulado} es la ganancia o pérdida total desde el inicio del período hasta un momento dado. Responde a la pregunta: ``Si invertí \$100 al inicio, ¿cuánto tengo ahora?''
\end{definicion}

\subsection{Dos Tipos de Rendimientos: Simple vs Logarítmico}

\begin{teoria}[Rendimientos Simples vs Logarítmicos]
Existen dos formas de calcular rendimientos:

\textbf{1. Rendimiento Simple (Aritmético):}
\begin{equation}
    R_t = \frac{P_t - P_{t-1}}{P_{t-1}} = \frac{P_t}{P_{t-1}} - 1
\end{equation}

\textbf{2. Rendimiento Logarítmico (Continuo):}
\begin{equation}
    r_t = \ln\left(\frac{P_t}{P_{t-1}}\right) = \ln(P_t) - \ln(P_{t-1})
\end{equation}

\textbf{¿Cuál usar?}
\begin{itemize}
    \item \textbf{Simples}: Más intuitivos (``gané 5\%'')
    \item \textbf{Logarítmicos}: Se suman fácilmente, tienen mejores propiedades estadísticas
\end{itemize}
\end{teoria}

\begin{figure}[H]
\centering
\begin{tikzpicture}
% Simple returns
\begin{scope}[xshift=0cm]
\node[draw, rectangle, fill=blue!10, minimum width=4cm, minimum height=2cm] at (0,0) {
    \begin{tabular}{c}
        \textbf{Rendimiento Simple} \\[0.2cm]
        $R_t = \frac{P_t - P_{t-1}}{P_{t-1}}$
    \end{tabular}
};
\node[below, text width=4cm, text centered, font=\small] at (0,-1.5) {
    Se \textbf{multiplican} para acumular:\\
    $(1+R_1)(1+R_2)(1+R_3) - 1$
};
\end{scope}

% Log returns
\begin{scope}[xshift=7cm]
\node[draw, rectangle, fill=green!10, minimum width=4cm, minimum height=2cm] at (0,0) {
    \begin{tabular}{c}
        \textbf{Rendimiento Log} \\[0.2cm]
        $r_t = \ln\left(\frac{P_t}{P_{t-1}}\right)$
    \end{tabular}
};
\node[below, text width=4cm, text centered, font=\small] at (0,-1.5) {
    Se \textbf{suman} para acumular:\\
    $r_1 + r_2 + r_3$
};
\end{scope}

% Arrow
\draw[<->, thick, purple] (2.5, 0) -- (4.5, 0);
\node[above, purple, font=\small] at (3.5, 0.1) {Convertir};
\node[below, purple, font=\tiny] at (3.5, -0.1) {$r = \ln(1+R)$};
\end{tikzpicture}
\caption{Diferencia entre rendimientos simples y logarítmicos}
\end{figure}

\subsection{Cálculo del Rendimiento Acumulado}

\begin{teoria}[Fórmulas de Rendimiento Acumulado]
\textbf{Método 1 - Usando rendimientos simples:}
\begin{equation}
    R_{acum} = \prod_{t=1}^{T}(1 + R_t) - 1 = (1+R_1)(1+R_2)\cdots(1+R_T) - 1
\end{equation}

\textbf{Método 2 - Usando rendimientos logarítmicos:}
\begin{equation}
    r_{acum} = \sum_{t=1}^{T} r_t = r_1 + r_2 + \cdots + r_T
\end{equation}

Para convertir de log-acumulado a simple: $R_{acum} = e^{r_{acum}} - 1$
\end{teoria}

\begin{ejemplo}[Cálculo Paso a Paso]
Supongamos 3 meses con rendimientos simples: $R_1 = 5\%$, $R_2 = -3\%$, $R_3 = 8\%$

\textbf{Método 1 (productos):}
\begin{align*}
    R_{acum} &= (1 + 0.05)(1 - 0.03)(1 + 0.08) - 1 \\
    &= (1.05)(0.97)(1.08) - 1 \\
    &= 1.1003 - 1 = 0.1003 = \textbf{10.03\%}
\end{align*}

\textbf{Método 2 (sumas de logs):}
\begin{align*}
    r_1 &= \ln(1.05) = 0.0488 \\
    r_2 &= \ln(0.97) = -0.0305 \\
    r_3 &= \ln(1.08) = 0.0770 \\
    r_{acum} &= 0.0488 - 0.0305 + 0.0770 = 0.0953 \\
    R_{acum} &= e^{0.0953} - 1 = \textbf{10.00\%}
\end{align*}

(La pequeña diferencia es por aproximación)
\end{ejemplo}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=14cm, height=7cm,
    xlabel={Fecha},
    ylabel={Rendimiento Acumulado (\%)},
    title={Rendimiento Acumulado de Acciones Tecnológicas (2018-2024)},
    grid=major,
    legend pos=outer north east,
    ymin=-50, ymax=800
]
% Simulated cumulative returns
\addplot[thick, purple] coordinates {
    (0,0) (12,20) (24,50) (36,80) (48,200) (60,400) (72,700)
};
\addlegendentry{NVDA (+700\%)}

\addplot[thick, blue] coordinates {
    (0,0) (12,15) (24,40) (36,100) (48,180) (60,250) (72,320)
};
\addlegendentry{AAPL (+320\%)}

\addplot[thick, green!60!black] coordinates {
    (0,0) (12,25) (24,60) (36,90) (48,120) (60,180) (72,280)
};
\addlegendentry{MSFT (+280\%)}

\addplot[thick, red] coordinates {
    (0,0) (12,30) (24,80) (36,200) (48,100) (60,50) (72,150)
};
\addlegendentry{TSLA (+150\%)}

% Reference line at 0
\addplot[thick, black, dashed] coordinates {(0,0) (72,0)};

% Annotation
\draw[<-, thick] (axis cs:48, 200) -- (axis cs:52, 280);
\node[above, font=\small] at (axis cs:55, 290) {COVID Rally};
\end{axis}
\end{tikzpicture}
\caption{Los rendimientos acumulados muestran el crecimiento total desde el inicio}
\end{figure}

\begin{libro}[Referencia sobre Rendimientos]
\textbf{Hull, J.C. (2018). \textit{Options, Futures, and Other Derivatives}. 10th Edition. Pearson.}

El libro estándar sobre derivados financieros. El Capítulo 15 cubre el cálculo de rendimientos y la diferencia entre discreto y continuo.

\textbf{Campbell, J.Y., Lo, A.W. \& MacKinlay, A.C. (1997). \textit{The Econometrics of Financial Markets}. Princeton.}

Tratamiento riguroso de retornos, distribuciones, y modelado econométrico.
\end{libro}

\subsection{Fundamento Teórico}

\begin{teoria}[Rendimiento Acumulado]
El rendimiento acumulado hasta el período $T$ se calcula como:

\textbf{Método 1 - Producto de (1 + retornos simples):}
\begin{equation}
    R_{acum} = \prod_{t=1}^{T}(1 + R_t) - 1
\end{equation}

\textbf{Método 2 - Suma de retornos logarítmicos:}
\begin{equation}
    r_{acum} = \sum_{t=1}^{T} r_t \quad \Rightarrow \quad R_{acum} = e^{r_{acum}} - 1
\end{equation}

En Python, usamos \texttt{.cumsum()} para la suma acumulada de retornos logarítmicos.
\end{teoria}

\subsection{Implementación}

\begin{lstlisting}[caption={Rendimientos acumulados}, label={lst:cumret}]
# ============================================
# CELDA: Rendimientos Acumulados
# ============================================

# Pivotear retornos
returns_wide = panel_df.pivot_table(
    index="Date", 
    columns="Company", 
    values="Return"
)

# Calcular rendimiento acumulado
# cumsum() suma acumulada de retornos logaritmicos
# exp() convierte a rendimiento simple: e^(sum(log_returns)) - 1
cumulative_returns = (np.exp(returns_wide.cumsum()) - 1) * 100  # En porcentaje

# Seleccionar empresas para graficar
top_empresas = ["Nvidia", "Apple", "Microsoft", "Tesla", "Amazon", "Meta Platforms"]

plt.figure(figsize=(14, 8))

for empresa in top_empresas:
    if empresa in cumulative_returns.columns:
        plt.plot(cumulative_returns.index, cumulative_returns[empresa], 
                 label=empresa, linewidth=2)

plt.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
plt.title("Rendimiento Acumulado (%)\nDesde Enero 2018", fontsize=14, fontweight='bold')
plt.xlabel("Fecha")
plt.ylabel("Rendimiento Acumulado (%)")
plt.legend(loc='upper left')
plt.grid(True, alpha=0.3)

# Anotar rendimiento final
for empresa in top_empresas:
    if empresa in cumulative_returns.columns:
        final_ret = cumulative_returns[empresa].iloc[-1]
        plt.annotate(f'{final_ret:.0f}%', 
                     xy=(cumulative_returns.index[-1], final_ret),
                     xytext=(5, 0), textcoords='offset points',
                     fontsize=9, fontweight='bold')

plt.tight_layout()
plt.savefig("../data/processed/cumulative_returns.png", dpi=150)
plt.show()
\end{lstlisting}

% ============================================
% MEJORA 8: ANÁLISIS POR PERÍODOS
% ============================================
\section{Mejora 8: Análisis por Períodos (Pre/Post COVID)}

\subsection{¿Qué es el Análisis de Régimen?}

\begin{definicion}[Régimen de Mercado]
Un \textbf{régimen de mercado} es un período caracterizado por un comportamiento estadístico particular. Los mercados pueden operar en diferentes regímenes:

\begin{itemize}
    \item \textbf{Régimen alcista (Bull market)}: Tendencia ascendente, baja volatilidad
    \item \textbf{Régimen bajista (Bear market)}: Tendencia descendente, alta volatilidad
    \item \textbf{Régimen de crisis}: Volatilidad extrema, correlaciones cambiantes
    \item \textbf{Régimen de recuperación}: Volatilidad decreciente, tendencia alcista
\end{itemize}
\end{definicion}

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=14cm, height=6cm,
    xlabel={Tiempo},
    ylabel={Precio del Mercado},
    title={Diferentes Regímenes de Mercado},
    grid=major,
    ymin=80, ymax=200,
    xmin=0, xmax=100,
    xtick={0,20,40,60,80,100},
    xticklabels={2018, 2019, 2020, 2021, 2022, 2024}
]
\addplot[thick, blue] coordinates {
    (0,100) (5,105) (10,115) (15,125) (20,135) (25,145) (30,150)
    (35,130) (37,100) (40,95) (43,110) (46,130) (50,160) (55,175) (60,185)
    (65,170) (70,155) (75,140) (80,145) (85,155) (90,165) (95,175) (100,180)
};

% Regime annotations
\fill[green!20, opacity=0.5] (axis cs:0,80) rectangle (axis cs:30,200);
\fill[red!20, opacity=0.5] (axis cs:30,80) rectangle (axis cs:43,200);
\fill[blue!20, opacity=0.5] (axis cs:43,80) rectangle (axis cs:60,200);
\fill[orange!20, opacity=0.5] (axis cs:60,80) rectangle (axis cs:80,200);
\fill[green!10, opacity=0.5] (axis cs:80,80) rectangle (axis cs:100,200);

% Labels
\node[font=\small] at (axis cs:15, 190) {Bull Market};
\node[font=\small, red] at (axis cs:36, 190) {Crisis};
\node[font=\small, blue] at (axis cs:51, 190) {Recuperación};
\node[font=\small, orange] at (axis cs:70, 190) {Corrección};
\node[font=\small] at (axis cs:90, 190) {Estable};

% COVID marker
\draw[<-, thick, red] (axis cs:37, 100) -- (axis cs:42, 85);
\node[red, font=\small] at (axis cs:45, 85) {COVID};
\end{axis}
\end{tikzpicture}
\caption{Los mercados pasan por diferentes regímenes con características estadísticas distintas}
\end{figure}

\subsection{¿Por Qué Comparar Períodos?}

\begin{teoria}[Importancia del Análisis por Períodos]
Comparar estadísticos entre períodos nos permite:

\begin{enumerate}
    \item \textbf{Detectar cambios estructurales}: ¿Cambió el comportamiento del mercado después de un evento?
    
    \item \textbf{Evaluar el impacto de shocks}: ¿Cuánto aumentó la volatilidad durante la crisis?
    
    \item \textbf{Identificar nuevas correlaciones}: ¿Las empresas se correlacionaron más durante la crisis?
    
    \item \textbf{Medir la recuperación}: ¿Se normalizaron los parámetros después del shock?
\end{enumerate}
\end{teoria}

\subsection{El Caso COVID-19}

\begin{importante}[COVID-19 como Experimento Natural]
La pandemia de COVID-19 (marzo 2020) fue un shock exógeno que permite estudiar:

\begin{itemize}
    \item \textbf{Pre-COVID (2018-Feb 2020)}: Mercado ``normal''
    \item \textbf{Crisis (Mar-Abr 2020)}: Caída extrema (-34\% en S\&P 500)
    \item \textbf{Post-COVID (May 2020-2024)}: Recuperación y ``nueva normalidad''
\end{itemize}

Comparar estos períodos revela cómo cambiaron:
\begin{itemize}
    \item Retornos medios
    \item Volatilidad
    \item Correlaciones entre activos
    \item Comportamiento sectorial
\end{itemize}
\end{importante}

\begin{figure}[H]
\centering
\begin{tikzpicture}
% Timeline
\draw[thick, ->] (0,0) -- (14,0);

% Periods
\fill[green!20] (0,-0.5) rectangle (5,0.5);
\fill[red!30] (5,-0.5) rectangle (6,0.5);
\fill[blue!20] (6,-0.5) rectangle (14,0.5);

% Labels
\node[above] at (2.5, 0.6) {\small Pre-COVID};
\node[above] at (5.5, 0.6) {\small Crisis};
\node[above] at (10, 0.6) {\small Post-COVID};

% Dates
\node[below] at (0, -0.6) {\small 2018};
\node[below] at (5, -0.6) {\small Mar 2020};
\node[below] at (6, -0.6) {\small May 2020};
\node[below] at (14, -0.6) {\small 2024};

% Statistics boxes
\begin{scope}[yshift=-2.5cm]
\node[draw, rectangle, fill=green!10, minimum width=3cm, minimum height=1.5cm] at (2.5, 0) {
    \begin{tabular}{c}
        $\bar{r} = 1.2\%$ \\
        $\sigma = 4.5\%$
    \end{tabular}
};
\node[draw, rectangle, fill=red!10, minimum width=1.5cm, minimum height=1.5cm] at (5.5, 0) {
    \begin{tabular}{c}
        $\bar{r} = -15\%$ \\
        $\sigma = 25\%$
    \end{tabular}
};
\node[draw, rectangle, fill=blue!10, minimum width=5cm, minimum height=1.5cm] at (10, 0) {
    \begin{tabular}{c}
        $\bar{r} = 1.8\%$ \\
        $\sigma = 6.2\%$
    \end{tabular}
};
\end{scope}
\end{tikzpicture}
\caption{Comparación de estadísticos en diferentes períodos}
\end{figure}

\subsection{Tests Estadísticos para Comparar Períodos}

\begin{teoria}[Tests de Comparación]
Para comparar períodos estadísticamente, podemos usar:

\textbf{1. Test t de dos muestras} (para comparar medias):
\begin{equation}
    t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
\end{equation}

$H_0$: Las medias son iguales ($\mu_1 = \mu_2$)

\textbf{2. Test F de Levene} (para comparar varianzas):

Evalúa si las varianzas son iguales: $H_0: \sigma_1^2 = \sigma_2^2$

\textbf{3. Test de Chow} (para detectar cambio estructural):

Evalúa si los parámetros de un modelo cambiaron en un punto específico.
\end{teoria}

\begin{libro}[Referencias sobre Cambios Estructurales]
\textbf{Hamilton, J.D. (1994). \textit{Time Series Analysis}. Princeton University Press.}

Capítulo 22 cubre cambios de régimen y modelos de Markov-switching para detectar cambios en series temporales.

\textbf{Bai, J. \& Perron, P. (2003). ``Computation and Analysis of Multiple Structural Change Models''. \textit{Journal of Applied Econometrics}, 18, 1-22.}

Metodología para detectar múltiples puntos de cambio estructural en series temporales.
\end{libro}

\subsection{Fundamento Teórico}

\begin{teoria}[Análisis de Régimen]
El mercado financiero opera en diferentes ``regímenes'' caracterizados por distintos niveles de volatilidad y correlación. Eventos como:
\begin{itemize}
    \item Crisis financieras
    \item Pandemias
    \item Cambios de política monetaria
\end{itemize}

Pueden cambiar fundamentalmente el comportamiento del mercado. Comparar estadísticos antes y después de estos eventos revela cambios estructurales.
\end{teoria}

\subsection{Implementación}

\begin{lstlisting}[caption={Analisis por periodos}, label={lst:periods}]
# ============================================
# CELDA: Comparacion Pre/Post COVID
# ============================================

# Definir periodos
COVID_START = pd.Timestamp("2020-03-01")

# Dividir el dataset
pre_covid = panel_df[panel_df["Date"] < COVID_START]
post_covid = panel_df[panel_df["Date"] >= COVID_START]

print(f"Periodo Pre-COVID: {pre_covid['Date'].min().date()} a {pre_covid['Date'].max().date()}")
print(f"Periodo Post-COVID: {post_covid['Date'].min().date()} a {post_covid['Date'].max().date()}")

# Calcular estadisticos por periodo
stats_comparison = []

for company in panel_df["Company"].unique():
    ret_pre = pre_covid[pre_covid["Company"] == company]["Return"].dropna()
    ret_post = post_covid[post_covid["Company"] == company]["Return"].dropna()
    
    stats_comparison.append({
        "Company": company,
        "Mean_Pre": ret_pre.mean(),
        "Mean_Post": ret_post.mean(),
        "Vol_Pre": ret_pre.std(),
        "Vol_Post": ret_post.std(),
        "Change_Mean": ret_post.mean() - ret_pre.mean(),
        "Change_Vol": ret_post.std() - ret_pre.std()
    })

stats_df = pd.DataFrame(stats_comparison)

# Visualizar cambios
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Cambio en retorno medio
colors = ['green' if x > 0 else 'red' for x in stats_df["Change_Mean"]]
axes[0].barh(stats_df["Company"], stats_df["Change_Mean"], color=colors, alpha=0.7)
axes[0].axvline(x=0, color='black', linewidth=0.5)
axes[0].set_xlabel("Cambio en Retorno Medio")
axes[0].set_title("Cambio en Retorno Medio\n(Post-COVID vs Pre-COVID)")

# Cambio en volatilidad
colors = ['red' if x > 0 else 'green' for x in stats_df["Change_Vol"]]
axes[1].barh(stats_df["Company"], stats_df["Change_Vol"], color=colors, alpha=0.7)
axes[1].axvline(x=0, color='black', linewidth=0.5)
axes[1].set_xlabel("Cambio en Volatilidad")
axes[1].set_title("Cambio en Volatilidad\n(Post-COVID vs Pre-COVID)")

plt.tight_layout()
plt.savefig("../data/processed/period_comparison.png", dpi=150)
plt.show()
\end{lstlisting}

% ============================================
% RESUMEN DE MEJORAS
% ============================================
\section{Resumen de Mejoras Propuestas}

\begin{table}[H]
\centering
\small
\begin{tabular}{|c|p{4cm}|p{8cm}|}
\hline
\textbf{\#} & \textbf{Mejora} & \textbf{Qué Revela} \\
\hline
1 & Valores Faltantes y Outliers & Calidad de datos, empresas con datos incompletos, eventos extremos \\
\hline
2 & Matriz de Correlación & Relaciones entre empresas, oportunidades de diversificación \\
\hline
3 & Series Temporales Comparativas & Rendimiento relativo, impacto de eventos de mercado \\
\hline
4 & Rolling Statistics & Cambios en tendencia y volatilidad a lo largo del tiempo \\
\hline
5 & Análisis de Distribución & Asimetría, curtosis, desviaciones de normalidad \\
\hline
6 & Drawdown Analysis & Peores escenarios, tiempo de recuperación \\
\hline
7 & Rendimientos Acumulados & Performance total del período por empresa \\
\hline
8 & Análisis por Períodos & Cambios estructurales pre/post eventos \\
\hline
\end{tabular}
\caption{Resumen de mejoras propuestas para el EDA}
\end{table}

% ============================================
% GLOSARIO DE TÉRMINOS
% ============================================
\section{Glosario de Términos Estadísticos}

\begin{longtable}{|p{4cm}|p{10cm}|}
\hline
\textbf{Término} & \textbf{Definición} \\
\hline
\endhead

Asimetría (Skewness) & Medida de cuán ``inclinada'' está una distribución. Valor 0 = simétrica. \\
\hline
Correlación & Medida de la relación lineal entre dos variables (-1 a +1). \\
\hline
Curtosis & Medida del ``peso'' de las colas de una distribución. \\
\hline
Desviación Estándar ($\sigma$) & Raíz cuadrada de la varianza. Mide la dispersión en las mismas unidades que los datos. \\
\hline
Drawdown & Caída porcentual desde un máximo histórico. \\
\hline
EDA & Exploratory Data Analysis. Proceso de examinar datos antes de modelar. \\
\hline
IQR & Interquartile Range. Diferencia entre el percentil 75 y 25. \\
\hline
Leptocúrtica & Distribución con colas más pesadas que la normal (más eventos extremos). \\
\hline
Media ($\mu$) & Promedio aritmético de los datos. \\
\hline
Mediana & Valor que divide los datos en dos mitades iguales. \\
\hline
NaN & Not a Number. Representa un valor faltante en pandas. \\
\hline
Normalidad & Propiedad de seguir una distribución normal (campana de Gauss). \\
\hline
Outlier & Valor atípico, muy alejado del resto de los datos. \\
\hline
Percentil & Valor debajo del cual cae un porcentaje de los datos. \\
\hline
Régimen & Período con características estadísticas similares. \\
\hline
Rendimiento Logarítmico & $r = \ln(P_t/P_{t-1})$. Se suma para acumular. \\
\hline
Rendimiento Simple & $R = (P_t - P_{t-1})/P_{t-1}$. Más intuitivo. \\
\hline
Rolling (Móvil) & Estadístico calculado sobre una ventana deslizante. \\
\hline
Serie Temporal & Secuencia de datos ordenados en el tiempo. \\
\hline
Varianza ($\sigma^2$) & Promedio de las desviaciones cuadradas respecto a la media. \\
\hline
Volatilidad & En finanzas, generalmente la desviación estándar de los retornos. \\
\hline
Z-score & Número de desviaciones estándar que un valor está de la media. \\
\hline
\end{longtable}

% ============================================
% DIAGRAMA DE FLUJO DEL EDA
% ============================================
\section{Flujo Completo del EDA Mejorado}

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=1.2cm,
    block/.style={rectangle, draw, fill=blue!20, text width=4cm, text centered, rounded corners, minimum height=1cm},
    arrow/.style={thick, ->, >=stealth}
]

% Nodos
\node (load) [block] {1. Cargar Datos};
\node (missing) [block, below of=load] {2. Valores Faltantes};
\node (desc) [block, below of=missing] {3. Estadísticos Descriptivos};
\node (dist) [block, below of=desc] {4. Análisis de Distribución};
\node (outliers) [block, below of=dist] {5. Detección de Outliers};

\node (corr) [block, right of=load, xshift=5cm] {6. Matriz de Correlación};
\node (series) [block, below of=corr] {7. Series Temporales};
\node (rolling) [block, below of=series] {8. Rolling Statistics};
\node (drawdown) [block, below of=rolling] {9. Drawdown Analysis};
\node (periods) [block, below of=drawdown] {10. Análisis por Períodos};

\node (conclusions) [block, fill=green!20, below of=outliers, xshift=2.5cm, yshift=-0.5cm] {Conclusiones del EDA};

% Flechas
\draw [arrow] (load) -- (missing);
\draw [arrow] (missing) -- (desc);
\draw [arrow] (desc) -- (dist);
\draw [arrow] (dist) -- (outliers);
\draw [arrow] (load) -- (corr);
\draw [arrow] (corr) -- (series);
\draw [arrow] (series) -- (rolling);
\draw [arrow] (rolling) -- (drawdown);
\draw [arrow] (drawdown) -- (periods);
\draw [arrow] (outliers) -- (conclusions);
\draw [arrow] (periods) -- (conclusions);

\end{tikzpicture}
\caption{Flujo del EDA completo}
\end{figure}

% ============================================
% REFERENCIAS
% ============================================
\section{Referencias y Recursos}

\subsection{Libros Fundamentales (Por Nivel)}

\begin{libro}[Nivel Básico - Introducción a la Estadística]
\textbf{1. Triola, M.F. (2018). \textit{Elementary Statistics}. 13th Edition. Pearson.}
\begin{itemize}
    \item Ideal para comenzar desde cero
    \item Cubre estadística descriptiva, probabilidad, inferencia
    \item Muchos ejemplos y ejercicios
\end{itemize}

\textbf{2. Diez, D.M., Cetinkaya-Rundel, M. \& Barr, C.D. (2019). \textit{OpenIntro Statistics}. 4th Edition.}
\begin{itemize}
    \item \textbf{GRATIS}: \url{https://www.openintro.org/book/os/}
    \item Excelente introducción moderna
    \item Incluye videos y recursos en línea
\end{itemize}
\end{libro}

\begin{libro}[Nivel Intermedio - Análisis de Datos]
\textbf{3. McKinney, W. (2022). \textit{Python for Data Analysis}. 3rd Edition. O'Reilly.}
\begin{itemize}
    \item Guía definitiva de pandas
    \item Escrito por el creador de pandas
    \item Muy práctico, con código ejecutable
\end{itemize}

\textbf{4. VanderPlas, J. (2016). \textit{Python Data Science Handbook}. O'Reilly.}
\begin{itemize}
    \item \textbf{GRATIS}: \url{https://jakevdp.github.io/PythonDataScienceHandbook/}
    \item Cubre NumPy, pandas, Matplotlib, Scikit-Learn
    \item Notebooks de Jupyter disponibles
\end{itemize}
\end{libro}

\begin{libro}[Nivel Avanzado - Finanzas y Series Temporales]
\textbf{5. Tsay, R.S. (2010). \textit{Analysis of Financial Time Series}. 3rd Edition. Wiley.}
\begin{itemize}
    \item LA referencia para series temporales financieras
    \item Cubre GARCH, volatilidad, VaR
    \item Nivel matemático intermedio-alto
\end{itemize}

\textbf{6. Campbell, J.Y., Lo, A.W. \& MacKinlay, A.C. (1997). \textit{The Econometrics of Financial Markets}. Princeton.}
\begin{itemize}
    \item Tratamiento riguroso de econometría financiera
    \item CAPM, eficiencia de mercados, modelado
    \item Nivel avanzado
\end{itemize}
\end{libro}

\subsection{Documentación Oficial de Librerías}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|p{6cm}|}
\hline
\textbf{Librería} & \textbf{URL} & \textbf{Uso Principal} \\
\hline
Pandas & \url{https://pandas.pydata.org/docs/} & Manipulación de datos tabulares \\
\hline
NumPy & \url{https://numpy.org/doc/} & Cálculo numérico, arrays \\
\hline
Matplotlib & \url{https://matplotlib.org/stable/} & Visualización de datos \\
\hline
Seaborn & \url{https://seaborn.pydata.org/} & Visualización estadística \\
\hline
SciPy & \url{https://docs.scipy.org/doc/scipy/} & Funciones científicas, tests \\
\hline
Statsmodels & \url{https://www.statsmodels.org/} & Modelos estadísticos, regresión \\
\hline
yfinance & \url{https://github.com/ranaroussi/yfinance} & Descarga datos de Yahoo Finance \\
\hline
\end{tabular}
\caption{Documentación oficial de librerías Python para análisis de datos}
\end{table}

\subsection{Proyectos Similares en GitHub}

\begin{enumerate}
    \item \textbf{QuantStats}: \url{https://github.com/ranaroussi/quantstats}
    \begin{itemize}
        \item Librería para análisis de portafolios
        \item Calcula Sharpe ratio, drawdown, métricas de riesgo
        \item Genera reportes HTML automáticos
    \end{itemize}
    
    \item \textbf{PyPortfolioOpt}: \url{https://github.com/robertmartin8/PyPortfolioOpt}
    \begin{itemize}
        \item Optimización de portafolios con Python
        \item Implementa Markowitz, Black-Litterman
        \item Excelente documentación
    \end{itemize}
    
    \item \textbf{ffn - Financial Functions}: \url{https://github.com/pmorissette/ffn}
    \begin{itemize}
        \item Funciones financieras para Python
        \item Cálculo de métricas de performance
        \item Análisis de series temporales financieras
    \end{itemize}
    
    \item \textbf{Stock Analysis}: \url{https://github.com/stefmolin/stock-analysis}
    \begin{itemize}
        \item Proyecto educativo de análisis de acciones
        \item Incluye notebooks con EDA completo
        \item Código bien documentado
    \end{itemize}
    
    \item \textbf{Financial-Models-Numerical-Methods}: \url{https://github.com/cantaro86/Financial-Models-Numerical-Methods}
    \begin{itemize}
        \item Modelos financieros en Python
        \item Black-Scholes, Monte Carlo, GARCH
        \item Notebooks de Jupyter con teoría y código
    \end{itemize}
\end{enumerate}

\subsection{Cursos y Tutoriales en Línea}

\begin{table}[H]
\centering
\small
\begin{tabular}{|p{4cm}|p{5cm}|p{4cm}|}
\hline
\textbf{Plataforma} & \textbf{Curso} & \textbf{Nivel} \\
\hline
Coursera & ``Python and Statistics for Financial Analysis'' (HKUST) & Intermedio \\
\hline
DataCamp & ``Introduction to Portfolio Analysis in Python'' & Intermedio \\
\hline
edX & ``Data Science: Probability'' (Harvard) & Básico \\
\hline
Kaggle Learn & ``Pandas'' y ``Data Visualization'' & Básico \\
\hline
MIT OpenCourseWare & ``Statistics for Applications'' (18.650) & Avanzado \\
\hline
YouTube & StatQuest with Josh Starmer & Básico-Intermedio \\
\hline
\end{tabular}
\caption{Recursos de aprendizaje en línea recomendados}
\end{table}

\subsection{Artículos Académicos Clave}

\begin{enumerate}
    \item \textbf{Markowitz, H. (1952)}. ``Portfolio Selection''. \textit{The Journal of Finance}, 7(1), 77-91.
    \begin{itemize}
        \item Fundamento de la teoría moderna de portafolios
        \item Introduce el concepto de diversificación óptima
    \end{itemize}
    
    \item \textbf{Sharpe, W.F. (1964)}. ``Capital Asset Prices: A Theory of Market Equilibrium''. \textit{The Journal of Finance}, 19(3), 425-442.
    \begin{itemize}
        \item Introduce el CAPM
        \item Define el concepto de beta
    \end{itemize}
    
    \item \textbf{Fama, E.F. (1970)}. ``Efficient Capital Markets: A Review''. \textit{The Journal of Finance}, 25(2), 383-417.
    \begin{itemize}
        \item Hipótesis de mercados eficientes
        \item Fundamento teórico del análisis financiero
    \end{itemize}
    
    \item \textbf{Cont, R. (2001)}. ``Empirical Properties of Asset Returns''. \textit{Quantitative Finance}, 1, 223-236.
    \begin{itemize}
        \item Documenta los ``hechos estilizados'' de retornos
        \item Colas pesadas, volatility clustering, asimetría
    \end{itemize}
\end{enumerate}

\end{document}
