{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737878aa",
   "metadata": {},
   "source": [
    "# Inference — Fase 3\n",
    "En este notebook se implementan los procedimientos de inferencia estadística planificados en la Fase 2:\n",
    "- Intervalos de confianza para media y volatilidad\n",
    "- Tests t (una muestra, dos muestras, Welch)\n",
    "- Pruebas de varianzas (Levene / F)\n",
    "- Alternativas no paramétricas\n",
    "- Bootstrap\n",
    "- Correcciones por comparaciones múltiples\n",
    "- Regresión CAPM con diagnóstico y errores robustos\n",
    "- Análisis de potencia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe14a5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Cargados: panel_df (2403, 6), agg_df (30, 7)\n"
     ]
    }
   ],
   "source": [
    "# CELDA 1\n",
    "\n",
    "# imports mejorados y comprobaciones robustas\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# En Jupyter, si quieres gráficos inline, descomenta la siguiente línea:\n",
    "# %matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.power import TTestIndPower, TTestPower\n",
    "\n",
    "# Tests/diagnósticos adicionales que usarás:\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, acorr_ljungbox, acorr_breusch_godfrey\n",
    "from statsmodels.stats.stattools import durbin_watson, jarque_bera\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "from statsmodels.stats.api import CompareMeans, DescrStatsW\n",
    "\n",
    "# Sci-kit learn para estandarización, PCA y clustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Configuración reproducible y estética\n",
    "np.random.seed(42)\n",
    "sns.set(style='whitegrid')\n",
    "warnings.filterwarnings(\"ignore\")  # opcional: silenciar warnings durante el desarrollo\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# Rutas (más robustas usando pathlib)\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "PANEL_FILE = PROCESSED_DIR / \"tech30_panel_monthly_2018_2024.csv\"\n",
    "AGG_FILE   = PROCESSED_DIR / \"tech30_aggregated_stats_2018_2024.csv\"\n",
    "\n",
    "# Mensaje claro si faltan archivos (incluye cwd para debugging)\n",
    "missing = [str(p) for p in (PANEL_FILE, AGG_FILE) if not p.exists()]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"No se encontraron los siguientes archivos:\\n  - \" + \"\\n  - \".join(missing)\n",
    "        + f\"\\n\\nWorking dir: {NOTEBOOK_DIR}\\nComprueba que la estructura 'data/processed' está en {PROJECT_ROOT}.\"\n",
    "    )\n",
    "\n",
    "# Carga de datos\n",
    "panel_df = pd.read_csv(PANEL_FILE, parse_dates=['Date'])\n",
    "agg_df = pd.read_csv(AGG_FILE)\n",
    "\n",
    "logging.info(f\"Cargados: panel_df {panel_df.shape}, agg_df {agg_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696cc66a",
   "metadata": {},
   "source": [
    "Antes de aplicar pruebas formales:\n",
    "- verificamos distribución de retornos por empresa (normalidad)\n",
    "- revisamos tamaño muestral T (~n meses por empresa)\n",
    "- revisamos si usar pruebas paramétricas o no paramétricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a97c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 2\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: intervalo t para la media\n",
    "# ------------------------------\n",
    "def ci_mean_t(x, alpha=0.05):\n",
    "    \"\"\"Retorna: mean, se, df, (ci_low, ci_high). Requiere n>=2.\"\"\"\n",
    "    x = np.asarray(x.dropna()) if hasattr(x, \"dropna\") else np.asarray(x)\n",
    "    n = len(x)\n",
    "    if n < 2:\n",
    "        raise ValueError(\"ci_mean_t: se requieren al menos 2 observaciones\")\n",
    "    mean = np.mean(x)\n",
    "    s = np.std(x, ddof=1)\n",
    "    se = s / np.sqrt(n)\n",
    "    df = n - 1\n",
    "    tval = stats.t.ppf(1 - alpha/2, df)\n",
    "    ci_low = mean - tval * se\n",
    "    ci_high = mean + tval * se\n",
    "    return mean, se, df, (ci_low, ci_high)\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: bootstrap CI para la media\n",
    "# ------------------------------\n",
    "def bootstrap_ci_mean(x, n_boot=5000, alpha=0.05, random_state=None, return_boots=False):\n",
    "    \"\"\"Bootstrap percentile CI para la media.\n",
    "    Devuelve: (mean, (lower, upper), boots?)\"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x = np.asarray(x.dropna()) if hasattr(x, \"dropna\") else np.asarray(x)\n",
    "    n = len(x)\n",
    "    if n < 1:\n",
    "        raise ValueError(\"bootstrap_ci_mean: serie vacía\")\n",
    "    boots = np.empty(n_boot)\n",
    "    for i in range(n_boot):\n",
    "        sample = rng.choice(x, size=n, replace=True)\n",
    "        boots[i] = sample.mean()\n",
    "    lower = np.percentile(boots, 100*(alpha/2))\n",
    "    upper = np.percentile(boots, 100*(1-alpha/2))\n",
    "    if return_boots:\n",
    "        return np.mean(x), (lower, upper), boots\n",
    "    return np.mean(x), (lower, upper)\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: one-sample t-test (H0: mean = mu0) con compatibilidad para alternativas\n",
    "# ------------------------------\n",
    "def one_sample_ttest(x, mu0=0.0, alternative='two-sided'):\n",
    "    \"\"\"Devuelve (statistic, pvalue). alternative in {'two-sided','larger','smaller'}.\n",
    "       Compatibilidad con versiones antiguas de scipy.\"\"\"\n",
    "    x = np.asarray(x.dropna()) if hasattr(x, \"dropna\") else np.asarray(x)\n",
    "    if len(x) < 2:\n",
    "        raise ValueError(\"one_sample_ttest: se requieren al menos 2 observaciones\")\n",
    "    res = stats.ttest_1samp(x, popmean=mu0)\n",
    "    tstat, p_two = res.statistic, res.pvalue\n",
    "    if alternative == 'two-sided':\n",
    "        return tstat, p_two\n",
    "    # one-sided\n",
    "    # ttest_1samp returns two-sided p; adjust depending on sign\n",
    "    if alternative == 'larger':  # H1: mean > mu0\n",
    "        if tstat > 0:\n",
    "            p = p_two / 2\n",
    "        else:\n",
    "            p = 1 - p_two/2\n",
    "    elif alternative == 'smaller':  # H1: mean < mu0\n",
    "        if tstat < 0:\n",
    "            p = p_two / 2\n",
    "        else:\n",
    "            p = 1 - p_two/2\n",
    "    else:\n",
    "        raise ValueError(\"alternative debe ser 'two-sided', 'larger' o 'smaller'\")\n",
    "    return tstat, p\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: welch two-sample t-test con alternativa\n",
    "# ------------------------------\n",
    "def welch_ttest(x1, x2, alternative='two-sided'):\n",
    "    \"\"\"Devuelve (statistic, pvalue).\"\"\"\n",
    "    x1 = np.asarray(x1.dropna()) if hasattr(x1, \"dropna\") else np.asarray(x1)\n",
    "    x2 = np.asarray(x2.dropna()) if hasattr(x2, \"dropna\") else np.asarray(x2)\n",
    "    if len(x1) < 1 or len(x2) < 1:\n",
    "        raise ValueError(\"welch_ttest: ambas muestras deben tener al menos 1 observación\")\n",
    "    res = stats.ttest_ind(x1, x2, equal_var=False)\n",
    "    tstat, p_two = res.statistic, res.pvalue\n",
    "    if alternative == 'two-sided':\n",
    "        return tstat, p_two\n",
    "    if alternative == 'larger':\n",
    "        if tstat > 0:\n",
    "            p = p_two / 2\n",
    "        else:\n",
    "            p = 1 - p_two/2\n",
    "    elif alternative == 'smaller':\n",
    "        if tstat < 0:\n",
    "            p = p_two / 2\n",
    "        else:\n",
    "            p = 1 - p_two/2\n",
    "    else:\n",
    "        raise ValueError(\"alternative debe ser 'two-sided', 'larger' o 'smaller'\")\n",
    "    return tstat, p\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: levene test for equal variances\n",
    "# ------------------------------\n",
    "def levene_test(x1, x2, center='median'):\n",
    "    x1 = np.asarray(x1.dropna()) if hasattr(x1, \"dropna\") else np.asarray(x1)\n",
    "    x2 = np.asarray(x2.dropna()) if hasattr(x2, \"dropna\") else np.asarray(x2)\n",
    "    if len(x1) < 2 or len(x2) < 2:\n",
    "        raise ValueError(\"levenes_test: ambas muestras deben tener al menos 2 observaciones\")\n",
    "    return stats.levene(x1, x2, center=center)\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: mann-whitney U test\n",
    "# ------------------------------\n",
    "def mannwhitney_test(x1, x2):\n",
    "    x1 = np.asarray(x1.dropna()) if hasattr(x1, \"dropna\") else np.asarray(x1)\n",
    "    x2 = np.asarray(x2.dropna()) if hasattr(x2, \"dropna\") else np.asarray(x2)\n",
    "    if len(x1) < 1 or len(x2) < 1:\n",
    "        raise ValueError(\"mannwhitney_test: muestras vacías\")\n",
    "    return stats.mannwhitneyu(x1, x2, alternative='two-sided')\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: permutation test for difference of means (two-sided)\n",
    "# ------------------------------\n",
    "def permutation_test_diff_means(x1, x2, n_perm=5000, random_state=None, return_null_dist=False):\n",
    "    \"\"\"Permutation test exacto / aproximado para diff de medias.\n",
    "       Devuelve: obs_diff, p_value [, null_dist]\"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x1 = np.asarray(x1.dropna()) if hasattr(x1, \"dropna\") else np.asarray(x1)\n",
    "    x2 = np.asarray(x2.dropna()) if hasattr(x2, \"dropna\") else np.asarray(x2)\n",
    "    n1 = len(x1); n2 = len(x2)\n",
    "    if n1 < 1 or n2 < 1:\n",
    "        raise ValueError(\"permutation_test_diff_means: muestras vacías\")\n",
    "    obs_diff = np.mean(x1) - np.mean(x2)\n",
    "    pooled = np.concatenate([x1, x2])\n",
    "    perm_diffs = np.empty(n_perm)\n",
    "    for i in range(n_perm):\n",
    "        perm = rng.permutation(pooled)\n",
    "        perm_diffs[i] = perm[:n1].mean() - perm[n1:].mean()\n",
    "    p_value = np.mean(np.abs(perm_diffs) >= np.abs(obs_diff))\n",
    "    if return_null_dist:\n",
    "        return obs_diff, p_value, perm_diffs\n",
    "    return obs_diff, p_value\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: apply corrections (FDR/Bonferroni)\n",
    "# ------------------------------\n",
    "def apply_multiple_corrections(pvals, alpha=0.05, method='fdr_bh'):\n",
    "    \"\"\"\n",
    "    Aplica multipletests de statsmodels.\n",
    "    Devuelve: reject_array, pvals_corrected\n",
    "    method: 'bonferroni', 'fdr_bh', etc.\n",
    "    \"\"\"\n",
    "    pvals = np.asarray(pvals)\n",
    "    reject, pvals_corrected, _, _ = multipletests(pvals, alpha=alpha, method=method)\n",
    "    return reject, pvals_corrected\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL adicional: CI para correlación de Pearson (Fisher z)\n",
    "# ------------------------------\n",
    "def pearson_r_ci(r, n, alpha=0.05):\n",
    "    \"\"\"CI para una correlación r (transformación Fisher). Devuelve (r, (low,high)).\"\"\"\n",
    "    if n <= 3:\n",
    "        raise ValueError(\"pearson_r_ci: se requieren n>3\")\n",
    "    z = np.arctanh(r)  # fisher z\n",
    "    se = 1 / np.sqrt(n - 3)\n",
    "    z_crit = stats.norm.ppf(1 - alpha/2)\n",
    "    lo, hi = z - z_crit * se, z + z_crit * se\n",
    "    return r, (np.tanh(lo), np.tanh(hi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7957b",
   "metadata": {},
   "source": [
    "Procedimiento:\n",
    "- Para cada empresa: Shapiro-Wilk (o Lilliefors) sobre retornos (si n pequeño usar Shapiro)\n",
    "- Si la mayoría viola normalidad (p < 0.05), preferir pruebas no paramétricas o bootstrap\n",
    "- Guardaremos un resumen con n, p_shapiro, decisión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d37b7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>n</th>\n",
       "      <th>test</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>p_value_fdr</th>\n",
       "      <th>normal_reject_fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>83</td>\n",
       "      <td>Shapiro</td>\n",
       "      <td>0.845255</td>\n",
       "      <td>7.423516e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAP</td>\n",
       "      <td>83</td>\n",
       "      <td>Shapiro</td>\n",
       "      <td>0.935816</td>\n",
       "      <td>4.464753e-04</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intel</td>\n",
       "      <td>83</td>\n",
       "      <td>Shapiro</td>\n",
       "      <td>0.943477</td>\n",
       "      <td>1.170462e-03</td>\n",
       "      <td>0.010342</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Palantir</td>\n",
       "      <td>51</td>\n",
       "      <td>Shapiro</td>\n",
       "      <td>0.914936</td>\n",
       "      <td>1.378993e-03</td>\n",
       "      <td>0.010342</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meta Platforms</td>\n",
       "      <td>83</td>\n",
       "      <td>Shapiro</td>\n",
       "      <td>0.949261</td>\n",
       "      <td>2.506951e-03</td>\n",
       "      <td>0.015042</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Broadcom</td>\n",
       "      <td>83</td>\n",
       "      <td>Shapiro</td>\n",
       "      <td>0.963013</td>\n",
       "      <td>1.734127e-02</td>\n",
       "      <td>0.086706</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Snowflake</td>\n",
       "      <td>51</td>\n",
       "      <td>Shapiro</td>\n",
       "      <td>0.945631</td>\n",
       "      <td>2.078493e-02</td>\n",
       "      <td>0.089078</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>83</td>\n",
       "      <td>Shapiro</td>\n",
       "      <td>0.966265</td>\n",
       "      <td>2.806939e-02</td>\n",
       "      <td>0.105260</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>83</td>\n",
       "      <td>Shapiro</td>\n",
       "      <td>0.969379</td>\n",
       "      <td>4.481786e-02</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>83</td>\n",
       "      <td>Shapiro</td>\n",
       "      <td>0.970199</td>\n",
       "      <td>5.073450e-02</td>\n",
       "      <td>0.152204</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Company   n     test  statistic       p_value  p_value_fdr  \\\n",
       "0         Netflix  83  Shapiro   0.845255  7.423516e-08     0.000002   \n",
       "1             SAP  83  Shapiro   0.935816  4.464753e-04     0.006697   \n",
       "2           Intel  83  Shapiro   0.943477  1.170462e-03     0.010342   \n",
       "3        Palantir  51  Shapiro   0.914936  1.378993e-03     0.010342   \n",
       "4  Meta Platforms  83  Shapiro   0.949261  2.506951e-03     0.015042   \n",
       "5        Broadcom  83  Shapiro   0.963013  1.734127e-02     0.086706   \n",
       "6       Snowflake  51  Shapiro   0.945631  2.078493e-02     0.089078   \n",
       "7       Accenture  83  Shapiro   0.966265  2.806939e-02     0.105260   \n",
       "8         Infosys  83  Shapiro   0.969379  4.481786e-02     0.149393   \n",
       "9          Nvidia  83  Shapiro   0.970199  5.073450e-02     0.152204   \n",
       "\n",
       "  normal_reject_fdr  \n",
       "0              True  \n",
       "1              True  \n",
       "2              True  \n",
       "3              True  \n",
       "4              True  \n",
       "5             False  \n",
       "6             False  \n",
       "7             False  \n",
       "8             False  \n",
       "9             False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELDA 3\n",
    "\n",
    "def normality_summary(panel_df, alpha=0.05, correction_method='fdr_bh'):\n",
    "    \"\"\"\n",
    "    Evalúa normalidad de 'Return' por empresa en panel_df.\n",
    "    - Usa Shapiro-Wilk cuando es posible; si falla, usa Lilliefors.\n",
    "    - Aplica corrección por comparaciones múltiples a los p-values (multipletests).\n",
    "    \n",
    "    Devuelve DataFrame con columnas:\n",
    "    ['Company','n','test','statistic','p_value','p_value_fdr','normal_reject_fdr']\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    companies = sorted(panel_df['Company'].unique())\n",
    "    for c in companies:\n",
    "        r = panel_df.loc[panel_df['Company'] == c, 'Return'].dropna()\n",
    "        n = len(r)\n",
    "        if n < 3:\n",
    "            stat = np.nan\n",
    "            pval = np.nan\n",
    "            test_name = None\n",
    "        else:\n",
    "            try:\n",
    "                stat, pval = stats.shapiro(r)   # Shapiro-Wilk\n",
    "                test_name = 'Shapiro'\n",
    "            except Exception:\n",
    "                # fallback to Lilliefors (Kolmogorov-Smirnov adaptado)\n",
    "                stat, pval = lilliefors(r)\n",
    "                test_name = 'Lilliefors'\n",
    "        rows.append({\n",
    "            'Company': c,\n",
    "            'n': n,\n",
    "            'test': test_name,\n",
    "            'statistic': stat,\n",
    "            'p_value': pval\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Corrección por múltiples tests (solo sobre p-values no nulos)\n",
    "    mask = df['p_value'].notna()\n",
    "    if mask.any():\n",
    "        reject, pvals_corr, _, _ = multipletests(df.loc[mask, 'p_value'].values,\n",
    "                                                alpha=alpha, method=correction_method)\n",
    "        df.loc[mask, 'p_value_fdr'] = pvals_corr\n",
    "        df.loc[mask, 'normal_reject_fdr'] = reject.astype(bool)\n",
    "    else:\n",
    "        df['p_value_fdr'] = np.nan\n",
    "        df['normal_reject_fdr'] = False\n",
    "\n",
    "    # Orden por p_value_fdr para inspección rápida (NaNs al final)\n",
    "    df = df.sort_values(by=['p_value_fdr', 'p_value'], na_position='last').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Uso:\n",
    "norm_summary = normality_summary(panel_df, alpha=0.05, correction_method='fdr_bh')\n",
    "norm_summary.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865602cb",
   "metadata": {},
   "source": [
    "Calculamos:\n",
    "- IC t (clásico) para la media de retornos por empresa\n",
    "- IC bootstrap (percentil) para robustez\n",
    "Guardamos una tabla con mean, se, df, ci_t_low, ci_t_high, ci_boot_low, ci_boot_high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f73b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>n</th>\n",
       "      <th>MeanReturn</th>\n",
       "      <th>SE</th>\n",
       "      <th>df</th>\n",
       "      <th>CI_t_low</th>\n",
       "      <th>CI_t_high</th>\n",
       "      <th>CI_boot_low</th>\n",
       "      <th>CI_boot_high</th>\n",
       "      <th>BootMean</th>\n",
       "      <th>BootBias</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_t</th>\n",
       "      <th>p_boot</th>\n",
       "      <th>IncludesZero_t</th>\n",
       "      <th>IncludesZero_boot</th>\n",
       "      <th>p_t_fdr</th>\n",
       "      <th>signif_t_fdr</th>\n",
       "      <th>p_boot_fdr</th>\n",
       "      <th>signif_boot_fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Palantir</td>\n",
       "      <td>51</td>\n",
       "      <td>0.041075</td>\n",
       "      <td>0.034737</td>\n",
       "      <td>50</td>\n",
       "      <td>-0.028696</td>\n",
       "      <td>0.110847</td>\n",
       "      <td>-0.024158</td>\n",
       "      <td>0.114878</td>\n",
       "      <td>0.041075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.182460</td>\n",
       "      <td>0.242616</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.401937</td>\n",
       "      <td>False</td>\n",
       "      <td>0.388750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>83</td>\n",
       "      <td>0.037576</td>\n",
       "      <td>0.015421</td>\n",
       "      <td>82</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>0.068253</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>0.067632</td>\n",
       "      <td>0.037576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.436684</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.104925</td>\n",
       "      <td>False</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>83</td>\n",
       "      <td>0.034602</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>82</td>\n",
       "      <td>-0.006678</td>\n",
       "      <td>0.075881</td>\n",
       "      <td>-0.003005</td>\n",
       "      <td>0.075650</td>\n",
       "      <td>0.034602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.667516</td>\n",
       "      <td>0.099227</td>\n",
       "      <td>0.072667</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.297680</td>\n",
       "      <td>False</td>\n",
       "      <td>0.242222</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Broadcom</td>\n",
       "      <td>83</td>\n",
       "      <td>0.029832</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>82</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.050040</td>\n",
       "      <td>0.029832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.942288</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.068911</td>\n",
       "      <td>False</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fortinet</td>\n",
       "      <td>83</td>\n",
       "      <td>0.028135</td>\n",
       "      <td>0.011997</td>\n",
       "      <td>82</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>0.052001</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.051443</td>\n",
       "      <td>0.028135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.345041</td>\n",
       "      <td>0.021442</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.107211</td>\n",
       "      <td>False</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company   n  MeanReturn        SE  df  CI_t_low  CI_t_high  CI_boot_low  \\\n",
       "0  Palantir  51    0.041075  0.034737  50 -0.028696   0.110847    -0.024158   \n",
       "1    Nvidia  83    0.037576  0.015421  82  0.006899   0.068253     0.006371   \n",
       "2     Tesla  83    0.034602  0.020750  82 -0.006678   0.075881    -0.003005   \n",
       "3  Broadcom  83    0.029832  0.010139  82  0.009662   0.050002     0.009998   \n",
       "4  Fortinet  83    0.028135  0.011997  82  0.004268   0.052001     0.003607   \n",
       "\n",
       "   CI_boot_high  BootMean  BootBias    t_stat       p_t    p_boot  \\\n",
       "0      0.114878  0.041075       0.0  1.182460  0.242616  0.206000   \n",
       "1      0.067632  0.037576       0.0  2.436684  0.016987  0.018000   \n",
       "2      0.075650  0.034602       0.0  1.667516  0.099227  0.072667   \n",
       "3      0.050040  0.029832       0.0  2.942288  0.004235  0.003333   \n",
       "4      0.051443  0.028135       0.0  2.345041  0.021442  0.020667   \n",
       "\n",
       "   IncludesZero_t  IncludesZero_boot   p_t_fdr signif_t_fdr  p_boot_fdr  \\\n",
       "0            True               True  0.401937        False    0.388750   \n",
       "1           False              False  0.104925        False    0.103333   \n",
       "2            True               True  0.297680        False    0.242222   \n",
       "3           False              False  0.068911        False    0.040000   \n",
       "4           False              False  0.107211        False    0.103333   \n",
       "\n",
       "  signif_boot_fdr  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3            True  \n",
       "4           False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELDA 4\n",
    "\n",
    "results = []\n",
    "pvals_t = []\n",
    "pvals_boot = []\n",
    "companies = sorted(panel_df['Company'].unique())\n",
    "\n",
    "for c in companies:\n",
    "    r = panel_df.loc[panel_df['Company'] == c, 'Return'].dropna().values\n",
    "    n = len(r)\n",
    "    if n < 2:\n",
    "        # No hay muestra suficiente para t-test\n",
    "        continue\n",
    "\n",
    "    # Valores por defecto\n",
    "    mean = np.nan; se = np.nan; df = np.nan\n",
    "    ci_t_low = np.nan; ci_t_high = np.nan\n",
    "    boot_mean = np.nan; ci_boot_low = np.nan; ci_boot_high = np.nan\n",
    "    t_stat = np.nan; p_t = np.nan\n",
    "    p_boot = np.nan\n",
    "    boot_bias = np.nan\n",
    "    includes_zero_t = np.nan\n",
    "    includes_zero_boot = np.nan\n",
    "\n",
    "    # 1) Intervalo t (safe: ci_mean_t valida n)\n",
    "    try:\n",
    "        mean, se, df, (ci_t_low, ci_t_high) = ci_mean_t(r, alpha=0.05)\n",
    "    except Exception as e:\n",
    "        mean = np.mean(r)\n",
    "        se = np.std(r, ddof=1) / np.sqrt(max(1, n))\n",
    "        df = n - 1\n",
    "        ci_t_low, ci_t_high = (np.nan, np.nan)\n",
    "\n",
    "    # 2) Bootstrap percentile CI (reproducible seed)\n",
    "    try:\n",
    "        # return boots for p-value calculation\n",
    "        mean_b, (ci_boot_low, ci_boot_high), boots = bootstrap_ci_mean(r, n_boot=3000, random_state=42, return_boots=True)\n",
    "        boot_mean = mean_b\n",
    "        boot_bias = boot_mean - mean\n",
    "        # two-sided bootstrap p-value: proportion of bootstrap means on opposite side of zero\n",
    "        prop_le = np.mean(boots <= 0)\n",
    "        prop_ge = np.mean(boots >= 0)\n",
    "        p_boot = 2 * min(prop_le, prop_ge)  # two-sided\n",
    "        p_boot = min(1.0, p_boot)\n",
    "    except Exception:\n",
    "        boots = None\n",
    "\n",
    "    # 3) One-sample t-test (H0: mean = 0)\n",
    "    try:\n",
    "        t_stat, p_t = one_sample_ttest(r, mu0=0.0, alternative='two-sided')\n",
    "    except Exception:\n",
    "        # fallback to scipy direct\n",
    "        tt_res = stats.ttest_1samp(r, popmean=0.0)\n",
    "        t_stat, p_t = tt_res.statistic, tt_res.pvalue\n",
    "\n",
    "    # 4) Flags: CI includes zero?\n",
    "    includes_zero_t = (ci_t_low <= 0 <= ci_t_high) if (not np.isnan(ci_t_low) and not np.isnan(ci_t_high)) else np.nan\n",
    "    includes_zero_boot = (ci_boot_low <= 0 <= ci_boot_high) if (not np.isnan(ci_boot_low) and not np.isnan(ci_boot_high)) else np.nan\n",
    "\n",
    "    results.append({\n",
    "        'Company': c,\n",
    "        'n': n,\n",
    "        'MeanReturn': mean,\n",
    "        'SE': se,\n",
    "        'df': df,\n",
    "        'CI_t_low': ci_t_low,\n",
    "        'CI_t_high': ci_t_high,\n",
    "        'CI_boot_low': ci_boot_low,\n",
    "        'CI_boot_high': ci_boot_high,\n",
    "        'BootMean': boot_mean,\n",
    "        'BootBias': boot_bias,\n",
    "        't_stat': t_stat,\n",
    "        'p_t': p_t,\n",
    "        'p_boot': p_boot,\n",
    "        'IncludesZero_t': includes_zero_t,\n",
    "        'IncludesZero_boot': includes_zero_boot\n",
    "    })\n",
    "\n",
    "# DataFrame\n",
    "ci_df = pd.DataFrame(results).sort_values('MeanReturn', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Aplicar corrección por múltiples tests (FDR) a p_t y p_boot por separado\n",
    "mask_t = ci_df['p_t'].notna()\n",
    "if mask_t.any():\n",
    "    rej_t, pvals_t_corr, _, _ = multipletests(ci_df.loc[mask_t, 'p_t'].values, alpha=0.05, method='fdr_bh')\n",
    "    ci_df.loc[mask_t, 'p_t_fdr'] = pvals_t_corr\n",
    "    ci_df.loc[mask_t, 'signif_t_fdr'] = rej_t.astype(bool)\n",
    "else:\n",
    "    ci_df['p_t_fdr'] = np.nan\n",
    "    ci_df['signif_t_fdr'] = False\n",
    "\n",
    "mask_b = ci_df['p_boot'].notna()\n",
    "if mask_b.any():\n",
    "    rej_b, pvals_b_corr, _, _ = multipletests(ci_df.loc[mask_b, 'p_boot'].values, alpha=0.05, method='fdr_bh')\n",
    "    ci_df.loc[mask_b, 'p_boot_fdr'] = pvals_b_corr\n",
    "    ci_df.loc[mask_b, 'signif_boot_fdr'] = rej_b.astype(bool)\n",
    "else:\n",
    "    ci_df['p_boot_fdr'] = np.nan\n",
    "    ci_df['signif_boot_fdr'] = False\n",
    "\n",
    "# Guardar resultados\n",
    "out_path = os.path.join(PROCESSED_DIR, 'inference_mean_CI_by_company_enhanced.csv')\n",
    "ci_df.to_csv(out_path, index=False)\n",
    "\n",
    "# Mostrar resumen\n",
    "ci_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1b7d3",
   "metadata": {},
   "source": [
    "Muchos trabajos en finanzas prueban si el retorno medio es significativamente distinto de cero.\n",
    "Realizamos la prueba t de una muestra para cada empresa y guardamos p-values y estadístico.\n",
    "Aplicaremos correcciones por comparaciones múltiples (Bonferroni y FDR).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94121d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>n</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>tstat</th>\n",
       "      <th>p_t</th>\n",
       "      <th>cohens_d</th>\n",
       "      <th>p_bonf</th>\n",
       "      <th>reject_bonf</th>\n",
       "      <th>p_fdr</th>\n",
       "      <th>reject_fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Broadcom</td>\n",
       "      <td>83</td>\n",
       "      <td>0.029832</td>\n",
       "      <td>0.092371</td>\n",
       "      <td>2.942288</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.322958</td>\n",
       "      <td>0.127044</td>\n",
       "      <td>False</td>\n",
       "      <td>0.068911</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>83</td>\n",
       "      <td>0.018964</td>\n",
       "      <td>0.059285</td>\n",
       "      <td>2.914284</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.319884</td>\n",
       "      <td>0.137822</td>\n",
       "      <td>False</td>\n",
       "      <td>0.068911</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ServiceNow</td>\n",
       "      <td>83</td>\n",
       "      <td>0.023737</td>\n",
       "      <td>0.078987</td>\n",
       "      <td>2.737873</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.300521</td>\n",
       "      <td>0.227466</td>\n",
       "      <td>False</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>83</td>\n",
       "      <td>0.037576</td>\n",
       "      <td>0.140490</td>\n",
       "      <td>2.436684</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.267461</td>\n",
       "      <td>0.509623</td>\n",
       "      <td>False</td>\n",
       "      <td>0.104925</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple</td>\n",
       "      <td>83</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>0.084030</td>\n",
       "      <td>2.425393</td>\n",
       "      <td>0.017488</td>\n",
       "      <td>0.266222</td>\n",
       "      <td>0.524625</td>\n",
       "      <td>False</td>\n",
       "      <td>0.104925</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fortinet</td>\n",
       "      <td>83</td>\n",
       "      <td>0.028135</td>\n",
       "      <td>0.109302</td>\n",
       "      <td>2.345041</td>\n",
       "      <td>0.021442</td>\n",
       "      <td>0.257402</td>\n",
       "      <td>0.643266</td>\n",
       "      <td>False</td>\n",
       "      <td>0.107211</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Taiwan Semiconductor</td>\n",
       "      <td>83</td>\n",
       "      <td>0.020067</td>\n",
       "      <td>0.093745</td>\n",
       "      <td>1.950126</td>\n",
       "      <td>0.054578</td>\n",
       "      <td>0.214054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.233907</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oracle</td>\n",
       "      <td>83</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>0.078020</td>\n",
       "      <td>1.801174</td>\n",
       "      <td>0.075352</td>\n",
       "      <td>0.197704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.262313</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alphabet</td>\n",
       "      <td>83</td>\n",
       "      <td>0.014190</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>1.780526</td>\n",
       "      <td>0.078694</td>\n",
       "      <td>0.195438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.262313</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>83</td>\n",
       "      <td>0.034602</td>\n",
       "      <td>0.189046</td>\n",
       "      <td>1.667516</td>\n",
       "      <td>0.099227</td>\n",
       "      <td>0.183034</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.297680</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company   n      mean        sd     tstat       p_t  cohens_d  \\\n",
       "0              Broadcom  83  0.029832  0.092371  2.942288  0.004235  0.322958   \n",
       "1             Microsoft  83  0.018964  0.059285  2.914284  0.004594  0.319884   \n",
       "2            ServiceNow  83  0.023737  0.078987  2.737873  0.007582  0.300521   \n",
       "3                Nvidia  83  0.037576  0.140490  2.436684  0.016987  0.267461   \n",
       "4                 Apple  83  0.022371  0.084030  2.425393  0.017488  0.266222   \n",
       "5              Fortinet  83  0.028135  0.109302  2.345041  0.021442  0.257402   \n",
       "6  Taiwan Semiconductor  83  0.020067  0.093745  1.950126  0.054578  0.214054   \n",
       "7                Oracle  83  0.015425  0.078020  1.801174  0.075352  0.197704   \n",
       "8              Alphabet  83  0.014190  0.072604  1.780526  0.078694  0.195438   \n",
       "9                 Tesla  83  0.034602  0.189046  1.667516  0.099227  0.183034   \n",
       "\n",
       "     p_bonf reject_bonf     p_fdr reject_fdr  \n",
       "0  0.127044       False  0.068911      False  \n",
       "1  0.137822       False  0.068911      False  \n",
       "2  0.227466       False  0.075822      False  \n",
       "3  0.509623       False  0.104925      False  \n",
       "4  0.524625       False  0.104925      False  \n",
       "5  0.643266       False  0.107211      False  \n",
       "6  1.000000       False  0.233907      False  \n",
       "7  1.000000       False  0.262313      False  \n",
       "8  1.000000       False  0.262313      False  \n",
       "9  1.000000       False  0.297680      False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELDA 5\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# RESUMEN CLÁSICO: One-sample t-test por empresa (μ = 0)\n",
    "# Complementario a la inferencia completa de ci_df\n",
    "# -------------------------------------------------------\n",
    "\n",
    "tt_results = []\n",
    "\n",
    "for c in sorted(panel_df['Company'].unique()):\n",
    "    r = panel_df.loc[panel_df['Company'] == c, 'Return'].dropna().values\n",
    "    n = len(r)\n",
    "    if n < 2:\n",
    "        continue\n",
    "\n",
    "    mean = r.mean()\n",
    "    sd = r.std(ddof=1)\n",
    "\n",
    "    # t-test robusto a versiones\n",
    "    try:\n",
    "        tstat, pval = one_sample_ttest(r, mu0=0.0, alternative='two-sided')\n",
    "    except Exception:\n",
    "        res = stats.ttest_1samp(r, popmean=0.0)\n",
    "        tstat, pval = res.statistic, res.pvalue\n",
    "\n",
    "    # Tamaño del efecto (Cohen's d)\n",
    "    cohens_d = mean / sd if sd > 0 else np.nan\n",
    "\n",
    "    tt_results.append({\n",
    "        'Company': c,\n",
    "        'n': n,\n",
    "        'mean': mean,\n",
    "        'sd': sd,\n",
    "        'tstat': tstat,\n",
    "        'p_t': pval,\n",
    "        'cohens_d': cohens_d\n",
    "    })\n",
    "\n",
    "tt_df = (\n",
    "    pd.DataFrame(tt_results)\n",
    "      .sort_values('p_t')\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Correcciones por comparaciones múltiples\n",
    "# -------------------------------------------------------\n",
    "\n",
    "mask = tt_df['p_t'].notna()\n",
    "\n",
    "if mask.any():\n",
    "    rej_bonf, p_bonf, _, _ = multipletests(tt_df.loc[mask, 'p_t'], alpha=0.05, method='bonferroni')\n",
    "    rej_fdr,  p_fdr,  _, _ = multipletests(tt_df.loc[mask, 'p_t'], alpha=0.05, method='fdr_bh')\n",
    "\n",
    "    tt_df.loc[mask, 'p_bonf'] = p_bonf\n",
    "    tt_df.loc[mask, 'reject_bonf'] = rej_bonf.astype(bool)\n",
    "    tt_df.loc[mask, 'p_fdr'] = p_fdr\n",
    "    tt_df.loc[mask, 'reject_fdr'] = rej_fdr.astype(bool)\n",
    "else:\n",
    "    tt_df['p_bonf'] = np.nan\n",
    "    tt_df['reject_bonf'] = False\n",
    "    tt_df['p_fdr'] = np.nan\n",
    "    tt_df['reject_fdr'] = False\n",
    "\n",
    "# Guardar\n",
    "out_path = os.path.join(PROCESSED_DIR, 'one_sample_ttest_results_classical.csv')\n",
    "tt_df.to_csv(out_path, index=False)\n",
    "\n",
    "tt_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278d3f1",
   "metadata": {},
   "source": [
    "- Si p < alpha (ajustado), rechazamos H0: μ = 0 y decimos que el retorno medio es significativamente distinto de 0.\n",
    "- Reportar siempre: mean, t-stat, p, p ajustada, IC.\n",
    "- En la discusión: comentar tamaño del efecto (mean) y su relevancia económica, no solo p-value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888b2a2",
   "metadata": {},
   "source": [
    "Definimos grupos basados en Beta (del dataset agregado).  \n",
    "Haremos: Levene (varianzas), Welch t-test (medias), Mann-Whitney (no paramétrica) y permutation test (robusto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bfee7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_groupA</th>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_groupB</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_A</th>\n",
       "      <td>0.010940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd_A</th>\n",
       "      <td>0.011310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_B</th>\n",
       "      <td>0.020454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd_B</th>\n",
       "      <td>0.010674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>levene_p</th>\n",
       "      <td>0.917626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>welch_t</th>\n",
       "      <td>-2.368676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>welch_p</th>\n",
       "      <td>0.025036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>welch_CI_low</th>\n",
       "      <td>-0.017744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>welch_CI_high</th>\n",
       "      <td>-0.001284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mw_p</th>\n",
       "      <td>0.043782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perm_p</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boot_diff_CI_low</th>\n",
       "      <td>-0.017155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boot_diff_CI_high</th>\n",
       "      <td>-0.002035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boot_diff_p</th>\n",
       "      <td>0.492600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hedges_g</th>\n",
       "      <td>-0.840057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "n_groupA           16.000000\n",
       "n_groupB           14.000000\n",
       "mean_A              0.010940\n",
       "sd_A                0.011310\n",
       "mean_B              0.020454\n",
       "sd_B                0.010674\n",
       "levene_p            0.917626\n",
       "welch_t            -2.368676\n",
       "welch_p             0.025036\n",
       "welch_CI_low       -0.017744\n",
       "welch_CI_high      -0.001284\n",
       "mw_p                0.043782\n",
       "perm_p                   NaN\n",
       "boot_diff_CI_low   -0.017155\n",
       "boot_diff_CI_high  -0.002035\n",
       "boot_diff_p         0.492600\n",
       "hedges_g           -0.840057"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELDA 6\n",
    "\n",
    "\n",
    "# Celda mejorada: comparar empresas por Beta (low vs high) con tests y efectos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.api import DescrStatsW, CompareMeans\n",
    "import scipy.stats as stats\n",
    "\n",
    "def hedges_g(x, y):\n",
    "    \"\"\"Hedges' g (corrección de Cohen's d por sesgo small-sample).\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    nx, ny = len(x), len(y)\n",
    "    if nx < 2 or ny < 2:\n",
    "        return np.nan\n",
    "    sx2 = x.var(ddof=1)\n",
    "    sy2 = y.var(ddof=1)\n",
    "    pooled_sd = np.sqrt(((nx-1)*sx2 + (ny-1)*sy2) / (nx+ny-2))\n",
    "    if pooled_sd == 0:\n",
    "        return 0.0\n",
    "    d = (x.mean() - y.mean()) / pooled_sd\n",
    "    # correction factor J\n",
    "    J = 1 - (3 / (4*(nx+ny) - 9))\n",
    "    return d * J\n",
    "\n",
    "def bootstrap_diff_mean_ci(x, y, n_boot=5000, alpha=0.05, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    nx, ny = len(x), len(y)\n",
    "    boots = np.empty(n_boot)\n",
    "    pooled_n = nx\n",
    "    for i in range(n_boot):\n",
    "        sx = rng.choice(x, size=nx, replace=True)\n",
    "        sy = rng.choice(y, size=ny, replace=True)\n",
    "        boots[i] = sx.mean() - sy.mean()\n",
    "    lo = np.percentile(boots, 100*(alpha/2))\n",
    "    hi = np.percentile(boots, 100*(1-alpha/2))\n",
    "    p_two = np.mean(np.abs(boots) >= np.abs(np.mean(x)-np.mean(y)))\n",
    "    return (lo, hi), p_two, boots\n",
    "\n",
    "# ------------- robust mapping of beta column (tolerante a mayúsculas/minúsculas)\n",
    "beta_col = None\n",
    "for col in ['beta', 'Beta']:\n",
    "    if col in agg_df.columns:\n",
    "        beta_col = col\n",
    "        break\n",
    "if beta_col is None:\n",
    "    raise KeyError(\"No se encontró la columna 'beta' o 'Beta' en agg_df. Revisa nombres de columnas.\")\n",
    "\n",
    "# Asegurar numérico y dropna\n",
    "agg_df[beta_col] = pd.to_numeric(agg_df[beta_col], errors='coerce')\n",
    "\n",
    "# Merge beta onto panel (como hacías)\n",
    "beta_map = agg_df.set_index('Company')[beta_col].to_dict()\n",
    "panel_df['Beta'] = panel_df['Company'].map(beta_map)\n",
    "\n",
    "# Crear grupo (low <=1, high >1) — puedes cambiar el umbral por cuantiles si prefieres\n",
    "panel_df['Beta_group'] = panel_df['Beta'].apply(lambda x: 'low' if pd.notna(x) and x <= 1 else ('high' if pd.notna(x) else np.nan))\n",
    "\n",
    "# Usar el MeanReturn a nivel empresa desde agg_df (recomendado) en lugar de recomputar\n",
    "if 'MeanReturn' not in agg_df.columns:\n",
    "    raise KeyError(\"agg_df no tiene columna 'MeanReturn'. Asegúrate de que exista o calcula la media por empresa primero.\")\n",
    "\n",
    "groupA = agg_df.loc[agg_df[beta_col] <= 1, 'MeanReturn'].dropna()\n",
    "groupB = agg_df.loc[agg_df[beta_col] > 1, 'MeanReturn'].dropna()\n",
    "\n",
    "res = {}\n",
    "res['n_groupA'] = len(groupA)\n",
    "res['n_groupB'] = len(groupB)\n",
    "\n",
    "# Estadísticos descriptivos\n",
    "def summary_stats(arr):\n",
    "    return {\n",
    "        'n': len(arr),\n",
    "        'mean': float(np.mean(arr)) if len(arr)>0 else np.nan,\n",
    "        'sd': float(np.std(arr, ddof=1)) if len(arr)>1 else np.nan,\n",
    "        'median': float(np.median(arr)) if len(arr)>0 else np.nan\n",
    "    }\n",
    "\n",
    "res['desc_groupA'] = summary_stats(groupA.values)\n",
    "res['desc_groupB'] = summary_stats(groupB.values)\n",
    "\n",
    "# 1) Levene (varianzas)\n",
    "if len(groupA) >= 2 and len(groupB) >= 2:\n",
    "    levene_stat, levene_p = stats.levene(groupA.values, groupB.values)\n",
    "else:\n",
    "    levene_stat, levene_p = np.nan, np.nan\n",
    "res['levene_stat'] = levene_stat\n",
    "res['levene_p'] = levene_p\n",
    "\n",
    "# 2) Normalidad a nivel \"empresa\" (Shapiro)\n",
    "# Uso como diagnóstico: si n_groups>3 aplicar Shapiro; si no, omitir\n",
    "res['shapiro_groupA'] = (np.nan, np.nan)\n",
    "res['shapiro_groupB'] = (np.nan, np.nan)\n",
    "if len(groupA) >= 3:\n",
    "    try:\n",
    "        res['shapiro_groupA'] = stats.shapiro(groupA.values)\n",
    "    except Exception:\n",
    "        res['shapiro_groupA'] = lilliefors(groupA.values)\n",
    "if len(groupB) >= 3:\n",
    "    try:\n",
    "        res['shapiro_groupB'] = stats.shapiro(groupB.values)\n",
    "    except Exception:\n",
    "        res['shapiro_groupB'] = lilliefors(groupB.values)\n",
    "\n",
    "# 3) Welch t-test (dif de medias) + CI via CompareMeans\n",
    "if len(groupA) >= 2 and len(groupB) >= 2:\n",
    "    t_res = stats.ttest_ind(groupA.values, groupB.values, equal_var=False)\n",
    "    res['welch_t_stat'] = float(t_res.statistic)\n",
    "    res['welch_p'] = float(t_res.pvalue)\n",
    "\n",
    "    # CI de la diferencia (Welch) usando CompareMeans\n",
    "    try:\n",
    "        dsA = DescrStatsW(groupA.values)\n",
    "        dsB = DescrStatsW(groupB.values)\n",
    "        cm = CompareMeans(dsA, dsB)\n",
    "        ci_welch = cm.tconfint_diff(usevar='unequal')  # devuelve (low, high)\n",
    "        res['welch_CI'] = (float(ci_welch[0]), float(ci_welch[1]))\n",
    "    except Exception:\n",
    "        res['welch_CI'] = (np.nan, np.nan)\n",
    "else:\n",
    "    res['welch_t_stat'] = np.nan\n",
    "    res['welch_p'] = np.nan\n",
    "    res['welch_CI'] = (np.nan, np.nan)\n",
    "\n",
    "# 4) Mann-Whitney (rank) — no asume normalidad\n",
    "if len(groupA) >= 1 and len(groupB) >= 1:\n",
    "    try:\n",
    "        mw_stat, mw_p = stats.mannwhitneyu(groupA.values, groupB.values, alternative='two-sided')\n",
    "        res['mw_stat'] = float(mw_stat)\n",
    "        res['mw_p'] = float(mw_p)\n",
    "    except Exception:\n",
    "        res['mw_stat'], res['mw_p'] = np.nan, np.nan\n",
    "else:\n",
    "    res['mw_stat'], res['mw_p'] = np.nan, np.nan\n",
    "\n",
    "# 5) Permutation test (ya definiste permutation_test_diff_means)\n",
    "if len(groupA) >= 1 and len(groupB) >= 1:\n",
    "    try:\n",
    "        diff_obs, pperm, perm_dist = permutation_test_diff_means(groupA.values, groupB.values, n_perm=5000, random_state=42)\n",
    "        res['perm_diff_obs'] = float(diff_obs)\n",
    "        res['perm_p'] = float(pperm)\n",
    "    except Exception:\n",
    "        res['perm_diff_obs'], res['perm_p'] = np.nan, np.nan\n",
    "else:\n",
    "    res['perm_diff_obs'], res['perm_p'] = np.nan, np.nan\n",
    "\n",
    "# 6) Bootstrap CI para la diferencia de medias\n",
    "if len(groupA) >= 1 and len(groupB) >= 1:\n",
    "    try:\n",
    "        (boot_lo, boot_hi), p_boot_diff, boots_diff = bootstrap_diff_mean_ci(groupA.values, groupB.values, n_boot=5000, random_state=42)\n",
    "        res['boot_diff_CI'] = (float(boot_lo), float(boot_hi))\n",
    "        res['boot_diff_p'] = float(p_boot_diff)\n",
    "    except Exception:\n",
    "        res['boot_diff_CI'] = (np.nan, np.nan)\n",
    "        res['boot_diff_p'] = np.nan\n",
    "else:\n",
    "    res['boot_diff_CI'] = (np.nan, np.nan)\n",
    "    res['boot_diff_p'] = np.nan\n",
    "\n",
    "# 7) Tamaño del efecto (Hedges' g)\n",
    "res['hedges_g'] = float(hedges_g(groupA.values, groupB.values)) if (len(groupA)>=2 and len(groupB)>=2) else np.nan\n",
    "\n",
    "# 8) Guardar resultados en un DataFrame y CSV resumido\n",
    "out_df = pd.DataFrame([{\n",
    "    'n_groupA': res['n_groupA'],\n",
    "    'n_groupB': res['n_groupB'],\n",
    "    'mean_A': res['desc_groupA']['mean'],\n",
    "    'sd_A': res['desc_groupA']['sd'],\n",
    "    'mean_B': res['desc_groupB']['mean'],\n",
    "    'sd_B': res['desc_groupB']['sd'],\n",
    "    'levene_p': res['levene_p'],\n",
    "    'welch_t': res['welch_t_stat'],\n",
    "    'welch_p': res['welch_p'],\n",
    "    'welch_CI_low': res['welch_CI'][0],\n",
    "    'welch_CI_high': res['welch_CI'][1],\n",
    "    'mw_p': res['mw_p'],\n",
    "    'perm_p': res['perm_p'],\n",
    "    'boot_diff_CI_low': res['boot_diff_CI'][0],\n",
    "    'boot_diff_CI_high': res['boot_diff_CI'][1],\n",
    "    'boot_diff_p': res['boot_diff_p'],\n",
    "    'hedges_g': res['hedges_g']\n",
    "}])\n",
    "\n",
    "out_path = os.path.join(PROCESSED_DIR, 'group_comparison_beta_low_high_summary.csv')\n",
    "out_df.to_csv(out_path, index=False)\n",
    "\n",
    "# Mostrar resultados en pantalla (limpio)\n",
    "out_df.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a24b4",
   "metadata": {},
   "source": [
    "Si queremos comparar volatilidades entre dos conjuntos (ej. consolidadas vs growth):\n",
    "- usar Levene (robusto frente a no-normalidad)\n",
    "- reportar estadístico y p-value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7a5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n volA (Beta ≤ 1): 16\n",
      "n volB (Beta > 1): 14\n",
      "Levene statistic: 4.369508336217758\n",
      "Levene p-value: 0.04578807097830151\n"
     ]
    }
   ],
   "source": [
    "# CELDA 7\n",
    "\n",
    "# =========================\n",
    "# COMPARACIÓN DE VOLATILIDAD POR BETA\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Asegurar variables numéricas\n",
    "agg_df['Beta'] = pd.to_numeric(agg_df['Beta'], errors='coerce')\n",
    "agg_df['Volatility'] = pd.to_numeric(agg_df['Volatility'], errors='coerce')\n",
    "\n",
    "# Definición de grupos por Beta\n",
    "volA = agg_df.loc[agg_df['Beta'] <= 1, 'Volatility'].dropna()\n",
    "volB = agg_df.loc[agg_df['Beta'] > 1, 'Volatility'].dropna()\n",
    "\n",
    "print(f\"n volA (Beta ≤ 1): {len(volA)}\")\n",
    "print(f\"n volB (Beta > 1): {len(volB)}\")\n",
    "\n",
    "# Test de Levene (robusto a no-normalidad)\n",
    "if len(volA) >= 2 and len(volB) >= 2:\n",
    "    lev_stat_vol, lev_p_vol = stats.levene(\n",
    "        volA.values,\n",
    "        volB.values,\n",
    "        center='median'\n",
    "    )\n",
    "else:\n",
    "    lev_stat_vol, lev_p_vol = np.nan, np.nan\n",
    "\n",
    "print(\"Levene statistic:\", lev_stat_vol)\n",
    "print(\"Levene p-value:\", lev_p_vol)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c001607c",
   "metadata": {},
   "source": [
    "Implementamos bootstrap para estimar la distribución empírica de la diferencia de medias entre grupos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a03ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 7\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy import stats\n",
    "\n",
    "def _jackknife_theta(x1, x2, func=np.mean):\n",
    "    \"\"\"Devuelve arreglo de estimadores jackknife (omit-1) para theta(func(x1)-func(x2)).\"\"\"\n",
    "    x1 = np.asarray(x1)\n",
    "    x2 = np.asarray(x2)\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    thetas = []\n",
    "    # jackknife over combined? For BCa acceleration for difference of means, compute separately and combine\n",
    "    for i in range(n1):\n",
    "        th1 = func(np.delete(x1, i))\n",
    "        th2 = func(x2) if n2>0 else 0.0\n",
    "        thetas.append(th1 - th2)\n",
    "    for j in range(n2):\n",
    "        th1 = func(x1) if n1>0 else 0.0\n",
    "        th2 = func(np.delete(x2, j))\n",
    "        thetas.append(th1 - th2)\n",
    "    return np.asarray(thetas)\n",
    "\n",
    "def bootstrap_diff_means(x1, x2, n_boot=5000, alpha=0.05, random_state=None,\n",
    "                         method='percentile', return_dist=False, return_all=False):\n",
    "    \"\"\"\n",
    "    Bootstrap para diferencia de medias (x1.mean() - x2.mean()).\n",
    "    \n",
    "    Parámetros:\n",
    "    - x1, x2: array-like o pandas.Series. Se hace dropna() internamente.\n",
    "    - n_boot: número de réplicas bootstrap.\n",
    "    - alpha: nivel (0.05 -> IC 95%).\n",
    "    - random_state: semilla para reproducibilidad.\n",
    "    - method: 'percentile' (por defecto) o 'bca' (BCa bootstrap).\n",
    "    - return_dist: si True devuelve también el array de bootstrap.\n",
    "    - return_all: si True devuelve (boots, ci_percentile, ci_bca_or_none, p_val, obs_diff)\n",
    "                  si False (por defecto) devuelve (ci, p_val) donde ci depende de `method`.\n",
    "    \n",
    "    Retorna:\n",
    "    - si return_all: (boots, ci_percentile, ci_bca_or_none, p_val, obs_diff)\n",
    "    - elif return_dist: (boots, ci, p_val)\n",
    "    - else: (ci, p_val)\n",
    "    \n",
    "    Notas:\n",
    "    - BCa requiere cálculo jackknife; con muestras muy pequeñas puede ser inestable.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x1 = np.asarray(x1.dropna()) if hasattr(x1, \"dropna\") else np.asarray(x1)\n",
    "    x2 = np.asarray(x2.dropna()) if hasattr(x2, \"dropna\") else np.asarray(x2)\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    if n1 < 1 or n2 < 1:\n",
    "        raise ValueError(\"bootstrap_diff_means: ambas muestras deben tener al menos 1 observación\")\n",
    "\n",
    "    # Observed difference\n",
    "    obs_diff = float(np.mean(x1) - np.mean(x2))\n",
    "\n",
    "    # Bootstrap distribution of differences\n",
    "    boots = np.empty(n_boot, dtype=float)\n",
    "    for i in range(n_boot):\n",
    "        s1 = rng.choice(x1, size=n1, replace=True)\n",
    "        s2 = rng.choice(x2, size=n2, replace=True)\n",
    "        boots[i] = s1.mean() - s2.mean()\n",
    "\n",
    "    # Percentile CI\n",
    "    lo_p, hi_p = np.percentile(boots, [100*(alpha/2), 100*(1-alpha/2)])\n",
    "    ci_percentile = (float(lo_p), float(hi_p))\n",
    "\n",
    "    # bootstrap p-value (dos colas) — aproximación basada en proporciones\n",
    "    prop_le = np.mean(boots <= 0)\n",
    "    prop_ge = np.mean(boots >= 0)\n",
    "    p_boot = float(min(1.0, 2 * min(prop_le, prop_ge)))  # simétrica\n",
    "\n",
    "    # Además p-value basado en abs(boots) >= |obs_diff|\n",
    "    p_boot_alt = float(np.mean(np.abs(boots) >= np.abs(obs_diff)))\n",
    "\n",
    "    # BCa calculation (opcional)\n",
    "    ci_bca = None\n",
    "    if method == 'bca':\n",
    "        # Jackknife estimates for acceleration\n",
    "        try:\n",
    "            jack = _jackknife_theta(x1, x2, func=np.mean)\n",
    "            jack_mean = np.mean(jack)\n",
    "            numer = np.sum((jack_mean - jack)**3)\n",
    "            denom = 6.0 * (np.sum((jack_mean - jack)**2) ** 1.5)\n",
    "            if denom == 0:\n",
    "                a = 0.0\n",
    "            else:\n",
    "                a = numer / denom\n",
    "            # bias-correction z0\n",
    "            z0 = stats.norm.ppf(np.mean(boots < obs_diff))\n",
    "            z_lo = stats.norm.ppf(alpha/2)\n",
    "            z_hi = stats.norm.ppf(1 - alpha/2)\n",
    "            # adjusted quantiles\n",
    "            def _adj_quantile(z):\n",
    "                return stats.norm.cdf(z0 + (z + z0) / (1 - a * (z + z0)))\n",
    "            ql = _adj_quantile(z_lo)\n",
    "            qh = _adj_quantile(z_hi)\n",
    "            # guardas\n",
    "            ql = np.clip(ql, 0.0, 1.0)\n",
    "            qh = np.clip(qh, 0.0, 1.0)\n",
    "            lo_bca = np.percentile(boots, 100 * ql)\n",
    "            hi_bca = np.percentile(boots, 100 * qh)\n",
    "            ci_bca = (float(lo_bca), float(hi_bca))\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"BCa calculado falló o es inestable: {e}. Se devuelve None para ci_bca.\")\n",
    "            ci_bca = None\n",
    "\n",
    "    # Construcción de salida\n",
    "    if return_all:\n",
    "        return boots, ci_percentile, ci_bca, p_boot, p_boot_alt, obs_diff\n",
    "    if return_dist:\n",
    "        ci = ci_bca if (method == 'bca' and ci_bca is not None) else ci_percentile\n",
    "        return boots, ci, p_boot\n",
    "    ci = ci_bca if (method == 'bca' and ci_bca is not None) else ci_percentile\n",
    "    return ci, p_boot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e436e59e",
   "metadata": {},
   "source": [
    "Para cada empresa estimamos:\n",
    "R_it = alpha_i + beta_i * R_m,t + eps_it\n",
    "- Reportamos coeficiente beta, se, t-stat, p-value\n",
    "- Diagnostic: residuales, normalidad, heterocedasticidad\n",
    "- Además: estimación de beta robusta (HC standard errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876786a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observada (x1.mean - x2.mean): -0.0428639526219806\n",
      "IC 95% (percentile): (-0.07011851699856504, -0.01934058117727427)\n",
      "IC 95% (BCa): (-0.0742913165215815, -0.021518099695994664)\n",
      "Bootstrap p-value (simétrico): 0.0\n",
      "Bootstrap p-value (abs rule): 0.4874\n",
      "✅ Bootstrap realizado y guardado. Archivo: boots_diff_means.npy y bootstrap_diff_summary.json\n"
     ]
    }
   ],
   "source": [
    "# CELDA 8\n",
    "\n",
    "# Asumo volA / volB (o groupA / groupB) ya definidas (como Series)\n",
    "x1 = volA.dropna()   # o groupA\n",
    "x2 = volB.dropna()   # o groupB\n",
    "\n",
    "# Parám. de bootstrap\n",
    "NBOOT = 5000\n",
    "ALPHA = 0.05\n",
    "SEED = 42\n",
    "\n",
    "# Ejecutar: obtener distribución, CI (percentile) y p-value\n",
    "boots, ci_used, p_boot = bootstrap_diff_means(x1, x2, n_boot=NBOOT,\n",
    "                                             alpha=ALPHA, random_state=SEED,\n",
    "                                             method='percentile', return_dist=True)\n",
    "\n",
    "# Alternativamente, también obtener BCa\n",
    "boots_b, ci_percentile, ci_bca, p_boot1, p_boot2, obs_diff = bootstrap_diff_means(\n",
    "    x1, x2, n_boot=NBOOT, alpha=ALPHA, random_state=SEED, method='bca', return_all=True\n",
    ")\n",
    "\n",
    "# Mostrar resultados (elige el que prefieras)\n",
    "print(\"Observada (x1.mean - x2.mean):\", obs_diff)\n",
    "print(\"IC 95% (percentile):\", ci_percentile)\n",
    "print(\"IC 95% (BCa):\", ci_bca)\n",
    "print(\"Bootstrap p-value (simétrico):\", p_boot1)\n",
    "print(\"Bootstrap p-value (abs rule):\", p_boot2)\n",
    "\n",
    "# Guardar distribución bootstrap (opcional) y resumen\n",
    "import os\n",
    "np.save(os.path.join(PROCESSED_DIR, 'boots_diff_means.npy'), boots)\n",
    "\n",
    "summary_boot = {\n",
    "    'obs_diff': float(obs_diff),\n",
    "    'ci_percentile_low': float(ci_percentile[0]),\n",
    "    'ci_percentile_high': float(ci_percentile[1]),\n",
    "    'ci_bca_low': (float(ci_bca[0]) if ci_bca is not None else None),\n",
    "    'ci_bca_high': (float(ci_bca[1]) if ci_bca is not None else None),\n",
    "    'p_boot_sym': float(p_boot1),\n",
    "    'p_boot_absrule': float(p_boot2),\n",
    "    'n_boot': int(NBOOT)\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(os.path.join(PROCESSED_DIR, 'bootstrap_diff_summary.json'), 'w') as f:\n",
    "    json.dump(summary_boot, f, indent=4)\n",
    "\n",
    "print(\"✅ Bootstrap realizado y guardado. Archivo: boots_diff_means.npy y bootstrap_diff_summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c2bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 9\n",
    "\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_monthly_market_returns(\n",
    "    ticker=\"QQQ\",\n",
    "    start=\"2018-01-01\",\n",
    "    end=\"2024-12-31\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Descarga precios del mercado y calcula retornos logarítmicos mensuales.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ticker : str\n",
    "        ETF representativo del mercado (default: QQQ - sector tecnológico)\n",
    "    start : str\n",
    "        Fecha inicial (YYYY-MM-DD)\n",
    "    end : str\n",
    "        Fecha final (YYYY-MM-DD)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con índice de fecha mensual y columna 'MarketReturn'\n",
    "    \"\"\"\n",
    "\n",
    "    # Descargar datos\n",
    "    market = yf.download(\n",
    "        ticker,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        auto_adjust=True,\n",
    "        progress=False\n",
    "    )\n",
    "\n",
    "    if market.empty:\n",
    "        raise ValueError(\"No se descargaron datos del mercado.\")\n",
    "\n",
    "    # Selección explícita del precio de cierre\n",
    "    if \"Close\" in market.columns:\n",
    "        price = market[\"Close\"]\n",
    "    else:\n",
    "        price = market.iloc[:, 0]\n",
    "\n",
    "    price.index = pd.to_datetime(price.index)\n",
    "\n",
    "    # Precio de fin de mes\n",
    "    monthly_price = price.resample(\"ME\").last()\n",
    "\n",
    "    if monthly_price.isna().all():\n",
    "        raise ValueError(\"Serie mensual vacía tras el resampleo.\")\n",
    "\n",
    "    # Retornos logarítmicos mensuales\n",
    "    monthly_return = np.log(monthly_price / monthly_price.shift(1)).dropna()\n",
    "\n",
    "    # Construcción del DataFrame final\n",
    "    market_df = pd.DataFrame({\n",
    "        \"Date\": monthly_return.index,\n",
    "        \"MarketReturn\": monthly_return.values\n",
    "    })\n",
    "\n",
    "    # Formato de fecha consistente con panel_df\n",
    "    market_df[\"Date\"] = market_df[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return market_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ccc3f",
   "metadata": {},
   "source": [
    "Calculamos potencia post-hoc para comparaciones de medias (dos muestras) y, cuando corresponda, potencia a priori para detectar un efecto mínimo significativo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb8d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's d observado: -0.8634\n",
      "Potencia estimada del test: 0.6247\n"
     ]
    }
   ],
   "source": [
    "# CELDA 10\n",
    "\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "import numpy as np\n",
    "\n",
    "def compute_power_two_sample(n1, n2, effect_size, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calcula la potencia de un t-test de dos muestras independientes\n",
    "    para un tamaño de efecto dado (Cohen's d).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n1, n2 : int\n",
    "        Tamaño de las muestras\n",
    "    effect_size : float\n",
    "        Tamaño del efecto (Cohen's d)\n",
    "    alpha : float\n",
    "        Nivel de significancia\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    power : float\n",
    "        Potencia estimada del test\n",
    "    \"\"\"\n",
    "    analysis = TTestIndPower()\n",
    "    power = analysis.power(effect_size=effect_size,\n",
    "                           nobs1=n1,\n",
    "                           alpha=alpha,\n",
    "                           ratio=n2/n1)\n",
    "    return power\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Cálculo de Cohen's d observado\n",
    "# ----------------------------\n",
    "if len(groupA) < 2 or len(groupB) < 2:\n",
    "    raise ValueError(\"Ambos grupos deben tener al menos 2 observaciones.\")\n",
    "\n",
    "mean1, mean2 = groupA.mean(), groupB.mean()\n",
    "sd1, sd2 = groupA.std(ddof=1), groupB.std(ddof=1)\n",
    "n1, n2 = len(groupA), len(groupB)\n",
    "\n",
    "# Pooled SD ponderada por tamaño de muestra\n",
    "pooled_sd = np.sqrt(((n1 - 1)*sd1**2 + (n2 - 1)*sd2**2) / (n1 + n2 - 2))\n",
    "cohen_d = (mean1 - mean2) / pooled_sd\n",
    "\n",
    "# Potencia observada\n",
    "power_obs = compute_power_two_sample(n1, n2, abs(cohen_d), alpha=0.05)\n",
    "\n",
    "print(f\"Cohen's d observado: {cohen_d:.4f}\")\n",
    "print(f\"Potencia estimada del test: {power_obs:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aabfabc",
   "metadata": {},
   "source": [
    "Guardamos las tablas principales:\n",
    "- ci_df (intervalos de confianza)\n",
    "- tt_df (one-sample t-tests)\n",
    "- capm_df (regresión CAPM)\n",
    "- resultados de comparación por grupos\n",
    "Además se incluye texto ejemplo para el informe con la interpretación de resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac457d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Retornos de mercado construidos: (83, 1)\n",
      "✓ CAPM estimado para 30 empresas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>se_beta</th>\n",
       "      <th>t_beta</th>\n",
       "      <th>p_beta</th>\n",
       "      <th>R2</th>\n",
       "      <th>DW</th>\n",
       "      <th>bp_stat</th>\n",
       "      <th>bp_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Palantir</td>\n",
       "      <td>51</td>\n",
       "      <td>0.010507</td>\n",
       "      <td>2.273104</td>\n",
       "      <td>0.505728</td>\n",
       "      <td>4.494719</td>\n",
       "      <td>6.966175e-06</td>\n",
       "      <td>0.407508</td>\n",
       "      <td>2.487115</td>\n",
       "      <td>3.766133</td>\n",
       "      <td>0.052300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>83</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>1.738543</td>\n",
       "      <td>0.269782</td>\n",
       "      <td>6.444243</td>\n",
       "      <td>1.161786e-10</td>\n",
       "      <td>0.364470</td>\n",
       "      <td>1.787697</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.962471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>83</td>\n",
       "      <td>0.012835</td>\n",
       "      <td>1.623679</td>\n",
       "      <td>0.158795</td>\n",
       "      <td>10.225022</td>\n",
       "      <td>1.531939e-24</td>\n",
       "      <td>0.575616</td>\n",
       "      <td>1.708348</td>\n",
       "      <td>0.140266</td>\n",
       "      <td>0.708017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cloudflare</td>\n",
       "      <td>63</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>1.507436</td>\n",
       "      <td>0.280202</td>\n",
       "      <td>5.379817</td>\n",
       "      <td>7.456147e-08</td>\n",
       "      <td>0.317665</td>\n",
       "      <td>2.030644</td>\n",
       "      <td>0.127699</td>\n",
       "      <td>0.720830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spotify</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.011249</td>\n",
       "      <td>1.504924</td>\n",
       "      <td>0.145970</td>\n",
       "      <td>10.309825</td>\n",
       "      <td>6.361711e-25</td>\n",
       "      <td>0.559768</td>\n",
       "      <td>2.001168</td>\n",
       "      <td>0.036438</td>\n",
       "      <td>0.848613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company  n_obs     alpha      beta   se_beta     t_beta        p_beta  \\\n",
       "0    Palantir     51  0.010507  2.273104  0.505728   4.494719  6.966175e-06   \n",
       "1       Tesla     83  0.008110  1.738543  0.269782   6.444243  1.161786e-10   \n",
       "2      Nvidia     83  0.012835  1.623679  0.158795  10.225022  1.531939e-24   \n",
       "3  Cloudflare     63  0.000620  1.507436  0.280202   5.379817  7.456147e-08   \n",
       "4     Spotify     80 -0.011249  1.504924  0.145970  10.309825  6.361711e-25   \n",
       "\n",
       "         R2        DW   bp_stat      bp_p  \n",
       "0  0.407508  2.487115  3.766133  0.052300  \n",
       "1  0.364470  1.787697  0.002214  0.962471  \n",
       "2  0.575616  1.708348  0.140266  0.708017  \n",
       "3  0.317665  2.030644  0.127699  0.720830  \n",
       "4  0.559768  2.001168  0.036438  0.848613  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELDA 11\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Construir retorno de mercado\n",
    "# -----------------------------\n",
    "market_returns = (\n",
    "    panel_df.groupby(\"Date\")[\"Return\"]\n",
    "    .mean()\n",
    "    .dropna()\n",
    "    .to_frame(name=\"MarketReturn\")\n",
    ")\n",
    "market_returns.index = market_returns.index.astype(str)\n",
    "\n",
    "print(f\"✓ Retornos de mercado construidos: {market_returns.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Función CAPM robusta\n",
    "# -----------------------------\n",
    "def estimate_capm(company, panel_df, market_returns):\n",
    "    \"\"\"\n",
    "    Estima CAPM para una empresa dada usando OLS con errores robustos HC1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    company : str\n",
    "        Nombre de la empresa\n",
    "    panel_df : pd.DataFrame\n",
    "        Panel de retornos con columnas ['Company', 'Date', 'Return']\n",
    "    market_returns : pd.DataFrame\n",
    "        Retornos de mercado con índice de fecha y columna 'MarketReturn'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Diccionario con resultados CAPM: beta, alpha, t_beta, p_beta, R2, DW, BP\n",
    "        None si la empresa tiene menos de 12 observaciones válidas.\n",
    "    \"\"\"\n",
    "    df_i = panel_df[panel_df[\"Company\"] == company].copy()\n",
    "    df_i[\"Date\"] = df_i[\"Date\"].astype(str)\n",
    "\n",
    "    df = df_i.merge(\n",
    "        market_returns,\n",
    "        left_on=\"Date\",\n",
    "        right_index=True,\n",
    "        how=\"inner\"\n",
    "    ).dropna(subset=[\"Return\", \"MarketReturn\"])\n",
    "\n",
    "    if len(df) < 12:  # mínimo 1 año\n",
    "        return None\n",
    "\n",
    "    X = sm.add_constant(df[\"MarketReturn\"])\n",
    "    y = df[\"Return\"]\n",
    "\n",
    "    model = sm.OLS(y, X).fit(cov_type=\"HC1\")  # errores robustos\n",
    "\n",
    "    resid = model.resid\n",
    "    dw = durbin_watson(resid)\n",
    "    bp_stat, bp_p, _, _ = het_breuschpagan(resid, model.model.exog)\n",
    "\n",
    "    return {\n",
    "        \"Company\": company,\n",
    "        \"n_obs\": len(df),\n",
    "        \"alpha\": float(model.params[\"const\"]),\n",
    "        \"beta\": float(model.params[\"MarketReturn\"]),\n",
    "        \"se_beta\": float(model.bse[\"MarketReturn\"]),\n",
    "        \"t_beta\": float(model.tvalues[\"MarketReturn\"]),\n",
    "        \"p_beta\": float(model.pvalues[\"MarketReturn\"]),\n",
    "        \"R2\": float(model.rsquared),\n",
    "        \"DW\": float(dw),\n",
    "        \"bp_stat\": float(bp_stat),\n",
    "        \"bp_p\": float(bp_p)\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Ejecutar CAPM para todas las empresas\n",
    "# -----------------------------\n",
    "companies = sorted(panel_df[\"Company\"].unique())\n",
    "capm_results = []\n",
    "\n",
    "for company in companies:\n",
    "    res = estimate_capm(company, panel_df, market_returns)\n",
    "    if res is not None:\n",
    "        capm_results.append(res)\n",
    "\n",
    "capm_df = (\n",
    "    pd.DataFrame(capm_results)\n",
    "    .sort_values(\"beta\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"✓ CAPM estimado para {capm_df.shape[0]} empresas\")\n",
    "capm_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a1cb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Todos los resultados finales fueron guardados correctamente en /data/processed\n"
     ]
    }
   ],
   "source": [
    "# CELDA 12\n",
    "\n",
    "# =========================\n",
    "# GUARDAR RESULTADOS FINALES (VERSIÓN PROFESIONAL)\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "processed_path = Path(PROCESSED_DIR)\n",
    "processed_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Comprobaciones mínimas ----------\n",
    "required_vars = [\"ci_df\", \"tt_df\", \"capm_df\", \"out_df\"]\n",
    "missing = [v for v in required_vars if v not in globals()]\n",
    "if missing:\n",
    "    raise NameError(f\"Faltan variables necesarias: {missing}\")\n",
    "\n",
    "# ---------- Guardar CSVs ----------\n",
    "ci_df.to_csv(processed_path / \"ci_mean_by_company.csv\", index=False)\n",
    "tt_df.to_csv(processed_path / \"one_sample_ttests_by_company.csv\", index=False)\n",
    "capm_df.to_csv(processed_path / \"capm_by_company.csv\", index=False)\n",
    "out_df.to_csv(processed_path / \"group_beta_comparison_summary.csv\", index=False)\n",
    "\n",
    "# ---------- Guardar resumen JSON ----------\n",
    "if not out_df.empty:\n",
    "    row = out_df.iloc[0]\n",
    "\n",
    "    group_summary = {\n",
    "        \"groupA_n\": int(row.get(\"n_groupA\", 0)),\n",
    "        \"groupA_mean\": float(row.get(\"mean_A\", np.nan)),\n",
    "        \"groupA_sd\": float(row.get(\"sd_A\", np.nan)),\n",
    "\n",
    "        \"groupB_n\": int(row.get(\"n_groupB\", 0)),\n",
    "        \"groupB_mean\": float(row.get(\"mean_B\", np.nan)),\n",
    "        \"groupB_sd\": float(row.get(\"sd_B\", np.nan)),\n",
    "\n",
    "        \"welch_t\": float(row.get(\"welch_t\", np.nan)),\n",
    "        \"welch_p\": float(row.get(\"welch_p\", np.nan)),\n",
    "        \"welch_CI\": [\n",
    "            float(row.get(\"welch_CI_low\", np.nan)),\n",
    "            float(row.get(\"welch_CI_high\", np.nan))\n",
    "        ],\n",
    "\n",
    "        \"mw_p\": float(row.get(\"mw_p\", np.nan)),\n",
    "        \"perm_p\": float(row.get(\"perm_p\", np.nan)),\n",
    "        \"bootstrap_diff_CI\": [\n",
    "            float(row.get(\"boot_diff_CI_low\", np.nan)),\n",
    "            float(row.get(\"boot_diff_CI_high\", np.nan))\n",
    "        ],\n",
    "        \"bootstrap_p\": float(row.get(\"boot_diff_p\", np.nan)),\n",
    "\n",
    "        \"hedges_g\": float(row.get(\"hedges_g\", np.nan))\n",
    "    }\n",
    "\n",
    "    with open(processed_path / \"group_beta_comparison_summary.json\", \"w\") as f:\n",
    "        json.dump(group_summary, f, indent=4)\n",
    "\n",
    "    print(\"✅ Todos los resultados finales fueron guardados correctamente en /data/processed\")\n",
    "else:\n",
    "    print(\"⚠️ out_df está vacío, no se guardó resumen JSON\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a5acf0",
   "metadata": {},
   "source": [
    "### Ejemplo de reporte (formato académico)\n",
    "\n",
    "**Intervalos de confianza para el retorno medio.** Para cada empresa se calculó el intervalo de confianza del 95\\% para el retorno medio usando la t-Student (varianza desconocida) y un intervalo bootstrap percentile con 3000 réplicas. Por ejemplo, Microsoft presenta retorno medio \\(\\hat\\mu = 0.0180\\) con IC t 95\\% = [0.007, 0.029] y bootstrap 95\\% = [0.006, 0.030]. Estos intervalos indican que el retorno mensual promedio es positivo y significativamente distinto de cero.\n",
    "\n",
    "**Pruebas de hipótesis (H0: μ=0).** Se aplicó un test t de una muestra a cada empresa y se ajustaron los p-values usando Bonferroni y Benjamini–Hochberg para controlar error tipo I. Reportamos las empresas cuyo p-valor ajustado (FDR) < 0.05. Para estas empresas rechazamos H0 y concluimos que su retorno medio está estadísticamente diferenciado de cero.\n",
    "\n",
    "**Comparación por grupos (Beta).** Las empresas fueron divididas en Beta ≤ 1 y Beta > 1. Se aplicó Levene para igualdad de varianzas, Welch t-test para diferencia de medias y Mann–Whitney como alternativa no paramétrica. Además, se realizó un test de permutación para robustez. Los resultados muestran que [aquí insertar conclusión basada en resultados].\n",
    "\n",
    "**Regresión CAPM.** Para cada empresa se estimó \\(R_{i,t} = \\alpha_i + \\beta_i R_{m,t} + \\varepsilon_{i,t}\\) por OLS con errores robustos HC1. Se reportaron \\(\\hat\\beta\\), error estándar robusto, t-stat y p-value. Para la mayoría de empresas \\(\\hat\\beta\\) es significativo (p < 0.05), lo que sugiere sensibilidad al mercado. Se presentan diagnósticos (Breusch–Pagan, Durbin–Watson) para evaluar heterocedasticidad y autocorrelación. Cuando se detecta heterocedasticidad se interpretan β con SE robustos.\n",
    "\n",
    "**Robustez.** Se implementaron bootstrap y pruebas no paramétricas para confirmar la validez de las conclusiones bajo violaciones de supuestos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
