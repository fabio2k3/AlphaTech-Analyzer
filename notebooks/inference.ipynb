{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737878aa",
   "metadata": {},
   "source": [
    "# Inference — Fase 3\n",
    "En este notebook se implementan los procedimientos de inferencia estadística planificados en la Fase 2:\n",
    "- Intervalos de confianza para media y volatilidad\n",
    "- Tests t (una muestra, dos muestras, Welch)\n",
    "- Pruebas de varianzas (Levene / F)\n",
    "- Alternativas no paramétricas\n",
    "- Bootstrap\n",
    "- Correcciones por comparaciones múltiples\n",
    "- Regresión CAPM con diagnóstico y errores robustos\n",
    "- Análisis de potencia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe14a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.power import TTestIndPower, TTestPower\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "from statsmodels.stats.api import CompareMeans, DescrStatsW\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# rutas (notebook en /notebooks)\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.dirname(NOTEBOOK_DIR)\n",
    "PROCESSED_DIR = os.path.join(PROJECT_ROOT, \"data\", \"processed\")\n",
    "\n",
    "PANEL_FILE = os.path.join(PROCESSED_DIR, \"tech30_panel_monthly_2018_2024.csv\")\n",
    "AGG_FILE   = os.path.join(PROCESSED_DIR, \"tech30_aggregated_stats_2018_2024.csv\")\n",
    "\n",
    "assert os.path.exists(PANEL_FILE), f\"No se encontró {PANEL_FILE}\"\n",
    "assert os.path.exists(AGG_FILE), f\"No se encontró {AGG_FILE}\"\n",
    "\n",
    "panel_df = pd.read_csv(PANEL_FILE, parse_dates=['Date'])\n",
    "agg_df = pd.read_csv(AGG_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696cc66a",
   "metadata": {},
   "source": [
    "Antes de aplicar pruebas formales:\n",
    "- verificamos distribución de retornos por empresa (normalidad)\n",
    "- revisamos tamaño muestral T (~n meses por empresa)\n",
    "- revisamos si usar pruebas paramétricas o no paramétricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a97c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# UTIL: intervalo t para la media\n",
    "# ------------------------------\n",
    "def ci_mean_t(x, alpha=0.05):\n",
    "    x = np.array(x.dropna()) if hasattr(x, \"dropna\") else np.array(x)\n",
    "    n = len(x)\n",
    "    mean = np.mean(x)\n",
    "    s = np.std(x, ddof=1)\n",
    "    se = s / np.sqrt(n)\n",
    "    df = n - 1\n",
    "    tval = stats.t.ppf(1 - alpha/2, df)\n",
    "    ci_low = mean - tval * se\n",
    "    ci_high = mean + tval * se\n",
    "    return mean, se, df, (ci_low, ci_high)\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: bootstrap CI para la media\n",
    "# ------------------------------\n",
    "def bootstrap_ci_mean(x, n_boot=5000, alpha=0.05, random_state=0):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x = np.array(x.dropna()) if hasattr(x, \"dropna\") else np.array(x)\n",
    "    n = len(x)\n",
    "    boots = np.empty(n_boot)\n",
    "    for i in range(n_boot):\n",
    "        sample = rng.choice(x, size=n, replace=True)\n",
    "        boots[i] = sample.mean()\n",
    "    lower = np.percentile(boots, 100*(alpha/2))\n",
    "    upper = np.percentile(boots, 100*(1-alpha/2))\n",
    "    return (np.mean(x), (lower, upper), boots)\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: one-sample t-test (H0: mean = mu0)\n",
    "# ------------------------------\n",
    "def one_sample_ttest(x, mu0=0.0):\n",
    "    x = np.array(x.dropna()) if hasattr(x, \"dropna\") else np.array(x)\n",
    "    res = stats.ttest_1samp(x, popmean=mu0, alternative='two-sided')\n",
    "    # scipy <1.9 may not have alternative argument; if not, compute two-sided and adjust\n",
    "    return res\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: welch two-sample t-test\n",
    "# ------------------------------\n",
    "def welch_ttest(x1, x2, alternative='two-sided'):\n",
    "    x1 = np.array(x1.dropna())\n",
    "    x2 = np.array(x2.dropna())\n",
    "    res = stats.ttest_ind(x1, x2, equal_var=False)\n",
    "    return res\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: levene test for equal variances\n",
    "# ------------------------------\n",
    "def levene_test(x1, x2):\n",
    "    return stats.levene(x1.dropna(), x2.dropna())\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: mann-whitney U test\n",
    "# ------------------------------\n",
    "def mannwhitney_test(x1, x2):\n",
    "    return stats.mannwhitneyu(x1.dropna(), x2.dropna(), alternative='two-sided')\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: permutation test for difference of means (two-sided)\n",
    "# ------------------------------\n",
    "def permutation_test_diff_means(x1, x2, n_perm=5000, random_state=0):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x1 = np.array(x1.dropna())\n",
    "    x2 = np.array(x2.dropna())\n",
    "    obs_diff = np.mean(x1) - np.mean(x2)\n",
    "    pooled = np.concatenate([x1, x2])\n",
    "    n1 = len(x1)\n",
    "    perm_diffs = np.empty(n_perm)\n",
    "    for i in range(n_perm):\n",
    "        perm = rng.permutation(pooled)\n",
    "        perm_diffs[i] = perm[:n1].mean() - perm[n1:].mean()\n",
    "    p_value = np.mean(np.abs(perm_diffs) >= np.abs(obs_diff))\n",
    "    return obs_diff, p_value, perm_diffs\n",
    "\n",
    "# ------------------------------\n",
    "# UTIL: apply corrections\n",
    "# ------------------------------\n",
    "def apply_multiple_corrections(pvals, method='fdr_bh'):\n",
    "    # method options: 'bonferroni', 'fdr_bh' (Benjamini-Hochberg)\n",
    "    reject, pvals_corrected, _, _ = multipletests(pvals, alpha=0.05, method=method)\n",
    "    return reject, pvals_corrected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7957b",
   "metadata": {},
   "source": [
    "Procedimiento:\n",
    "- Para cada empresa: Shapiro-Wilk (o Lilliefors) sobre retornos (si n pequeño usar Shapiro)\n",
    "- Si la mayoría viola normalidad (p < 0.05), preferir pruebas no paramétricas o bootstrap\n",
    "- Guardaremos un resumen con n, p_shapiro, decisión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d37b7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>n</th>\n",
       "      <th>shapiro_stat</th>\n",
       "      <th>shapiro_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>83</td>\n",
       "      <td>0.845255</td>\n",
       "      <td>7.423516e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SAP</td>\n",
       "      <td>83</td>\n",
       "      <td>0.935816</td>\n",
       "      <td>4.464753e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Intel</td>\n",
       "      <td>83</td>\n",
       "      <td>0.943477</td>\n",
       "      <td>1.170462e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Palantir</td>\n",
       "      <td>51</td>\n",
       "      <td>0.914936</td>\n",
       "      <td>1.378993e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Meta Platforms</td>\n",
       "      <td>83</td>\n",
       "      <td>0.949261</td>\n",
       "      <td>2.506951e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Broadcom</td>\n",
       "      <td>83</td>\n",
       "      <td>0.963013</td>\n",
       "      <td>1.734127e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Snowflake</td>\n",
       "      <td>51</td>\n",
       "      <td>0.945631</td>\n",
       "      <td>2.078493e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>83</td>\n",
       "      <td>0.966265</td>\n",
       "      <td>2.806939e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>83</td>\n",
       "      <td>0.969379</td>\n",
       "      <td>4.481786e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>83</td>\n",
       "      <td>0.970199</td>\n",
       "      <td>5.073450e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Company   n  shapiro_stat     shapiro_p\n",
       "15         Netflix  83      0.845255  7.423516e-08\n",
       "19             SAP  83      0.935816  4.464753e-04\n",
       "12           Intel  83      0.943477  1.170462e-03\n",
       "18        Palantir  51      0.914936  1.378993e-03\n",
       "13  Meta Platforms  83      0.949261  2.506951e-03\n",
       "6         Broadcom  83      0.963013  1.734127e-02\n",
       "23       Snowflake  51      0.945631  2.078493e-02\n",
       "1        Accenture  83      0.966265  2.806939e-02\n",
       "11         Infosys  83      0.969379  4.481786e-02\n",
       "16          Nvidia  83      0.970199  5.073450e-02"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normality_summary(panel_df):\n",
    "    rows = []\n",
    "    companies = sorted(panel_df['Company'].unique())\n",
    "    for c in companies:\n",
    "        r = panel_df.loc[panel_df['Company']==c, 'Return'].dropna()\n",
    "        n = len(r)\n",
    "        if n < 3:\n",
    "            pval = np.nan\n",
    "            stat = np.nan\n",
    "        else:\n",
    "            try:\n",
    "                stat, pval = stats.shapiro(r)\n",
    "            except Exception:\n",
    "                # fallback to Lilliefors\n",
    "                stat, pval = lilliefors(r)\n",
    "        rows.append({'Company':c, 'n':n, 'shapiro_stat':stat, 'shapiro_p':pval})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "norm_summary = normality_summary(panel_df)\n",
    "norm_summary.sort_values('shapiro_p').head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865602cb",
   "metadata": {},
   "source": [
    "Calculamos:\n",
    "- IC t (clásico) para la media de retornos por empresa\n",
    "- IC bootstrap (percentil) para robustez\n",
    "Guardamos una tabla con mean, se, df, ci_t_low, ci_t_high, ci_boot_low, ci_boot_high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "913f73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for c in sorted(panel_df['Company'].unique()):\n",
    "    r = panel_df.loc[panel_df['Company']==c, 'Return'].dropna()\n",
    "    if len(r) < 2:\n",
    "        continue\n",
    "    mean, se, df, (ci_low, ci_high) = ci_mean_t(r, alpha=0.05)\n",
    "    mean_b, (boot_lo, boot_hi), boots = bootstrap_ci_mean(r, n_boot=3000)\n",
    "    results.append({\n",
    "        'Company': c,\n",
    "        'n': len(r),\n",
    "        'MeanReturn': mean,\n",
    "        'SE': se,\n",
    "        'df': df,\n",
    "        'CI_t_low': ci_low,\n",
    "        'CI_t_high': ci_high,\n",
    "        'CI_boot_low': boot_lo,\n",
    "        'CI_boot_high': boot_hi\n",
    "    })\n",
    "\n",
    "ci_df = pd.DataFrame(results).sort_values('MeanReturn', ascending=False)\n",
    "ci_df.head()\n",
    "# guardar\n",
    "ci_df.to_csv(os.path.join(PROCESSED_DIR, 'inference_mean_CI_by_company.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1b7d3",
   "metadata": {},
   "source": [
    "Muchos trabajos en finanzas prueban si el retorno medio es significativamente distinto de cero.\n",
    "Realizamos la prueba t de una muestra para cada empresa y guardamos p-values y estadístico.\n",
    "Aplicaremos correcciones por comparaciones múltiples (Bonferroni y FDR).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94121d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>n</th>\n",
       "      <th>tstat</th>\n",
       "      <th>pval</th>\n",
       "      <th>mean</th>\n",
       "      <th>p_bonf</th>\n",
       "      <th>p_fdr</th>\n",
       "      <th>reject_bonf</th>\n",
       "      <th>reject_fdr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Broadcom</td>\n",
       "      <td>83</td>\n",
       "      <td>2.942288</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.029832</td>\n",
       "      <td>0.127044</td>\n",
       "      <td>0.068911</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>83</td>\n",
       "      <td>2.914284</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.018964</td>\n",
       "      <td>0.137822</td>\n",
       "      <td>0.068911</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ServiceNow</td>\n",
       "      <td>83</td>\n",
       "      <td>2.737873</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.023737</td>\n",
       "      <td>0.227466</td>\n",
       "      <td>0.075822</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>83</td>\n",
       "      <td>2.436684</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.037576</td>\n",
       "      <td>0.509623</td>\n",
       "      <td>0.104925</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apple</td>\n",
       "      <td>83</td>\n",
       "      <td>2.425393</td>\n",
       "      <td>0.017488</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>0.524625</td>\n",
       "      <td>0.104925</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fortinet</td>\n",
       "      <td>83</td>\n",
       "      <td>2.345041</td>\n",
       "      <td>0.021442</td>\n",
       "      <td>0.028135</td>\n",
       "      <td>0.643266</td>\n",
       "      <td>0.107211</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Taiwan Semiconductor</td>\n",
       "      <td>83</td>\n",
       "      <td>1.950126</td>\n",
       "      <td>0.054578</td>\n",
       "      <td>0.020067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.233907</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Oracle</td>\n",
       "      <td>83</td>\n",
       "      <td>1.801174</td>\n",
       "      <td>0.075352</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.262313</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alphabet</td>\n",
       "      <td>83</td>\n",
       "      <td>1.780526</td>\n",
       "      <td>0.078694</td>\n",
       "      <td>0.014190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.262313</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>83</td>\n",
       "      <td>1.667516</td>\n",
       "      <td>0.099227</td>\n",
       "      <td>0.034602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297680</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company   n     tstat      pval      mean    p_bonf  \\\n",
       "6               Broadcom  83  2.942288  0.004235  0.029832  0.127044   \n",
       "14             Microsoft  83  2.914284  0.004594  0.018964  0.137822   \n",
       "22            ServiceNow  83  2.737873  0.007582  0.023737  0.227466   \n",
       "16                Nvidia  83  2.436684  0.016987  0.037576  0.509623   \n",
       "5                  Apple  83  2.425393  0.017488  0.022371  0.524625   \n",
       "9               Fortinet  83  2.345041  0.021442  0.028135  0.643266   \n",
       "26  Taiwan Semiconductor  83  1.950126  0.054578  0.020067  1.000000   \n",
       "17                Oracle  83  1.801174  0.075352  0.015425  1.000000   \n",
       "3               Alphabet  83  1.780526  0.078694  0.014190  1.000000   \n",
       "28                 Tesla  83  1.667516  0.099227  0.034602  1.000000   \n",
       "\n",
       "       p_fdr  reject_bonf  reject_fdr  \n",
       "6   0.068911        False       False  \n",
       "14  0.068911        False       False  \n",
       "22  0.075822        False       False  \n",
       "16  0.104925        False       False  \n",
       "5   0.104925        False       False  \n",
       "9   0.107211        False       False  \n",
       "26  0.233907        False       False  \n",
       "17  0.262313        False       False  \n",
       "3   0.262313        False       False  \n",
       "28  0.297680        False       False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_results = []\n",
    "for c in sorted(panel_df['Company'].unique()):\n",
    "    r = panel_df.loc[panel_df['Company']==c, 'Return'].dropna()\n",
    "    if len(r) < 2:\n",
    "        continue\n",
    "    tstat, pval = stats.ttest_1samp(r, popmean=0.0)\n",
    "    tt_results.append({'Company':c, 'n':len(r), 'tstat':tstat, 'pval':pval, 'mean':r.mean()})\n",
    "\n",
    "tt_df = pd.DataFrame(tt_results).sort_values('pval')\n",
    "# Correcciones\n",
    "reject_bonf, pvals_bonf = multipletests(tt_df['pval'], alpha=0.05, method='bonferroni')[:2]\n",
    "reject_fdr, pvals_fdr = multipletests(tt_df['pval'], alpha=0.05, method='fdr_bh')[:2]\n",
    "\n",
    "tt_df['p_bonf'] = pvals_bonf\n",
    "tt_df['p_fdr'] = pvals_fdr\n",
    "tt_df['reject_bonf'] = reject_bonf\n",
    "tt_df['reject_fdr'] = reject_fdr\n",
    "\n",
    "tt_df.to_csv(os.path.join(PROCESSED_DIR, 'one_sample_ttest_results.csv'), index=False)\n",
    "tt_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278d3f1",
   "metadata": {},
   "source": [
    "- Si p < alpha (ajustado), rechazamos H0: μ = 0 y decimos que el retorno medio es significativamente distinto de 0.\n",
    "- Reportar siempre: mean, t-stat, p, p ajustada, IC.\n",
    "- En la discusión: comentar tamaño del efecto (mean) y su relevancia económica, no solo p-value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888b2a2",
   "metadata": {},
   "source": [
    "Definimos grupos basados en Beta (del dataset agregado).  \n",
    "Haremos: Levene (varianzas), Welch t-test (medias), Mann-Whitney (no paramétrica) y permutation test (robusto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09bfee7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n groupA, groupB: 16 14\n",
      "Levene p: 0.9176256160621237\n",
      "Welch t-test: TtestResult(statistic=np.float64(-2.3686761526706204), pvalue=np.float64(0.025035992478887558), df=np.float64(27.819724586620843))\n",
      "Mann-Whitney p: 0.043782028935725754\n",
      "Permutation p: 0.0262\n"
     ]
    }
   ],
   "source": [
    "# merge beta info onto panel\n",
    "beta_map = agg_df.set_index('Company')['Beta'].to_dict()\n",
    "panel_df['Beta'] = panel_df['Company'].map(beta_map)\n",
    "panel_df['Beta_group'] = panel_df['Beta'].apply(lambda x: 'low' if x<=1 else 'high')\n",
    "\n",
    "# compute group series of company-averaged returns (MeanReturn already exists in agg_df)\n",
    "groupA = agg_df.loc[agg_df['Beta'] <= 1, 'MeanReturn']\n",
    "groupB = agg_df.loc[agg_df['Beta'] > 1, 'MeanReturn']\n",
    "\n",
    "print(\"n groupA, groupB:\", len(groupA), len(groupB))\n",
    "\n",
    "# Levene test on company-level returns\n",
    "levene_stat, levene_p = stats.levene(groupA.dropna(), groupB.dropna())\n",
    "print(\"Levene p:\", levene_p)\n",
    "\n",
    "# Welch t-test (company-level)\n",
    "t_welch = stats.ttest_ind(groupA.dropna(), groupB.dropna(), equal_var=False)\n",
    "print(\"Welch t-test:\", t_welch)\n",
    "\n",
    "# Mann-Whitney\n",
    "mw_stat, mw_p = stats.mannwhitneyu(groupA.dropna(), groupB.dropna(), alternative='two-sided')\n",
    "print(\"Mann-Whitney p:\", mw_p)\n",
    "\n",
    "# Permutation test on difference of means\n",
    "diff, pperm, perm_dist = permutation_test_diff_means(groupA.dropna(), groupB.dropna(), n_perm=5000)\n",
    "print(\"Permutation p:\", pperm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a24b4",
   "metadata": {},
   "source": [
    "Si queremos comparar volatilidades entre dos conjuntos (ej. consolidadas vs growth):\n",
    "- usar Levene (robusto frente a no-normalidad)\n",
    "- reportar estadístico y p-value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb7a5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(4.369508336217758), np.float64(0.04578807097830151))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volA = agg_df.loc[agg_df['Beta'] <=1, 'Volatility']\n",
    "volB = agg_df.loc[agg_df['Beta'] >1, 'Volatility']\n",
    "lev_stat_vol, lev_p_vol = stats.levene(volA.dropna(), volB.dropna())\n",
    "lev_stat_vol, lev_p_vol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c001607c",
   "metadata": {},
   "source": [
    "Implementamos bootstrap para estimar la distribución empírica de la diferencia de medias entre grupos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6a03ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.009513751702866911),\n",
       " (np.float64(-0.0172271259653391), np.float64(-0.002270210397347441)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bootstrap_diff_means(x1, x2, n_boot=5000, random_state=0):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x1 = np.array(x1.dropna())\n",
    "    x2 = np.array(x2.dropna())\n",
    "    n1 = len(x1); n2 = len(x2)\n",
    "    boots = np.empty(n_boot)\n",
    "    for i in range(n_boot):\n",
    "        s1 = rng.choice(x1, size=n1, replace=True)\n",
    "        s2 = rng.choice(x2, size=n2, replace=True)\n",
    "        boots[i] = s1.mean() - s2.mean()\n",
    "    return boots\n",
    "\n",
    "boots = bootstrap_diff_means(groupA.dropna(), groupB.dropna(), n_boot=5000)\n",
    "ci_low, ci_hi = np.percentile(boots, [2.5, 97.5])\n",
    "obs_diff = groupA.mean() - groupB.mean()\n",
    "obs_diff, (ci_low, ci_hi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e436e59e",
   "metadata": {},
   "source": [
    "Para cada empresa estimamos:\n",
    "R_it = alpha_i + beta_i * R_m,t + eps_it\n",
    "- Reportamos coeficiente beta, se, t-stat, p-value\n",
    "- Diagnostic: residuales, normalidad, heterocedasticidad\n",
    "- Además: estimación de beta robusta (HC standard errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c2bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_monthly_market_returns(ticker=\"QQQ\", start=\"2018-01-01\", end=\"2024-12-31\"):\n",
    "    market = yf.download(\n",
    "        ticker,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        progress=False,\n",
    "        auto_adjust=True\n",
    "    )\n",
    "\n",
    "    # Asegurar que trabajamos con una SERIE de precios\n",
    "    if isinstance(market, pd.DataFrame):\n",
    "        if \"Close\" in market.columns:\n",
    "            price = market[\"Close\"]\n",
    "        else:\n",
    "            # fallback ultra defensivo\n",
    "            price = market.iloc[:, 0]\n",
    "    else:\n",
    "        price = market\n",
    "\n",
    "    price.index = pd.to_datetime(price.index)\n",
    "\n",
    "    # Precio mensual (fin de mes)\n",
    "    monthly_price = price.resample(\"ME\").last().dropna()\n",
    "\n",
    "    # Retornos logarítmicos mensuales\n",
    "    monthly_return = np.log(monthly_price / monthly_price.shift(1)).dropna()\n",
    "\n",
    "    # Convertir explícitamente a DataFrame\n",
    "    monthly_return = pd.DataFrame({\n",
    "        \"MarketReturn\": monthly_return\n",
    "    })\n",
    "\n",
    "    # Formato de fecha compatible con panel_df\n",
    "    monthly_return.index = monthly_return.index.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return monthly_return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ccc3f",
   "metadata": {},
   "source": [
    "Calculamos potencia post-hoc para comparaciones de medias (dos muestras) y, cuando corresponda, potencia a priori para detectar un efecto mínimo significativo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5eb8d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.8651739386123514), np.float64(0.5649249335816061))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo: potencia para detectar delta de medias d (effect size Cohen's d)\n",
    "def compute_power_two_sample(n1, n2, effect_size, alpha=0.05):\n",
    "    analysis = TTestIndPower()\n",
    "    # approximate equal n: use n per group\n",
    "    n_per_group = min(n1, n2)\n",
    "    power = analysis.power(effect_size=effect_size, nobs1=n_per_group, alpha=alpha, ratio=n2/n1)\n",
    "    return power\n",
    "\n",
    "# calcular effect size Cohen's d observado entre groupA y groupB\n",
    "mean1, mean2 = groupA.mean(), groupB.mean()\n",
    "sd1, sd2 = groupA.std(ddof=1), groupB.std(ddof=1)\n",
    "pooled_sd = np.sqrt((sd1**2 + sd2**2)/2)\n",
    "cohen_d = (mean1 - mean2) / pooled_sd\n",
    "power_obs = compute_power_two_sample(len(groupA), len(groupB), abs(cohen_d), alpha=0.05)\n",
    "cohen_d, power_obs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aabfabc",
   "metadata": {},
   "source": [
    "Guardamos las tablas principales:\n",
    "- ci_df (intervalos de confianza)\n",
    "- tt_df (one-sample t-tests)\n",
    "- capm_df (regresión CAPM)\n",
    "- resultados de comparación por grupos\n",
    "Además se incluye texto ejemplo para el informe con la interpretación de resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fac457d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Retornos de mercado construidos: (83, 1)\n",
      "✓ CAPM estimado para 30 empresas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>se_beta</th>\n",
       "      <th>t_beta</th>\n",
       "      <th>p_beta</th>\n",
       "      <th>R2</th>\n",
       "      <th>DW</th>\n",
       "      <th>bp_stat</th>\n",
       "      <th>bp_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Palantir</td>\n",
       "      <td>51</td>\n",
       "      <td>0.010507</td>\n",
       "      <td>2.273104</td>\n",
       "      <td>0.505728</td>\n",
       "      <td>4.494719</td>\n",
       "      <td>6.966175e-06</td>\n",
       "      <td>0.407508</td>\n",
       "      <td>2.487115</td>\n",
       "      <td>3.766133</td>\n",
       "      <td>0.052300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>83</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>1.738543</td>\n",
       "      <td>0.269782</td>\n",
       "      <td>6.444243</td>\n",
       "      <td>1.161786e-10</td>\n",
       "      <td>0.364470</td>\n",
       "      <td>1.787697</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.962471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>83</td>\n",
       "      <td>0.012835</td>\n",
       "      <td>1.623679</td>\n",
       "      <td>0.158795</td>\n",
       "      <td>10.225022</td>\n",
       "      <td>1.531939e-24</td>\n",
       "      <td>0.575616</td>\n",
       "      <td>1.708348</td>\n",
       "      <td>0.140266</td>\n",
       "      <td>0.708017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cloudflare</td>\n",
       "      <td>63</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>1.507436</td>\n",
       "      <td>0.280202</td>\n",
       "      <td>5.379817</td>\n",
       "      <td>7.456147e-08</td>\n",
       "      <td>0.317665</td>\n",
       "      <td>2.030644</td>\n",
       "      <td>0.127699</td>\n",
       "      <td>0.720830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spotify</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.011249</td>\n",
       "      <td>1.504924</td>\n",
       "      <td>0.145970</td>\n",
       "      <td>10.309825</td>\n",
       "      <td>6.361711e-25</td>\n",
       "      <td>0.559768</td>\n",
       "      <td>2.001168</td>\n",
       "      <td>0.036438</td>\n",
       "      <td>0.848613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company  n_obs     alpha      beta   se_beta     t_beta        p_beta  \\\n",
       "0    Palantir     51  0.010507  2.273104  0.505728   4.494719  6.966175e-06   \n",
       "1       Tesla     83  0.008110  1.738543  0.269782   6.444243  1.161786e-10   \n",
       "2      Nvidia     83  0.012835  1.623679  0.158795  10.225022  1.531939e-24   \n",
       "3  Cloudflare     63  0.000620  1.507436  0.280202   5.379817  7.456147e-08   \n",
       "4     Spotify     80 -0.011249  1.504924  0.145970  10.309825  6.361711e-25   \n",
       "\n",
       "         R2        DW   bp_stat      bp_p  \n",
       "0  0.407508  2.487115  3.766133  0.052300  \n",
       "1  0.364470  1.787697  0.002214  0.962471  \n",
       "2  0.575616  1.708348  0.140266  0.708017  \n",
       "3  0.317665  2.030644  0.127699  0.720830  \n",
       "4  0.559768  2.001168  0.036438  0.848613  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# CAPM: ESTIMACIÓN DE BETAS (VERSIÓN FINAL ROBUSTA)\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# ---------- 1) CONSTRUIR RETORNO DE MERCADO DESDE EL PANEL ----------\n",
    "# Mercado = promedio cross-section de retornos (equally-weighted)\n",
    "\n",
    "market_returns = (\n",
    "    panel_df\n",
    "    .groupby(\"Date\")[\"Return\"]\n",
    "    .mean()\n",
    "    .dropna()\n",
    "    .to_frame(name=\"MarketReturn\")\n",
    ")\n",
    "\n",
    "market_returns.index = market_returns.index.astype(str)\n",
    "\n",
    "print(\"✓ Retornos de mercado construidos:\", market_returns.shape)\n",
    "\n",
    "\n",
    "# ---------- 2) FUNCIÓN CAPM ----------\n",
    "def estimate_capm(company, panel_df, market_returns):\n",
    "\n",
    "    df_i = panel_df[panel_df[\"Company\"] == company].copy()\n",
    "    df_i[\"Date\"] = df_i[\"Date\"].astype(str)\n",
    "\n",
    "    df = df_i.merge(\n",
    "        market_returns,\n",
    "        left_on=\"Date\",\n",
    "        right_index=True,\n",
    "        how=\"inner\"\n",
    "    ).dropna(subset=[\"Return\", \"MarketReturn\"])\n",
    "\n",
    "    if len(df) < 12:   # mínimo 1 año\n",
    "        return None\n",
    "\n",
    "    X = sm.add_constant(df[\"MarketReturn\"])\n",
    "    y = df[\"Return\"]\n",
    "\n",
    "    model = sm.OLS(y, X).fit(cov_type=\"HC1\")  # errores robustos\n",
    "\n",
    "    resid = model.resid\n",
    "    dw = durbin_watson(resid)\n",
    "    bp = het_breuschpagan(resid, model.model.exog)\n",
    "\n",
    "    return {\n",
    "        \"Company\": company,\n",
    "        \"n_obs\": len(df),\n",
    "        \"alpha\": float(model.params[\"const\"]),\n",
    "        \"beta\": float(model.params[\"MarketReturn\"]),\n",
    "        \"se_beta\": float(model.bse[\"MarketReturn\"]),\n",
    "        \"t_beta\": float(model.tvalues[\"MarketReturn\"]),\n",
    "        \"p_beta\": float(model.pvalues[\"MarketReturn\"]),\n",
    "        \"R2\": float(model.rsquared),\n",
    "        \"DW\": float(dw),\n",
    "        \"bp_stat\": float(bp[0]),\n",
    "        \"bp_p\": float(bp[1])\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------- 3) EJECUTAR CAPM ----------\n",
    "capm_results = []\n",
    "\n",
    "for company in sorted(panel_df[\"Company\"].unique()):\n",
    "    res = estimate_capm(company, panel_df, market_returns)\n",
    "    if res is not None:\n",
    "        capm_results.append(res)\n",
    "\n",
    "capm_df = (\n",
    "    pd.DataFrame(capm_results)\n",
    "    .sort_values(\"beta\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"✓ CAPM estimado para\", capm_df.shape[0], \"empresas\")\n",
    "capm_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01a1cb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Todos los resultados fueron guardados correctamente en /data/processed\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# GUARDAR RESULTADOS FINALES\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# ---------- Comprobaciones mínimas ----------\n",
    "required_vars = [\n",
    "    \"ci_df\", \"tt_df\", \"capm_df\",\n",
    "    \"groupA\", \"groupB\",\n",
    "    \"t_welch\", \"levene_p\", \"mw_p\", \"pperm\",\n",
    "    \"PROCESSED_DIR\"\n",
    "]\n",
    "\n",
    "missing = [v for v in required_vars if v not in globals()]\n",
    "if missing:\n",
    "    raise NameError(f\"Faltan variables necesarias: {missing}\")\n",
    "\n",
    "# ---------- Guardar CSVs ----------\n",
    "ci_df.to_csv(\n",
    "    os.path.join(PROCESSED_DIR, \"ci_mean_by_company.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "tt_df.to_csv(\n",
    "    os.path.join(PROCESSED_DIR, \"one_sample_ttests_by_company.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "capm_df.to_csv(\n",
    "    os.path.join(PROCESSED_DIR, \"capm_by_company.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "# ---------- Resumen comparación de betas ----------\n",
    "# t_welch es un objeto TtestResult → extraemos statistic y pvalue\n",
    "group_summary = {\n",
    "    \"groupA_mean\": float(groupA.mean()),\n",
    "    \"groupA_n\": int(len(groupA)),\n",
    "    \"groupB_mean\": float(groupB.mean()),\n",
    "    \"groupB_n\": int(len(groupB)),\n",
    "\n",
    "    \"welch_t\": float(t_welch.statistic),\n",
    "    \"welch_p\": float(t_welch.pvalue),\n",
    "\n",
    "    \"levene_p\": float(levene_p),\n",
    "    \"mw_p\": float(mw_p),\n",
    "    \"perm_p\": float(pperm)\n",
    "}\n",
    "\n",
    "with open(\n",
    "    os.path.join(PROCESSED_DIR, \"group_beta_comparison_summary.json\"),\n",
    "    \"w\"\n",
    ") as f:\n",
    "    json.dump(group_summary, f, indent=4)\n",
    "\n",
    "print(\"✅ Todos los resultados fueron guardados correctamente en /data/processed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a5acf0",
   "metadata": {},
   "source": [
    "### Ejemplo de reporte (formato académico)\n",
    "\n",
    "**Intervalos de confianza para el retorno medio.** Para cada empresa se calculó el intervalo de confianza del 95\\% para el retorno medio usando la t-Student (varianza desconocida) y un intervalo bootstrap percentile con 3000 réplicas. Por ejemplo, Microsoft presenta retorno medio \\(\\hat\\mu = 0.0180\\) con IC t 95\\% = [0.007, 0.029] y bootstrap 95\\% = [0.006, 0.030]. Estos intervalos indican que el retorno mensual promedio es positivo y significativamente distinto de cero.\n",
    "\n",
    "**Pruebas de hipótesis (H0: μ=0).** Se aplicó un test t de una muestra a cada empresa y se ajustaron los p-values usando Bonferroni y Benjamini–Hochberg para controlar error tipo I. Reportamos las empresas cuyo p-valor ajustado (FDR) < 0.05. Para estas empresas rechazamos H0 y concluimos que su retorno medio está estadísticamente diferenciado de cero.\n",
    "\n",
    "**Comparación por grupos (Beta).** Las empresas fueron divididas en Beta ≤ 1 y Beta > 1. Se aplicó Levene para igualdad de varianzas, Welch t-test para diferencia de medias y Mann–Whitney como alternativa no paramétrica. Además, se realizó un test de permutación para robustez. Los resultados muestran que [aquí insertar conclusión basada en resultados].\n",
    "\n",
    "**Regresión CAPM.** Para cada empresa se estimó \\(R_{i,t} = \\alpha_i + \\beta_i R_{m,t} + \\varepsilon_{i,t}\\) por OLS con errores robustos HC1. Se reportaron \\(\\hat\\beta\\), error estándar robusto, t-stat y p-value. Para la mayoría de empresas \\(\\hat\\beta\\) es significativo (p < 0.05), lo que sugiere sensibilidad al mercado. Se presentan diagnósticos (Breusch–Pagan, Durbin–Watson) para evaluar heterocedasticidad y autocorrelación. Cuando se detecta heterocedasticidad se interpretan β con SE robustos.\n",
    "\n",
    "**Robustez.** Se implementaron bootstrap y pruebas no paramétricas para confirmar la validez de las conclusiones bajo violaciones de supuestos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
